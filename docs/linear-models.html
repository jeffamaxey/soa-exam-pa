<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Linear Models | Society of Actuaries Exam PA</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Linear Models | Society of Actuaries Exam PA" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="jeffamaxey/soa-exam-pa" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Linear Models | Society of Actuaries Exam PA" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Jeff A. Maxey" />


<meta name="date" content="2024-10-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data-exploration-and-visualization.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="assets/css/style.css" type="text/css" />
<link rel="stylesheet" href="assets/css/toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Society of Actuaries Exam PA</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#getting-started"><i class="fa fa-check"></i>Getting Started</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#system-requirements"><i class="fa fa-check"></i>System Requirements</a></li>
</ul></li>
<li class="part"><span><b>I A Crash Course in R</b></span></li>
<li class="chapter" data-level="1" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html"><i class="fa fa-check"></i><b>1</b> Basics of R Programming</a>
<ul>
<li class="chapter" data-level="1.1" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#data-types-in-r"><i class="fa fa-check"></i><b>1.1</b> Data Types in R</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#exercise-1.2.2---calculating-least-squares-estimates-by-matrix-manipulation"><i class="fa fa-check"></i><b>1.1.1</b> Exercise 1.2.2 - Calculating least squares estimates by matrix manipulation</a></li>
<li class="chapter" data-level="1.1.2" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#data-frames"><i class="fa fa-check"></i><b>1.1.2</b> Data Frames</a></li>
<li class="chapter" data-level="1.1.3" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#exercise-1.2.3---listing-the-components-of-a-list"><i class="fa fa-check"></i><b>1.1.3</b> Exercise 1.2.3 - Listing the components of a list</a></li>
<li class="chapter" data-level="1.1.4" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#functions"><i class="fa fa-check"></i><b>1.1.4</b> Functions</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#basic-data-management"><i class="fa fa-check"></i><b>1.2</b> Basic Data Management</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#task-1-removing-unimportant-variables"><i class="fa fa-check"></i><b>1.2.1</b> Task 1: Removing Unimportant Variables</a></li>
<li class="chapter" data-level="1.2.2" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#task-2-missing-values"><i class="fa fa-check"></i><b>1.2.2</b> Task 2: Missing Values</a></li>
<li class="chapter" data-level="1.2.3" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#task-3-adding-new-variables"><i class="fa fa-check"></i><b>1.2.3</b> Task 3: Adding New Variables</a></li>
<li class="chapter" data-level="1.2.4" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#task-4-using-logical-tests-to-identify-observations-with-certain-characteristics"><i class="fa fa-check"></i><b>1.2.4</b> Task 4: Using Logical Tests to Identify Observations with Certain Characteristics</a></li>
<li class="chapter" data-level="1.2.5" data-path="basics-of-r-programming.html"><a href="basics-of-r-programming.html#end-of-chapter-1-practice-problems"><i class="fa fa-check"></i><b>1.2.5</b> End of Chapter 1 Practice Problems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-exploration-and-visualization.html"><a href="data-exploration-and-visualization.html"><i class="fa fa-check"></i><b>2</b> Data Exploration and Visualization</a>
<ul>
<li class="chapter" data-level="" data-path="data-exploration-and-visualization.html"><a href="data-exploration-and-visualization.html#chapter-02-overview"><i class="fa fa-check"></i>Chapter Overview</a></li>
<li class="chapter" data-level="2.1" data-path="data-exploration-and-visualization.html"><a href="data-exploration-and-visualization.html#chapter-02-making-ggplots"><i class="fa fa-check"></i><b>2.1</b> Making <code>ggplots</code></a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="data-exploration-and-visualization.html"><a href="data-exploration-and-visualization.html#chapter-02-making-ggplots-basic-features"><i class="fa fa-check"></i><b>2.1.1</b> Basic Features</a></li>
<li class="chapter" data-level="2.1.2" data-path="data-exploration-and-visualization.html"><a href="data-exploration-and-visualization.html#chapter-02-making-ggplots-customizing-your-plots"><i class="fa fa-check"></i><b>2.1.2</b> Customizing Your Plots</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="data-exploration-and-visualization.html"><a href="data-exploration-and-visualization.html#chapter-02-data-exploration"><i class="fa fa-check"></i><b>2.2</b> Data Exploration</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="data-exploration-and-visualization.html"><a href="data-exploration-and-visualization.html#chapter-02-data-exploration-univariate"><i class="fa fa-check"></i><b>2.2.1</b> Univariate Data Exploration</a></li>
<li class="chapter" data-level="2.2.2" data-path="data-exploration-and-visualization.html"><a href="data-exploration-and-visualization.html#chapter-02-data-exploration-bivariate"><i class="fa fa-check"></i><b>2.2.2</b> Bivariate Data Exploration</a></li>
<li class="chapter" data-level="2.2.3" data-path="data-exploration-and-visualization.html"><a href="data-exploration-and-visualization.html#end-of-chapter-practice-problems"><i class="fa fa-check"></i><b>2.2.3</b> End-of-Chapter Practice Problems</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Theory of and Case Studies in Predictive Analytics</b></span></li>
<li class="chapter" data-level="3" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>3</b> Linear Models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="linear-models.html"><a href="linear-models.html#a-primer-on-predictive-analytics"><i class="fa fa-check"></i><b>3.1</b> A Primer on Predictive Analytics</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="linear-models.html"><a href="linear-models.html#basic-terminology"><i class="fa fa-check"></i><b>3.1.1</b> Basic Terminology</a></li>
<li class="chapter" data-level="3.1.2" data-path="linear-models.html"><a href="linear-models.html#the-model-building-process"><i class="fa fa-check"></i><b>3.1.2</b> The Model Building Process</a></li>
<li class="chapter" data-level="3.1.3" data-path="linear-models.html"><a href="linear-models.html#bias-variance-trade-off"><i class="fa fa-check"></i><b>3.1.3</b> Bias-Variance Trade-Off</a></li>
<li class="chapter" data-level="3.1.4" data-path="linear-models.html"><a href="linear-models.html#feature-generation-and-selection"><i class="fa fa-check"></i><b>3.1.4</b> Feature Generation and Selection</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="linear-models.html"><a href="linear-models.html#linear-models-conceptual-foundation"><i class="fa fa-check"></i><b>3.2</b> Linear Models: Conceptual Foundation</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="linear-models.html"><a href="linear-models.html#model-formulation"><i class="fa fa-check"></i><b>3.2.1</b> Model Formulation</a></li>
<li class="chapter" data-level="3.2.2" data-path="linear-models.html"><a href="linear-models.html#model-evaluation-and-validation"><i class="fa fa-check"></i><b>3.2.2</b> Model Evaluation and Validation</a></li>
<li class="chapter" data-level="3.2.3" data-path="linear-models.html"><a href="linear-models.html#feature-generation"><i class="fa fa-check"></i><b>3.2.3</b> Feature Generation</a></li>
<li class="chapter" data-level="3.2.4" data-path="linear-models.html"><a href="linear-models.html#feature-selection"><i class="fa fa-check"></i><b>3.2.4</b> Feature Selection</a></li>
<li class="chapter" data-level="3.2.5" data-path="linear-models.html"><a href="linear-models.html#regularization"><i class="fa fa-check"></i><b>3.2.5</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="linear-models.html"><a href="linear-models.html#case-study-1-fitting-linear-models-in-r"><i class="fa fa-check"></i><b>3.3</b> Case Study 1: Fitting Linear Models in R</a>
<ul>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#about-this-case-study"><i class="fa fa-check"></i><strong>About this Case Study</strong></a></li>
<li class="chapter" data-level="3.3.1" data-path="linear-models.html"><a href="linear-models.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>3.3.1</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="3.3.2" data-path="linear-models.html"><a href="linear-models.html#simple-linear-regression"><i class="fa fa-check"></i><b>3.3.2</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="3.3.3" data-path="linear-models.html"><a href="linear-models.html#multiple-linear-regression"><i class="fa fa-check"></i><b>3.3.3</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="3.3.4" data-path="linear-models.html"><a href="linear-models.html#evaluation-of-linear-models"><i class="fa fa-check"></i><b>3.3.4</b> Evaluation of Linear Models</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="linear-models.html"><a href="linear-models.html#case-study-2-feature-selection-and-regularization"><i class="fa fa-check"></i><b>3.4</b> Case Study 2: Feature Selection and Regularization</a>
<ul>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#about-this-case-study-1"><i class="fa fa-check"></i>About this Case Study</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#data-dictionary"><i class="fa fa-check"></i>Data Dictionary</a></li>
<li class="chapter" data-level="3.4.1" data-path="linear-models.html"><a href="linear-models.html#preparatory-work"><i class="fa fa-check"></i><b>3.4.1</b> Preparatory Work</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#task-1-consider-a-data-issue"><i class="fa fa-check"></i>TASK 1: Consider a Data Issue</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#task-2-explore-the-numeric-variables"><i class="fa fa-check"></i>TASK 2: Explore the Numeric Variables</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#task-3-explore-the-factor-variables"><i class="fa fa-check"></i>TASK 3: Explore the Factor Variables</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#task-4-consider-two-graphs"><i class="fa fa-check"></i>TASK 4: Consider Two Graphs</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#task-5-explore-the-effect-of-releveling-factor-variables"><i class="fa fa-check"></i>TASK 5: Explore the Effect of Releveling Factor Variables</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#task-6-binarize-factor-variables-manually"><i class="fa fa-check"></i>TASK 6: Binarize Factor Variables Manually</a></li>
<li class="chapter" data-level="3.4.2" data-path="linear-models.html"><a href="linear-models.html#model-construction-and-feature-selection"><i class="fa fa-check"></i><b>3.4.2</b> Model Construction and Feature Selection</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#task-7-select-features-using-stepwise-selection"><i class="fa fa-check"></i>TASK 7: Select Features using Stepwise Selection</a></li>
<li class="chapter" data-level="3.4.3" data-path="linear-models.html"><a href="linear-models.html#model-validation"><i class="fa fa-check"></i><b>3.4.3</b> Model Validation</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#task-8-select-and-validate-the-recommended-model"><i class="fa fa-check"></i>TASK 8: Select and Validate the Recommended Model</a></li>
<li class="chapter" data-level="3.4.4" data-path="linear-models.html"><a href="linear-models.html#regularization-2"><i class="fa fa-check"></i><b>3.4.4</b> Regularization</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#task-9-effect-of-regularization"><i class="fa fa-check"></i>TASK 9: Effect of Regularization</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#task-10-perform-feature-selection-with-regularization"><i class="fa fa-check"></i>TASK 10: Perform Feature Selection with Regularization</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#conceptual-review-questions-for-chapter-3"><i class="fa fa-check"></i>Conceptual Review: Questions for Chapter 3</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/jeffamaxey/soa-exam-pa" target="blank">Github Repository</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Society of Actuaries Exam PA</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear-models" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapter 3</span> Linear Models<a href="linear-models.html#linear-models" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="a-primer-on-predictive-analytics" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> A Primer on Predictive Analytics<a href="linear-models.html#a-primer-on-predictive-analytics" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This subsection streamlines the material scattered in different parts of the PA modules (which are notoriously difficult to digest) and presents a coherent introduction to predictive analytics.</p>
<p>The fundamental concepts introduced in this section are universally applicable in the sense that they apply to essentially all types of models, and will be illustrated in the context of specific types of models (generalized linear models and decision trees, in particular) in this and later chapters.</p>
<div id="basic-terminology" class="section level3 hasAnchor" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> Basic Terminology<a href="linear-models.html#basic-terminology" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Predictive Analytics in a Nutshell:</strong></p>
<p>What exactly is predictive analytics? To answer this question, it may help to understand the three main categories of predictive modeling problems suggested by the PA modules:</p>
<ul>
<li><strong>Descriptive:</strong> Descriptive analytics focuses on what happened in the <strong><em>past</em></strong> and aims to “describe” or explain the observed trends by identifying the relationships between different variables in the data.
<ul>
<li><strong>Example:</strong> If you saw an increase in the lapse rate among the policyholders of a certain line of business, what kind of policyholders had the highest tendency to lapse? This is a question that can be answered by descriptive analytics.</li>
</ul></li>
<li><strong>Predictive:</strong> Predictive analytics focuses on what will happen in the <strong><em>future</em></strong> and is concerned with making accurate “predictions”.
<ul>
<li><strong>Example:</strong> For a prospective policyholder with certain characteristics, what is their predicted probability of lapse? The ability to make such a prediction will be useful for identifying future policyholders who will have a lower probability of lapse and contribute to the profitability of an insurer.</li>
</ul></li>
<li><strong>Prescriptive:</strong> Prescriptive analytics uses a combination of optimization and simulation to investigate and quantify impact of different “prescribed” actions in different scenarios.
<ul>
<li><strong>Example:</strong> If we reduce the premium by a certain amount, how will this affect the lapse rate?</li>
</ul></li>
</ul>
<p>Not surprisingly, Exam PA is predominantly concerned with <em>predictive analytics</em>, although the three modeling approaches are often mutually complementary, not contradictory.</p>
<p>There is always an output (or outcome) of interest, which can be numeric (salary, premium, injury rates) or categorical (positive/negative, email/spam), and we have at our disposal a collection of input variables that may offer potentially useful information for predicting or understanding the output.</p>
<p>This “input-output” setting is characteristic of predictive analytics in general, and our job is to develop a model teasing out the (possibly complex, overlapping) contributions of inputs to the outputs.</p>
<p><strong>Classification of Variables:</strong></p>
<p>Predictive analytics requires data, often with a large number of observations and variables. Generally speaking, there are two ways to classify variables in a predictive analytics context: By their role in the study (intended use) or by their nature (characteristics).</p>
<ul>
<li><p><strong>By Role:</strong> The variable that we are interested in predicting is called the <strong><em>target variable</em></strong>, or simply the <strong><em>target</em></strong> <strong>(a.k.a response variable, dependent variable, output variable, outcome variable).</strong></p>
<p>Despite the target variable being our interest, in most situations we cannot change the target variable directly, but we have control over some associated variables which can be used to predict the target. These variables go by different names, such as <strong><em>predictors, explanatory variables, independent variables, input variables</em></strong>.</p>
<p>In an actuarial context, predictors are also known as risk factors or risk drivers. In the remainder of this manual and in Exam PA, we will mostly use the term “predictors” and “features” (to be defined in Subsection 3.1.4).</p>
<p>Throughout your study of predictive analytics, it is useful to think of a predictive model as the following functional relationship between the target variable <span class="math inline">\(Y\)</span> and the set of predictors <span class="math inline">\(X = (X_{1}, ..., X_{p})\)</span> (collected as a vector): <span class="math display">\[
        \begin{equation}
        Y_{i} = f(X_{i}) + \epsilon_{i} (\#eq:linear-relationship)
        \end{equation}
        \]</span> Where:</p>
<ul>
<li><p>The subscript <span class="math inline">\(i\)</span> signifies the <span class="math inline">\(i\)</span>th observation in your dataset, so <span class="math inline">\(Y_{i}\)</span> is the value of the target variable for the <span class="math inline">\(i\)</span>th observation and <span class="math inline">\(X_{i} = (X_{i1},..., X_{ip})\)</span> is the corresponding vector of predictor values.</p></li>
<li><p>The symbol <span class="math inline">\(f\)</span> is a fixed (non-random) but unknown real function connecting the predictors and the target variables. Without the subscript <span class="math inline">\(i\)</span> (it is <span class="math inline">\(f\)</span> rather than <span class="math inline">\(f_{i}\)</span>), the function applies to all observations in the data, hence “systematic”. Largely synonymous with the model, this function carries the systematic information that the predictors offer about the target variable, and allows us to differentiate, or discriminate, the observations of the target variable on the basis of those of the predictors.</p>
<p>Different types of predictive models are distinguished by the structural form of this function, e.g., linear for linear models and piece-wise constant for decision trees, as we will see in later chapters.</p></li>
<li><p>The symbol <span class="math inline">\(\epsilon_{i}\)</span> is a zero-mean random error term carrying information that is specific to the <span class="math inline">\(i\)</span>th observation, hence “idiosyncratic” and the presence of the subscript <span class="math inline">\(i\)</span>. It can be regarded as a catch-all for what the systematic component of the model misses, e.g., the true relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is probably more complex than <a href="#eq:linear-relationship">(<strong>??</strong>)</a>, there are other variables associated with <span class="math inline">\(Y\)</span> omitted by the model.</p>
<p>Although <a href="#eq:linear-relationship">(<strong>??</strong>)</a> looks abstract and the exam will not test it directly, it will provide a useful framework for thinking about predictive analytics.</p>
<p>For convenience, we will refer to <span class="math inline">\(f\)</span> and <span class="math inline">\(\epsilon\)</span> respectively as the <span class="math inline">\(\fbox{signal function}\)</span> and the <span class="math inline">\(\fbox{noise}\)</span> which are engineering terms.</p>
<p>We are interested in the signal, but the data we have is “contaminated” with noise. The goal of predictive analytics is to filter out the noise and use a variety of tools and techniques to learn as much about the signal as possible from the data. This knowledge about the signal can then provide us with a basis for understanding the data-generating process underlying the population of interest, and making predictions for the target variable.</p></li>
</ul></li>
</ul>
<!-- -->
<ul>
<li><p><strong>By Nature:</strong> Variables can also be classified as <em>numeric</em> variables or <em>categorical</em> variables. Such a classification has important implications for developing an effective predictive model that aligns with the character of the target variable and predictors to produce realistic output.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Numeric Variables:</strong> Numeric variables take the form of numbers with a well-defined order (e.g., 1 must be less than 2) and an associated range. They can be further classified as:</p>
<ul>
<li><p><strong>Discrete variables:</strong> Restricted to only certain numeric values in that range, e.g., non-negative integers.</p></li>
<li><p><strong>Continuous:</strong> Can assume any value in a continuum, at least in theory.</p></li>
</ul></li>
<li><p><strong>Categorical Variables:</strong> Categorical variables take predefined values in a countable collection of “categories”. These categories, which often have no numeric order (i.e., we cannot say which category is larger or smaller), are called the <strong>levels</strong> or <strong>classes</strong> of the variable. Here are some examples of properties that can be described by categorical variables:</p>
<ul>
<li><p>Gender (male, female, or non-binary)</p></li>
<li><p>Smoking status (smoking or non-smoking)</p></li>
<li><p>Risk group (preferred, standard, rated, or un-insurable)</p></li>
<li><p>Marital status (single, married, divorced, or widowed)</p></li>
</ul>
<p>An important special case of a categorical variable is a <strong>binary</strong> variable, which only takes two possible levels (often yes or no), indicating whether an event has taken place or whether a characteristic is present.</p>
<p>In many datasets in practice, categorical variables are represented by numbers, but note that coding the levels of a categorical variable by numbers does not make the variable numeric. Consider, for instance, the variable <span class="math inline">\(X\)</span> which represents smoking status and is encoded as: <span class="math display">\[
X = \begin{cases} &amp; \text{0, for a non-smoker,} \\ &amp; \text{1, for a smoker,} \\ &amp; \text{2, for an individual with unknown smoking status.}  \end{cases}
\]</span></p>
<p>Even though the three levels “non-smoker”, “smoker”, and “unknown” have been coded as “0”, “1”, and “2”, respectively, the three numbers are merely labels without an implicit order and cannot be compared in an algebraic fashion. For example, “1” is not less than “2” in a meaningful fashion in this case.</p></li>
</ol>
<p>In predictive modeling, the type of model to use is largely determined by the nature of the target variable, not the predictors.</p>
<p>In other words, the distinction between continuous and categorical variables is relatively unimportant when they serve as predictors of a model, but we need to take the distinction properly into account when they serve as the target variable. Some predictive models (e.g., linear models) will work well only for continuous target variables while some (e.g., generalized linear models and decision trees) apply to both numeric and categorical target variables.</p></li>
</ul>
<p><strong>Supervised vs. Unsupervised Problems:</strong></p>
<p>Predictive analytics problems can also be classified into <em>supervised</em> and <em>unsupervised</em> problems, depending on the presence of a target variable and the objective of analysis.</p>
<ul>
<li><p><strong>Supervised Learning Problems:</strong> They refer to those for which there is a target variable “supervising” or guiding our analysis, and our goal is to understand the relationship between the target variable and the predictors, and/or make accurate predictions for the target based on the predictors.</p>
<ul>
<li><p><strong>Types of Supervised Learning Methods:</strong></p>
<ul>
<li><p>Generalized Linear Models (GLMs)</p></li>
<li><p>Decision Trees</p></li>
</ul></li>
</ul></li>
<li><p><strong>Unsupervised Learning Problems:</strong> For unsupervised learning methods, there is no target variable supervising our analysis (we are therefore “unsupervised”), and we are interested in extracting relationships and structures between different variables in the data.</p>
<ul>
<li><p><strong>Types of Unsupervised Learning Methods:</strong></p>
<ul>
<li><p>Principal Components Analysis (PCA)</p></li>
<li><p>Cluster Analysis</p></li>
</ul></li>
</ul></li>
</ul>
<p>Note that supervised and unsupervised learning methods are sometimes used in conjunction with one another. As we will see in Chapter 6, unsupervised learning methods can be used for the purposes of data exploration and producing potentially useful features for predicting the target variable more accurately.</p>
<p><strong>Regression vs. Classification Problems:</strong></p>
<p>In predictive analytics, it is customary to refer to supervised learning problems with a numeric target variable as <strong><em>regression</em></strong> problems (an exception is logistic regression, for which the target variable is binary; see Chapter 4. In contrast, when the target variable is categorical in nature, we are dealing with <strong><em>classification</em></strong> problems. A predictive model for predicting a categorical target variable involves “classifying” its observations to a certain level and is aptly called a <em>classifier</em>.</p>
<p>Both regression and classification problems are of importance in predictive modeling in general. The two kinds of predictive analytics problems have their unique features and will covered in detail in Part II of this manual.</p>
</div>
<div id="the-model-building-process" class="section level3 hasAnchor" number="3.1.2">
<h3><span class="header-section-number">3.1.2</span> The Model Building Process<a href="linear-models.html#the-model-building-process" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now that we have a first taste of what predictive analytics is like, in this important and rather lengthy subsection we will walk through the main steps involved in the construction and evaluation of a predictive model.</p>
<p>In practice, model building typically requires a sequence of complex and inter-related decisions. The whole process is iterative and often more of an art than a science. The framework here is necessarily simplified and focuses on the most important steps in Exam PA, but is rich enough to show you what it takes to build a good model in real life.</p>
<div id="stage-1-problem-definition" class="section level4 hasAnchor" number="3.1.2.1">
<h4><span class="header-section-number">3.1.2.1</span> Stage 1: Problem Definition<a href="linear-models.html#stage-1-problem-definition" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The first step in any model building exercise is to clearly formulate the business problems to which predictive analytics will be applied.</p>
<div id="characteristics-of-predictive-modeling-problems" class="section level5 unnumbered hasAnchor">
<h5>Characteristics of Predictive Modeling Problems<a href="linear-models.html#characteristics-of-predictive-modeling-problems" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Before we decide to apply predictive analytics to solve a business problem, we should ensure that it is indeed a problem that should be addressed by predictive modeling.</p>
<p>A conceptual exam task testing the syllabus learning outcome, “Describe the characteristics of predictive modeling problems.”, may ask:</p>
<p>Some common characteristics of predictive modeling problems include:</p>
<table>
<caption><span id="tab:unnamed-chunk-4">TABLE 3.1: </span>Characteristics of Predictive Modeling Problems</caption>
<thead>
<tr class="header">
<th align="left">Characteristic</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><strong>Issue</strong></td>
<td align="left">There is a clearly identified and defined business issue that needs to be addressed.</td>
</tr>
<tr class="even">
<td align="left"><strong>Questions</strong></td>
<td align="left">The issue can be addressed with a few well-defined questions (What data do we need? What is the target or outcome? What is the success criteria / how will the model performance be evaluated?)</td>
</tr>
<tr class="odd">
<td align="left"><strong>Data</strong></td>
<td align="left">Good and useful data is available for answering the questions above.</td>
</tr>
<tr class="even">
<td align="left"><strong>Impact</strong></td>
<td align="left">The predictions will likely drive actions or increase understanding.</td>
</tr>
<tr class="odd">
<td align="left"><strong>Better Solution</strong></td>
<td align="left">Predictive analytics likely produces a solution better than any existing approach.</td>
</tr>
<tr class="even">
<td align="left"><strong>Update</strong></td>
<td align="left">We can continue to monitor and update the models when new data becomes available.</td>
</tr>
</tbody>
</table>
<p>A typical predictive modeling problem will have most, but not necessarily all of these characteristics.</p>
</div>
<div id="problem-definition" class="section level5 unnumbered hasAnchor">
<h5>Problem Definition<a href="linear-models.html#problem-definition" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>After deciding to use predictive analytics to address the business issue of interest, we should define the problem as clearly as possible.</p>
<p>It is important to get to the root cause of the business issue and make it specific enough to be solvable.</p>
<p>The following strategies suggested can help us come up with a meaningful problem definition and give our project a higher chance of success:</p>
<ul>
<li><p><strong>Hypotheses:</strong> It is useful to use our prior knowledge of the business problem to ask questions and develop hypotheses that can prove or disprove in the course of our analytic work. Doing so helps us gain a clearer understanding of the business issue and guide our efforts in a clearly defined way. With the questions and hypotheses, we know where to focus on.</p></li>
<li><p><strong>KPI’s:</strong> We also need ways to assess the outcome by selecting appropriate key performance indicators (KPI’s), which will provide a quantitative basis to measure the success of the project. Naturally, these KPI’s should align with the overall business strategy as far as possible and show the client what key numbers will change as a result of your predictive analytic work.</p></li>
</ul>
</div>
<div id="constraints" class="section level5 unnumbered hasAnchor">
<h5>Constraints<a href="linear-models.html#constraints" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>As soon as we have defined the business problem clearly, it is important to evaluate the feasibility of solving the business problem and implementing the predictive analytic solution.</p>
<p>We want to make sure that the solutions we produce will work. Some considerations and constraints we should keep in ind when evaluating and prioritizing business problems include:</p>
<ul>
<li>The availability of easily accessible and high-quality data.</li>
<li>Implementation issues such as the presence of necessary IT infrastructure and technology to fit complex models efficiently, the timeline for completing the project, and the cost and effort required to maintain the selected model.</li>
</ul>
<p>Do we have the resources to implement complex models without freezing or crashing? If a model is operationally prohibitive to execute, then it makes sense to trade some prediction performance for ease of implementation. After all, if we cannot actually implement and apply the model in practice, then it is basically useless.</p>
</div>
</div>
<div id="stage-2-data-collection-and-validation" class="section level4 hasAnchor" number="3.1.2.2">
<h4><span class="header-section-number">3.1.2.2</span> Stage 2: Data Collection and Validation<a href="linear-models.html#stage-2-data-collection-and-validation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Predictive analytics relies on models, which in turn are constructed from data. After defining the business problem properly, we will spend some time and effort collecting useful data that will underlie the predictive models we are going to build.</p>
<p>This data collection stage is more important and intricate than you probably first thought. You may have heard of the phrase “garbage in, garbage out”, better known as GIGO, which means that low-quality data is doomed to produce low-quality output.</p>
<p>Here we will learn some key considerations and some pitfalls to avoid related to the collection and use of data.</p>
<div id="data-design" class="section level5 unnumbered hasAnchor">
<h5>Data Design<a href="linear-models.html#data-design" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>To begin, we will contemplate here to collect the data to be used in the modeling stage.</p>
<p>At the data design stage, there are a few things we should take note of to maximize the usefulness of our data source, which is the entire set of observations that enter the dataset you collect.</p>
<ul>
<li><p><strong>Relevance:</strong> Intuitively, the more data we have, the more information available and the better, provided that the data is unbiased (e.g., representative of the environment where our predictive model will operate). To ensure that the data is relevant for our business problem, it is necessary to source the data from the right population and time frame.</p>
<ul>
<li><p><strong>Population:</strong> As obvious as this may seem, it is important that the data source aligns with the true population we are interested in. If the data source is not a reasonably good proxy of a representative sample, then taking a larger dataset does not help, we are only representing the bias over again and again.</p></li>
<li><p><strong>Time Frame:</strong> When selecting an appropriate time frame for our data, it is advisable to choose the time period which best reflects the business environment in which we will be implementing our models. In general, recent history is more predictive of the near future than distant history, so data one year ago should be more useful than data 10 years ago, other things equal.</p></li>
</ul>
<p><strong>Example 3.1.1: Problems with a Facebook Poll</strong></p>
<p>In November 2020, the Divide States of America (DSA) held its 60th presidential election, with Donald Dump running against Joe Hidden. To gauge public sentiments towards the election, Great News Network (GNN), a/an information outlet, set up a poll on Facebook allowing users to vote for their preferred presidential candidate. Any Facebook users could take part in the poll, which was open between August 2020 and September 2020.</p>
<p>Evaluate the quality of the data collected by GNN with respect to the population, time frame, and/or other items.</p>
<p><strong><em>Solution:</em></strong> There are quite a few problems with the data collected by GNN, some of which are:</p>
<ul>
<li><p><strong>Population:</strong> The votes were limited to Facebook users while the intended audience was supposed to be all eligible citizens of DSA. Users of social media outlets tend to be younger generations, so there may be a systematic mismatch between the voters of the poll and the general population.</p></li>
<li><p><strong>Time Frame:</strong> The objective of the poll was to understand voters’ preferences at the time of the November 2020 election. The poll, conducted between August 2020 and September 2020, was premature in a way and might fail to gauge public sentiments accurately (a lot could happen in October). It may be desirable for the poll to extend to October, right before the November election took place.</p></li>
<li><p><strong>Quality:</strong> By design, the data collected is susceptible to <strong><em>contamination</em></strong>. An individual may register for several accounts and take part in the poll several times. The repetitive votes are allowed by the poll could substantially bias the polling results.</p></li>
</ul>
<p><strong>Example 3.1.2 Considerations with Time Frame (Based on Exercise 2.1.1 in the PA Modules)</strong></p>
<p>Suppose that you are constructing a model to predict which retirement option a customer will choose. You have data from 1990 to 2020 containing your customers choices. In 2010, your company introduced a digital platform, which increased not only the variety of retirement options available, but also the richness of the supporting data available to customers when they made their decisions.</p>
<p>Discuss the pros and cons of including all of the data from 1990 relative to including only the data from 2010 for constructing your predictive model.</p>
<p><strong><em>Solution:</em></strong></p>
<ul>
<li><p><strong>Pros:</strong> Including all of the data from 1990 means more data. Other things equal, having more data is generally desirable as it makes model training more robust and less vulnerable to noise.</p></li>
<li><p><strong>Cons:</strong> In predictive modeling, it is important to select the period of time that best reflects the environment in which we will be implementing our model. In this case, something happened in 2010 which significantly affected the behavior of the outcome (retirement options) we are modeling. This makes the data prior to 2010 less likely to be predictive of current and future behavior of customers. Including such (outdated) data may make the predictions of retirement options in the current era less accurate.</p></li>
</ul></li>
<li><p><strong>Sampling:</strong> Sampling is the process of taking a subset of observations from the data source to generate our dataset.</p>
<p>Why do we need to bother with sampling? Why not use the entire data source? In reality, the underlying population is often too big to handle, and we need a smaller, much more manageable subset to form our data.</p>
<p>The observations sampled should closely resemble the business environment in which our predictive model will be applied in the future. In fact, a good time frame, discussed above, can be seen as a form of sampling, which the same goal of making sure that our data is representative.</p>
<p>There are a number of sampling methods commonly used to draw an appropriate sample:</p>
<ul>
<li><p><strong>Random Sampling:</strong> This is the simplest sampling scheme by which we “randomly” draw observations from the underlying population without replacement until we have the required number of observations. Each record is equally likely to be sampled.</p>
<ul>
<li><p>One common way to achieve <strong>random sampling</strong> is through a survey or questionnaire. Individuals in the population are invited to respond to the survey and contribute to the collected dataset.</p>
<p>However, voluntary surveys are known to be vulnerable to <strong><em>respondent bias</em></strong>. Only those interested will respond, which means that the respondents of a survey may make up a population different from the the population of interest.</p>
<p>For example, university students who respond to end-of-semester course evaluations tend to be those who feel strongly about the courses they take. These students with strong opinions may substantially bias the results of the course evaluations which are supposed to be for the general students.</p>
<p>Surveys also tend to suffer from a <strong><em>low response rate</em></strong>, unless there are financial incentives for people to respond.</p></li>
</ul></li>
<li><p><strong>Stratified Sampling:</strong> Stratified sampling involves dividing the underlying population into a number of non-overlapping “strata” or groups in a non-random fashion, and randomly sampling (with or without replacement) a set number of observations from each stratum.</p>
<p>This sampling method has the notable advantage of ensuring that every stratum is properly represented in the collected data. In Exam PA, the strata are usually formed with respect to the distribution of the target variable.</p>
<p>Here are a few special cases of <strong>stratified sampling</strong>:</p>
<ul>
<li><p><strong><em>Oversampling and Undersampling:</em></strong> These are sampling methods designed specifically for unbalanced data, and we will learn about them in detail in Subsection 4.1.4.</p></li>
<li><p><strong>Systematic Sampling:</strong> By systematic sampling, we draw observations according to a set pattern and there is no random mechanism controlling which observations are sampled.</p>
<p>For a population with 100,000 units, we may order them in a well-defined way and sample every tenth observation to get a smaller, more manageable sample of 10,000 units. Once the sampling rule has been set, the sampled observations are pre-determined.</p></li>
</ul></li>
</ul></li>
<li><p><strong>Granularity:</strong> Granularity refers to how precisely a variable in a dataset is measured, or equivalently, how detailed the information contained by the variable is. As an example, location, in ascending order of granularity, can be recorded in different degrees of precision:</p>
<ul>
<li><p>By Country (least granular)</p></li>
<li><p>By State</p></li>
<li><p>By City</p></li>
<li><p>By Zip Code</p></li>
<li><p>By Address (most granular)</p></li>
</ul>
<p>From country to address, we have more and more specific information about the location of an individual.</p>
<p>At the data design stage, it is a good idea to use a relatively high level of granularity. It is always possible to go from a higher level of granularity to a lower level of granularity down the track, but not the other way around.</p></li>
</ul>
</div>
<div id="data-quality-issues" class="section level5 unnumbered hasAnchor">
<h5>Data Quality Issues<a href="linear-models.html#data-quality-issues" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Once we have collected the data from a data source representative of the population of interest using an appropriate sampling method, we have to take an important step before jumping straight into doing predictive modeling: <strong><em>Data Validation</em></strong>, the process of ensuring the quality and appropriateness of the data available.</p>
<p>If the collected data falls short of our standards, we may have to go back to the data collection step and search for an alternative dataset.</p>
<ul>
<li><p><strong>Reasonableness:</strong> For a dataset to be useful, the data values should, at a minimum, be reasonable, which can be checked by exploratory data analysis. Do the key statistics for the variables make sense in the context of the business problem? If one of the variables is income and one observation has a negative income, then almost certainly this is a recording error that should be fixed before we launch into model construction.</p></li>
<li><p><strong>Consistency:</strong> We also need to ensure that the records in the data are inputted consistently, meaning that the same basis and rules have been applied to all values, so that they can be directly compared with one another.</p>
<ul>
<li><strong><em>Numeric Variables:</em></strong> For numeric variables, the same unit should be used across all rows of the data for consistency. If one of the variables is weight, the nits values should be measured either all in kilograms or all in pounds. If there is a monetary variable, such as income, then the same currency should be used throughout.</li>
</ul></li>
<li><p><strong><em>Categorical Variables:</em></strong> We should make sure that the factor levels of categorical variables are defined and recorded consistently over time with no coding changes, like either the full name (e.g., Iowa) or the two-character abbreviation (e.g., IA) for the state of policy issue.</p></li>
</ul>
<pre><code>To check consistency, it is necessary to gain knowledge of how the data entries are recorded. To this end, the data dictionary (see the next point) that accompanies each PA exam project will be useful.

If we want to combine multiple datasets to form new variables (columns) or new observations (rows), then the consistency checks above extend to all constituent datasets to make sure that the concatenation works properly.

If we need to join datasets by a certain variable (column), it is especially important to ensure that the format of that variable is consistent across both datasets to ease matching, e.g., name should be recorded either as [first name] or [last name], [first name] so that each person can be identified uniquely. The possible existence of a middle name adds further complication.</code></pre>
<!-- -->
<ul>
<li><p><strong>Sufficient Documentation:</strong> A good dataset should also be sufficiently documented so that other users can easily gain an accurate understanding of different aspects of the data. The PA modules suggest that effective documentation should at least include the following information:</p></li>
<li><p>A description of the dataset overall, including the data source (how and when the dataset was collected).</p></li>
<li><p>A description of each variable in the data, including its name, definition, and format (range of values for numeric variables and the possible levels for categorical variables).</p></li>
<li><p>Notes about any past updates or other irregularities of the dataset.</p></li>
<li><p>A statement of accountability for the correctness of the dataset.</p></li>
<li><p>A description of the governance processes used to manage the dataset.</p></li>
</ul>
<p>Exam PA exam project describes the dataset in the “Business Problem” section and provides you with a <em>data dictionary</em>, which lists all the variables in the data together with their information. Here is a sample data dictionary for a hypothetical group of insurance policies:</p>
<table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-5">TABLE 3.2: </span>Sample Data Dictionary
</caption>
<thead>
<tr>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
VariableName
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Description
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Values
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<code>age</code>
</td>
<td style="text-align:left;">
The age of a policyholder
</td>
<td style="text-align:left;">
Integer, 20 to 65
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>gender</code>
</td>
<td style="text-align:left;">
The gender of a policyholder
</td>
<td style="text-align:left;">
3 levels, “F”, “M”, and “0”
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>type</code>
</td>
<td style="text-align:left;">
The risk type of a policyholder
</td>
<td style="text-align:left;">
2 levels, “standard” and “substandard”
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>n_claims</code>
</td>
<td style="text-align:left;">
The number of claims submitted
</td>
<td style="text-align:left;">
Integer, 0 to 10
</td>
</tr>
<tr>
<td style="text-align:left;">
<code>claims</code>
</td>
<td style="text-align:left;">
The total amount of claims
</td>
<td style="text-align:left;">
Numeric, 0 to 30,451.8
</td>
</tr>
</tbody>
</table>
</div>
<div id="other-data-issues" class="section level5 unnumbered hasAnchor">
<h5>Other Data Issues<a href="linear-models.html#other-data-issues" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Even if a dataset is representative of the population of interest and is of sufficient quality, there are additional regulatory and practical issues related to the collection and use of data that we need to be aware of.</p>
<ul>
<li><p><strong><em>PII</em></strong>: It is not uncommon that datasets contain personally identifiable information (PII). Examples of such include name, Social Security number, address, photographs and bio-metric needs.</p>
<ul>
<li>Anonymous: Needs to comply with the pertinent laws since processing of data is still required.</li>
<li>Data Security: Ensure that personal data receives sufficient protection such as encryption and access restrictions</li>
<li>Terms of Use: Be well aware of all terms and conditions and the privacy policy related to the collection and use of data.</li>
</ul></li>
<li><p><strong>Variables with Legal/Ethical Concerns</strong>: Race, Gender, Ethnicity, Age, Income, Disability Status may be controversial variables that are a part of the dataset, and differential treatment based on these variables may lead to unfair “discrimination” and regulation violations.</p>
<p>Proxies of Prohibited is occupation, which can be strongly correlated with gender, and coal mine workers. If we use occupation as a predictor, then even though we are not feeding gender directly into our model, we are still using the information about the gender indirectly.</p></li>
<li><p><strong>Target Leakeage</strong>: In predictive modeling, target leakage refers to the phenomenon that some predictors in a model include (“leak”) information about the target variable <strong><em>that will not be available when the model is applied in practice</em></strong>. These predictors are typically strongly associated with the target variable, but their values are not known until or after the target variable is observed. Remember that our aim when doing predictive analytics is to use the other variables to predict the target variable <strong><em>before</em></strong> it is observed, so these “predictors” cannot serve as predictors in reality. If we include these variables in the model construction process, then our model will appear to perform extraordinarily well.</p>
<p>Examples of Target Leakage:</p>
<ul>
<li><p>Suppose you are interest in predicting whether or not a policyholder of an insurance policy will incur a loss or not in a future period (binary target variable). If the number of incurred losses is one of the predictors you use, then it appears that you will be able to make the perfect predictions: <em><strong>By definition, an incurred loss must have arisen if the number of incurred losses is one or more</strong>. The number of incurred losses simply would not be available at the time we predict the occurrence of incurred losses in practice.</em></p></li>
<li><p>An extreme form of target leakage that is commonly tested on the exam is when the target variable itself is included as a predictor, or is used to develop new variables (e.g., principal components) for predicting the same target variable.</p>
<p>Exercise 3.1.7. *&amp; (Detecting target leakage) Consider the persinj dataset in Chapter 2 again, and treat amt as the target variable. The data dictionary is reproduced below:</p>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>amt</code></td>
<td>Settled claim amount (continuous numeric variable)</td>
</tr>
<tr class="even">
<td><code>inj</code></td>
<td>Injury code, with seven levels: 1 (no injury), 2, 3, 4, 5, 6 (fatal), 9 (not recorded).</td>
</tr>
<tr class="odd">
<td><code>legrep</code></td>
<td>legal representation (0 = no, 1 = yes)</td>
</tr>
<tr class="even">
<td><code>op_time</code></td>
<td>Operational time (standardized amount of time elapsed between the when the injury was reported and the time when the claim was settled)</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: decimal">
<li>Identify a variable in the dataset that may pose the problem of target leakage.</li>
<li>Suggest how to retain the variable in part (a) for constructing meaningful predictive models for amt.</li>
</ol>
<p><strong>Solution.</strong></p>
<ol style="list-style-type: decimal">
<li>The <code>op_time</code> variable may pose the problem of target leakage when amt is the target variable. According to the data dictionary, the value of op_time would not be known until a claim was settled, at which time the value of amt would be observed. Due to this timing issue, <code>op_time</code> ma not serve as a predictor of <code>amt</code> in practice.</li>
<li>We can first build a predictive model for <code>op_time</code> based on the variables other than <code>amt</code> and then use a separate predictive model to predict the <code>amt</code> based on the predicted value of <code>op_time</code> and/or other variables.</li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
<div id="stage-3-exploratory-data-analysis" class="section level4 hasAnchor" number="3.1.2.3">
<h4><span class="header-section-number">3.1.2.3</span> Stage 3: Exploratory Data Analysis<a href="linear-models.html#stage-3-exploratory-data-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>After we have collected and validated the data, the next step is to perform <strong>Exploratory Data Analysis</strong>, which was discussed in Section @ref(2.2) with a focus on R programming and will further be illustrated in the case studies sections in the later part of this manual. The goals of exploratory data analysis are the same as those presented in Section @ref(2.2):</p>
<dl>
<dt><strong>Exploratory Data Analysis</strong></dt>
<dd>
<p>With the use of descriptive statistics and graphical displays, clean the data for incorrect, unreasonable, and inconsistent entries, and understand the characteristics of and the key relationships among variables in the data.</p>
<p>The observations we make may suggest an appropriate type of predictive model to use (e.g., GLMs vs. Decision Trees) and the best form for the predictors to enter the model.</p>
</dd>
</dl>
</div>
<div id="stage-4-model-construction-evaluation-and-selection-important" class="section level4 hasAnchor" number="3.1.2.4">
<h4><span class="header-section-number">3.1.2.4</span> Stage 4: Model Construction, Evaluation, and Selection [IMPORTANT!]<a href="linear-models.html#stage-4-model-construction-evaluation-and-selection-important" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Having defined the problem, collected some useful data, and taken a first look at the key variables, it is time for us to move onto the modelling phase and construct our predictive models in earnest.</p>
<div id="should-we-use-all-available-data-to-train-our-models" class="section level5 hasAnchor" number="3.1.2.4.1">
<h5><span class="header-section-number">3.1.2.4.1</span> <strong>Should we use all available data to train our models?</strong><a href="linear-models.html#should-we-use-all-available-data-to-train-our-models" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>You may be tempted to fit your predictive models directly to the whole set of data. Remember that one of the main goals when doing predictive modeling is to construct models that make good predictions. The fundamental question is is:</p>
<p>How do we go about designing a predictive model that performs well when it is applied to <strong><em>new, previously unseen</em></strong> data? In other words, how do we make sure that the model calibrated on <strong><em>past</em></strong> data excels in predicting <strong><em>future</em></strong> target values on the basis of <strong><em>future</em></strong> predictor values?</p>
<p>If we use all of the collected data for model fitting, that will leave no independent data for assessing the prediction performance of our models. It does not help much to evaluate the models on the same data on which they were built. After all, the models have seen those data and are not making genuine predictions. To ensure that our predictive models do a good job of describing the past data they have seen and, more importantly, prediction new, <em>future</em> observations, we need an unconventional way of leveraging our available data.</p>
</div>
<div id="training-test-set-split" class="section level5 hasAnchor" number="3.1.2.4.2">
<h5><span class="header-section-number">3.1.2.4.2</span> <strong>Training / Test Set Split</strong><a href="linear-models.html#training-test-set-split" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>To construct a model that thrives on future data, it is common practice in predictive analytics to partition our data into a few parts, each of which plays a different role in the model development and evaluation process.</p>
<p>The simplest way is to split the full data into two parts, the training set and the test set; see Figure <a href="#fig:figure-schematic-diagram"><strong>??</strong></a> for a schematic diagram.</p>
<div class="float" id="figure-schematic-diagram">
<img src="assets/images/figure-3-1-1.jpeg" alt="Figure 3.1.1: A schematic diagram of the training / test set split." />
<div class="figcaption"><strong>Figure 3.1.1:</strong> A schematic diagram of the training / test set split.</div>
</div>
<dl>
<dt><strong>Training Set</strong></dt>
<dd>
<p>The larger part of the full data (70-80%), the <em>training set</em>, or <em>training data</em>, is where you “train”, fit, or develop your predictive model to estimate the signal function <span class="math inline">\(f\)</span> and, if needed, the model parameters.</p>
<p>The training is typically done by optimizing a certain objective function that describes how well the model matches the training observations. The fitted model is denoted by <span class="math inline">\(\hat{f}\)</span> , where the hat emphasizes that it is an estimate of <span class="math inline">\(f\)</span>. After the model has been trained, it is ready for making predictions on the other part of the full data.</p>
</dd>
<dt><strong>Test Set</strong></dt>
<dd>
<p>Following the fitting, you will apply the trained model to make a prediction for each observation in the <em>test set</em>, or <em>test data</em>, and assess the prediction performance of the model according to certain performance metrics.</p>
<p>Observations in the test set <u><strong>did not participate in the model training process</strong></u> and will provide a much more objective ground for evaluating prediction performance when the model is applied to new, future data.</p>
<p>In contrast, evaluating the model on the training set will give an overly optimistic and somewhat misleading picture of its true predictive performance – the model has already seen the training observations and is merely fitting, not predicting those observations.</p>
</dd>
</dl>
<p><strong>How to Split the Data?</strong></p>
<p>There are many ways to do the training/test split.</p>
<ul>
<li>It can be done <strong><em>purely randomly</em></strong> according to pre-specified proportions,</li>
<li>Using special <strong><em>statistical techniques</em></strong> that ensure the distributions of the target variable in the two sets are comparable (stratified sampling).</li>
<li>If one of the variables is a <strong><em>time-variable</em></strong>, such as calendar year or month, and the behavior of the target variable over time is of interest, then one more way to make the split is on the basis of time, allocating older observations to the training set, and the more recent observations to the test set. Such “out-of-time” validation is conducted often for time series data, also known as longitudinal data, and is use for evaluating how well a model extrapolates time trends observed in the past to future periods.</li>
</ul>
<p><strong>How many observations should we assign to the two sets?</strong></p>
<p>The relative size of the training and test sets involves a trade-off:</p>
<ul>
<li>Having more training data will make for a more robust predictive model more capable of learning the patterns in the data and less susceptible to noise.</li>
<li>If too little data is set aside for the test set, however, the assessment of the prediction performance of the trained model on new, unseen observations will be less reliable.</li>
</ul>
<p><strong>How to use the training/test set split to rank competing models?</strong></p>
<p>If we have multiple candidate models, then we can perform the following steps:</p>
<ol style="list-style-type: decimal">
<li>Split the data into training / test sets..
<ul>
<li>The same training and test sets should be used across all candidate models.</li>
</ul></li>
<li>Fit the models to the training set.</li>
<li>Evaluate the quality of these models on the test set; and</li>
<li>Choose the one with the best test set performance according to a certain model selection criterion.</li>
</ol>
<p>When the “test set” above is for <em>selecting</em> the best model and is more commonly referred to as the <strong><em>validation set</em></strong>.</p>
<dl>
<dt><strong>Test /Validation Set</strong></dt>
<dd>
<p>In many predictive modeling textbooks, the test set is where we obtain an independent measure of the prediction performance of your <strong><em>chosen model</em></strong> <strong>when</strong> it is applied to data not involved in training or <strong><em>selecting</em></strong> the final model. The test set is held out until the end.</p>
<p>The usage in this manual conforms to what you will likely see in PA exam projects, where we are more concerned with finding the best predictive model and less with exactly how well it performs on independent data. There is usually no independent test data set aside for final evaluation.</p>
</dd>
</dl>
</div>
<div id="common-performance-metrics" class="section level5 hasAnchor" number="3.1.2.4.3">
<h5><span class="header-section-number">3.1.2.4.3</span> Common Performance Metrics<a href="linear-models.html#common-performance-metrics" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>After making the training / test set split and fitting the predictive model (to the training set), it is time for us to evaluate the performance of the model on the training set or test set with respect to an appropriate metric, which measures thee extent to which the model model matches the observations in the data.</p>
<p>This requires a <strong>loss function</strong>, which quantifies the discrepancy between the actual predicted values for each observation of the target variable mathematically. Here are the three most commonly used loss functions:</p>
<table>
<thead>
<tr class="header">
<th>Name</th>
<th>Loss Function</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Square Loss</td>
<td><span class="math inline">\(L(y_{i},\hat{y}_{i}) = (y_{i}-\hat{y}_{i})^2\)</span></td>
</tr>
<tr class="even">
<td>Absolute Loss</td>
<td><span class="math inline">\(L(y_{i},\hat{y}_{i}) = |y_{i}-\hat{y}_{i}|\)</span></td>
</tr>
<tr class="odd">
<td>Zero-one Loss</td>
<td><span class="math inline">\(L(y_{i},\hat{y}_{i}) = 1, if y &lt;&gt; \hat{y}_{i}\)</span></td>
</tr>
</tbody>
</table>
<p>Here, <span class="math inline">\(y_{i}\)</span> and <span class="math inline">\(\hat{y}_{i}\)</span> are respectively the observed and predicted values (produced by a predictive model) of the target variable for the ith observation in the data at hand. In each case, the loss function is the smallest when <span class="math inline">\(y_{i}\)</span> = <span class="math inline">\(\hat{y}_{i}\)</span> , and grows with the difference between <span class="math inline">\(y_{i}\)</span> and <span class="math inline">\(\hat{y}_{i}\)</span>.</p>
<p>The precise choice of the loss function depends closely on the nature of the target variable (numerical or categorical), or equivalently the nature of the prediction problem (regression or classification).</p>
<p><strong>Regression Problems:</strong> When the target variable is numeric, we can assess the performance of a model by looking at the size of the discrepancy between each observed value of the target variable and the corresponding predicted value, <span class="math inline">\(y_{i} - \hat{y}_{i}\)</span>. For a given observation, we call this discrepancy the <strong><em>residual</em></strong> if the observation is in the training set, and <strong><em>prediction error</em></strong> if the observation is in the test set. A commonly used metric that aggregates all such discrepancies is the square loss function <span class="math inline">\(L(y_{i},\hat{y}_{i}) = (y_{i}-\hat{y}_{i})^2\)</span> and provides an overall performance measure is the <strong>Root Mean Squared Error (RMSE),</strong> defined on the training and test sets as:</p>
<div class="float">
<img src="assets/images/03-figure-rsme-equation.png" alt="Equation: Root Mean Squared Error Equation" />
<div class="figcaption"><strong><em>Equation: Root Mean Squared Error Equation</em></strong></div>
</div>
<p>By design, the individual residuals or prediction errors are squared (so that +/i discrepancies will not cancel out), summed, and averaged, followed by taking a square root, to yield the RMSE.</p>
<p>The <strong><em>smaller</em></strong> the RMSE, the <strong><em>better</em></strong> the fit of the model to the training / test data.</p>
<ul>
<li><p><strong>Mean Squared Error (MSE):</strong> In your prior studies, you may have seen the concept of <strong>Mean Squared Error (MSE)</strong>, which is simply the square of the RMSE:</p>
<p><img src="assets/images/03-figure-mse-equation.png" /></p>
<p>Due to the square relations, whether you use RMSE or MSE does not really matter, but the advantage of the RMSE over the MSE is that the <strong>RMSE has the same unit as the target variable, making it easier to interpret</strong>.</p></li>
<li><p><strong>Mean Absolute Error (MAE):</strong> Instead of the square loss function, we could have used the absolute loss function <span class="math inline">\(L(y_{i},\hat{y}_{i}) = |y_{i}-\hat{y}_{i}|\)</span>, in which case the resulting metric is called the mean absolute error (MAE) or mean absolute derivation (MAD):</p>
<p><img src="assets/images/03-figure-mean-absolute-error.png" /></p>
<p>While the loss function places a much smaller weight on large loss than the square loss function and therefore makes the fitted model more robust against outliers, the square loss function is more frequently used i practice because it is differentiable and eases model fitting, which involves optimizing objective functions.</p></li>
<li><p><strong>Fitting vs. Evaluation:</strong> The loss function that defines the performance metric can be the same or different as the one that defines the objective function for training the model. We can for example, use the square loss function to estimate the model parameters (e.g., the method of least squares for linear models) and use the absolute loss function to measure the model performance.</p></li>
</ul>
<p><strong>Exercise 3.1.8 (Calculation of test RMSE)</strong></p>
<p>You have fitted a predictive model and applied it to the following test set with five observations:</p>
<table>
<caption><em><strong>Table:</strong> Test Set of Five Observations</em></caption>
<thead>
<tr class="header">
<th align="center">Observation Number (i)</th>
<th align="center"><span class="math inline">\(y_{i}\)</span></th>
<th align="center"><span class="math inline">\(\hat{y}_{i}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">2</td>
<td align="center">4</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">5</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">6</td>
<td align="center">9</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">8</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">4</td>
<td align="center">6</td>
</tr>
</tbody>
</table>
<p>Calculate the test RMSE and test MAE.</p>
<p><strong><em>Solution:</em></strong> The test RMSE is the square root of the average squared prediction error</p>
<p>Test RMSE = <span class="math inline">\([(1/5)*((2-4)^2 + (5-3)^2 + (6-9)^2 + (8-3)^2 + (4-6)^2)]^{1/2}\)</span> = <strong>3.0332</strong></p>
<p>Test MAE = <span class="math inline">\((1/5)*(|2-4| + |5-3| + |6-9)| + |8-3| + |4-6|)\)</span> = <strong>2.8</strong></p>
<p><strong>Classification Problems:</strong> For categorical target variables. the predictions are simply labels, or certain factor levels of the target variable, and they cannot be handled algebraically, so the difference may not be well-defined or may not make sense even if it is defined.</p>
<p>Instead of using the square loss or absolute loss function, we use the zero-one loss function (which is actually an indicator function) to come <span class="math inline">\(y_i\)</span> and <span class="math inline">\(\hat{y}_{i}\)</span> meaningfully:</p>
<p><img src="assets/images/03-classification-error-rate.png" /></p>
<p>Both RMSE and classification error rate are universal performance metrics that apply to general regression and classification problems, respectively. They can be computed on the training set as ewll as the test set, but as discussed above, we are mainly interested in these performance metrics on the test set, because they measure how well the model fits the test observations, or equivalently how well the model makes predictions on future, unseen data. The goodness of fit of the model to the training set is usually of secondary importance.</p>
<p>In the rest of this manual, we will use the generic term training error to mean the training RMSE or training classification error rate (depending on whether the problem is regression or classification), and test error to mean the test (R)MSE or test classification error rate, as long as there is no confusion.</p>
<p><strong>Cross Validation</strong></p>
<p>In predictive analytics, there is a remarkably useful and widely applicable technique, known as <strong>Cross Validation (CV)</strong>, that is an enhanced version of the training/test set split described above. The power of this technique is that it provides means to assess the prediction performance of a model <strong><em>without</em></strong> <strong><em>using using additional test data</em></strong>. In Exam PA, it also serves an important purpose:</p>
<dl>
<dt><strong>Purpose of Cross Validation</strong></dt>
<dd>
<p>To select the values of <em>hyper-parameters (tuning parameters)</em>, which are parameters that control some aspect of the fitting process itself.</p>
</dd>
</dl>
<p>As we mentioned above, model fitting typically involves optimizing a certain objective function, and hyper-parameters often play a role either in the mathematical expression of the objective function, or in the set of constraints defining the optimization problem.</p>
<p>We will encounter concrete examples of hyperparameters in the context of GLMs and Decision Trees in later chapters.</p>
<p>In fact, almost all predictive models in modern use contain one or more hyperparameters that serve as indices of model complexity and need to be tuned carefully to achieve optimal model performance, speaking to their importance in predictive analytics.</p>
<hr />
<p><strong>Example 3.1.9 (Which Types of are Hyperparameters?)</strong></p>
<p>An actuary is fitting the simple linear regression model <span class="math inline">\(Y = \beta_{0}+\beta_{1}X+\epsilon\)</span> to a set of training data <span class="math inline">\(n_{tr}\)</span> observations. The estimates of <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span> are determined by minimizing the function, where <span class="math inline">\(\lambda\)</span> is a given positive constant, for <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span> .</p>
<p>Determine which of the parameters is a hyperparameter.</p>
<p><strong>Solution:</strong> The estimates <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span> are output of the minimization problem above, while <span class="math inline">\(\lambda\)</span> is an input that goes into the minimization problem. Therefore, only <span class="math inline">\(\lambda\)</span> is a hyperparameter.</p>
<hr />
<p>The tricky part of hyperparameters is that we have to provided their values in advanced; they are not optimized as part of the model fitting algorithm, so it is impossible to select their values given the training set alone.</p>
<p>In theory, we can further divide the training data into two parts. One part for training the model for a given set of hyperparameters under consideration, and one part for evaluating the predictive performance of the model.</p>
<p>Then we select the combination of hyperparameters that gives rise to the best performance. In practice, this will reduce the size of the training set and undesirably undermine the reliability of the model development process.</p>
<p><strong>Cross Validation (CV)</strong> is an ingenious method for tuning hyperparameters without having to further divide the training set. Given the training set, CV (more formally called <strong><em>k-fold CV</em></strong>) works by performing a series of splits <em>repeatedly</em> across the dataset. The procedure is as follows:</p>
<ul>
<li><strong>Step 1:</strong> For a given positive integer <em>k</em>, randomly split the training data into <em>k</em> folds of approximately equal size. The value of <em>k</em> can range between 2 (smallest) and <span class="math inline">\(n_{tr}\)</span> (largest). A common choice for <em>k</em> in practice is 10, which is the default value in many model fitting functions in R.</li>
<li><strong>Step 2:</strong>
<ul>
<li><p>One of the <em>k</em> folds is left out and the predictive model is fitted to the remaining <em>k-1</em> folds. Then the fitted model is used to make a prediction for each observation in the left-out fold and a performance metric is computed on that fold. This is a valid estimate of the prediction performance of the model because observations in the excluded fold are not part of the model training process. In other words, they are something unseen by the model, and we are really making predictions.</p></li>
<li><p>Then repeat this process with each fold left out in turn to get <em>k</em> performance values, <span class="math inline">\(V_{1}, ...,V_{k}\)</span> (e.g., RMSE for a numeric target and classification error rate for a categorical target).</p></li>
<li><p>The overall prediction performance of the model can be estimated as the average of the <em>k</em> performance values, known as the <strong>CV error:</strong></p>
<p><span class="math display">\[
\fbox{CV error = (V_{1}+...+V_{k})/k}
\]</span></p></li>
</ul></li>
</ul>
<p>If we have a set of candidate hyperparameter values, then we can perform Step 2 above for each set of values under consideration and select the combination that produces the best model performance.</p>
<p>Then the model is fitted to the <strong><em>entire training set</em></strong> (i.e., the <em>k</em> folds together) using this optimal combination of hyperparameter values and evaluated on the test set.</p>
<p>In fact, CV is such a useful technique that it is automatically built into some of the model fitting algorithms such as regularization and decision trees for tuning model parameters for best performance.</p>
<hr />
<p><strong>Exercise 3.1.10 (Mechanics of <em>k</em>-fold CV)</strong></p>
<p>An actuary has a dataset with n = 50 observations and p = 22 predictors. He is using 10-fold cross-validation to select from a variety of available models.</p>
<p>Calculate the approximate number of observations used for the training models in each round of cross-validation procedure.</p>
<p><strong>Solution:</strong> 10-fold CV involves (randomly) dividing the data into 10-folds of approximately equal size, each with about 50/10 = 5 observations. In each round, one fold is left out and the other 9 folds, with approximately 9(5) = 45 observations, are used to train a model.</p>
<hr />
<p><strong>Selecting the Best Model</strong></p>
<p>After fitting each candidate model under consideration to the training set (possibly using CV to tune its hyperparameters) and evaluating its performance on the test set, it is time to select the model that is the “best” in a certain sense. Here are some important considerations that come into play in the selection of the best model:</p>
<ul>
<li><strong>Prediction Performance:</strong> Choosing the model with the best prediction performance is relatively easy and objective. All we have to do is <u><strong><em>pick the model with the smallest test-RMSE</em></strong></u> for a regression problem, or <u><strong><em>smallesttest classification error rate</em></strong></u> for a classification problem. We can also use alternative evaluation metrics that capture more specific aspects of prediction performance if appropriate.</li>
<li><strong>Interpretability:</strong> A model that makes good predictions is not always preferable, if it is like a black box and its end users have little idea what goes into the decision-making process. For the final model to earn trust from stakeholders with no expertise in predictive analytics, it should be reasonably interpretable, meaning that the model predictions should be easily explained in terms of the predictors and lead to specific actions or insights.</li>
<li><strong>Ease of Implementation:</strong> Other things equal, the easier for a model to be implemented (computationally, financially, or logistically), the better the model. If the model requires prohibitive resources to construct and maintain (e.g., it takes forever to fit the model, or it is costly to collect values of the necessary predictors), then its end users may not afford to use it in the first place, even if it makes superb predictions.</li>
</ul>
<p>As we will see in the case studies sections, it is not uncommon for prediction performance to be in conflict with interpretability and ease oimplementation, so the selection of the best model in practice almost always involves a compromise between these conflicting criteria, and the business problem can have quite a strong influence on the “final winner”.</p>
<ul>
<li><p>If the focus of the project you receive in Exam PA is on prediction, then it is worth selecting a model that produces good predictions of the target variable even if the model is rather non-transparent or costly to implement.</p></li>
<li><p>If interpretation is the primary concern, then it is natural to select a relatively simple, interpretable model that clearly shows the relationship between the target variable and the predictors. Using such a model, we can better understand the association between the two groups of variables and make inference about the underlying data-generating mechanism, thereby making better decisions. Its prediction performance is of secondary importance.</p></li>
</ul>
</div>
</div>
<div id="stage-5-model-validation" class="section level4 hasAnchor" number="3.1.2.5">
<h4><span class="header-section-number">3.1.2.5</span> Stage 5: Model Validation<a href="linear-models.html#stage-5-model-validation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>After coming up with a tentative model, which appears to be the best among all models you have constructed, we should not rush to recommend it to the client. Instead, we should <em>validate</em> it by inspecting it for any obvious deficiencies and ensuring that the assumptions behind the model are largely satisfied. If found, the deficiencies can be used to improve the specification of the model and we will go back to Stage 4. As mentioned at the beginning of this subsection, model building is often an iterative process.</p>
<p>There are different kinds of model validation techniques. They may be performed on either the training set or the test set, and they may be model-dependent in the sense that they are specific to particular types of predictive models.</p>
<ul>
<li><p><strong><em>Training Set:</em></strong> For GLMs, there is a set of model diagnostic tools to check the model assumptions based on the training set. We will learn these tools in Subsections 3.2.2 and 4.1.4.</p></li>
<li><p><strong><em>Test Set:</em></strong> A general model validation technique applicable to both GLMs and Decision Trees is to compare the predicted values and the observed values of the target variable on the test set. The comparison can be quantitative (summarized by a number) or graphical (in form of a plot). If we use graphical means and if the model works well, then the plot of the predicted against the observed values not only should fall on the 45-degree straight line passing through the origin quite closely, the deviation from the line should have no systematic patterns. Here are two example plots:</p>
<div class="float">
<img src="assets/images/03-model-validation.png" alt="Figure: Model Validation Graphs" />
<div class="figcaption">Figure: Model Validation Graphs</div>
</div></li>
</ul>
<p><strong>For this validation technique to be meaningful, it is vitally important that we compare the predicted values and the observed values on the test set, not the training set.</strong></p>
<p>If we perform the comparison on the training set, then we are only assessing the goodness-of-fit of the model to the training data, not its prediction performance on unseen data. A model may produce actual and “predicted” values on the training set that are in close agreement simply because it is a complex and over-fitted model.</p>
<p>Another validation technique used in some old past PA exams is to compare the selected model to an existing baseline model, again on the test set.</p>
<p>This model is usually a primitive model, such as an Ordinary Least Squares Linear Model (if the selected model is a GLM) or a model that has no predictors and simply uses the average of the target variable on the training set for prediction. The model will provide a benchmark which any selected model should beat as a minimum requirement.</p>
<p>After the selected model has been validated, it can be recommended to the client for their consideration and comments.</p>
</div>
<div id="stage-6-model-maintenance" class="section level4 hasAnchor" number="3.1.2.6">
<h4><span class="header-section-number">3.1.2.6</span> Stage 6: Model Maintenance<a href="linear-models.html#stage-6-model-maintenance" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>If the client gladly accepts the selected model, then we can put it to actual use and maintain it over time so that it remains useful in the future. Here are some of the steps we can take:</p>
<ul>
<li><p><strong>Adjust the Business Problem:</strong> At times, it may help to alter the business problem to take the following into account:</p>
<ul>
<li>A surprise discovery, e.g., a certain outcome turns out to be far more common or impactful than initially thought</li>
<li>Changes in external factors, e.g., market conditions, regulations that may cause initial assumptions to shift, and justify modifying the business problem to incorporate the new conditions.</li>
</ul></li>
<li><p><strong>Consult with Subject Matter Experts:</strong></p>
<ul>
<li>If there are new findings that do not fit your current understanding of the business problem or modeling issues that cannot be easily resolved purely on predictive analytics</li>
<li>To understand the limitations on what can reasonably be implemented.</li>
</ul></li>
<li><p><strong>Gather Additional Data:</strong></p>
<ul>
<li>Gather new observations and retrain the model to ensure that it will continue to be predictive in new environments, and to improve its robustness and prediction performance.</li>
<li>Gather new variables, or additional predictors.</li>
</ul></li>
<li><p><strong>Apply New Types of Models:</strong> Try new types of models with different strengths and weaknesses when new technology or implementation possibilities are available.</p></li>
<li><p><strong>Refine Existing Models:</strong> Try new combinations or transformations of predictors, different training/test splits, alternative hyperparameter values, performance metrics etc.</p></li>
<li><p><strong>Field Test Proposed Model:</strong> Implement the recommended model in the exact way it will be used to gain users’ confidence. This is particularly important when the business problem, data, or type of model is new.</p></li>
</ul>
</div>
</div>
<div id="bias-variance-trade-off" class="section level3 hasAnchor" number="3.1.3">
<h3><span class="header-section-number">3.1.3</span> Bias-Variance Trade-Off<a href="linear-models.html#bias-variance-trade-off" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This subsection and the next will delve into the model construction stage (Stage 4) more carefully and introduce, in a statistical framework, the technical considerations that go into designing a good predictive model.</p>
<p><strong>Key Idea: A complex model does not equal a good predictive model</strong></p>
<p>If you are just beginning to learn predictive analytics, you may be tempted to create a super sophisticated model with a huge number of predictors, some of which may be only marginally related to the target variable, in attempt to maximize the prediction performance of the model.</p>
<p>After all, you don’ want the model to miss any potentially useful information. To your surprise, such a complex model does not necessarily make good predictions, contrary to your original intention. As will be discussed in this subsection and substantiated in the rest of the manual, an extremely important mentality to keep in mind when doing predictive analytics is:</p>
<dl>
<dt>Imporatnt Mentality for Predictive Analytics</dt>
<dd>
<p>Complexity does <strong><em>not</em></strong> guarantee good prediction performance</p>
</dd>
</dl>
<p><strong>Goodness of fit vs. Prediction Accuracy</strong></p>
<p>While complexity does not correlate very well with prediction performance (measured by the test error), it is intimately related to the goodness of fit to the training data (measured by the training error). In other words, goodness of fit to the training data is not quite the same as prediction accuracy, and the two types of error behave very differently with complexity, as Figure 3.1.3 below shows:</p>
<p><img src="assets/images/03-figure-goodness-fit-prediction-performance.png" /></p>
<p>In terms of the training and test errors, we can describe the problems with a model that is either too simple or too complex using the following 2x2 table:</p>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th>Scenario</th>
<th>Small Test Error</th>
<th>Large Test Error</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Small Training Error</strong></td>
<td>Model is optimal</td>
<td>Model is overfitted</td>
</tr>
<tr class="even">
<td><strong>Large Training Error</strong></td>
<td>Check your code for errors, this is too good to be true and rarely happens in real life</td>
<td>Model is underfitted</td>
</tr>
</tbody>
</table>
<p>The two undesirable scenarios in the last column of the table, both involve having a large test error, deserve a separate discussion.</p>
<p><strong>Case 1: Underfitting</strong></p>
<p>In the left tail of Figure 3.1.3, the model is too simple to capture the training data effectively. Without learning enough about the signal of the data, an <strong><em>underfitted</em></strong> model matches both the training and test data poorly, and is marked by relatively large training error as well as a relatively large test error. This is akin to a lazy student barely studies (“underfitted”) and, not surprisingly, bombs their math test.</p>
<p><strong>Case 2: Overfitting</strong></p>
<p>In the right tail of Figure 3.1.3, the model, which is overwhelmingly complex, is overfitting the data. It is fitting the data too hard and goes to extraordinary lengths to capture:</p>
<ul>
<li>The signal, which represents general relationships between the target variable and predictors, applicable to both the trianing and test data.</li>
<li>The noise, which represents patterns that are just caused by random chance rather than by true, general properties of the unknown function <span class="math inline">\(f\)</span>. These patterns are specific to the training set (i.e., they do not exist in the test data), but are mistreated as if they were signal.</li>
</ul>
<hr />
<p><strong>Decomposition of the Expected Test Error</strong></p>
<p>To better understand the U-shape behavior that characterizes the test MSE, it is instructive to break it down into different components, and examine how each of these components behaves. Although such a decomposition is mainly of theoretical nature and you don’t often calculate the individual components of the formula in Exam PA, keeping the decomposition in mind will help you understand what it takes to produce good predictions. In particular, it reinforces the practically important idea that more complex models are not necessarily superior models.</p>
<p>For simplicity, we will consider a numeric target variable so that the <strong>(R)MSE</strong> is an appropriate performance metric (categorical target variables admit a similar decomposition).</p>
<p>For a given set of predictor values <span class="math inline">\(X_{0}\)</span>, the decomopsition reads:</p>
<p><img src="assets/images/03-expected-test-error-bias-variance.png" /></p>
</div>
<div id="feature-generation-and-selection" class="section level3 hasAnchor" number="3.1.4">
<h3><span class="header-section-number">3.1.4</span> Feature Generation and Selection<a href="linear-models.html#feature-generation-and-selection" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
</div>
<div id="linear-models-conceptual-foundation" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Linear Models: Conceptual Foundation<a href="linear-models.html#linear-models-conceptual-foundation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="model-formulation" class="section level3 hasAnchor" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Model Formulation<a href="linear-models.html#model-formulation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="model-equation" class="section level4 hasAnchor" number="3.2.1.1">
<h4><span class="header-section-number">3.2.1.1</span> Model Equation<a href="linear-models.html#model-equation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Target variable <span class="math inline">\(Y\)</span> is <strong>numeric</strong>.</li>
<li><span class="math inline">\(Y\)</span> is related to predictors <span class="math inline">\(X_1, X_2, \dots, X_p\)</span> via the approximately <strong>linear</strong> relationship</li>
</ul>
<p><span class="math display">\[
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p + \varepsilon.
\]</span></p>
<ul>
<li>Linear signal function <span class="math inline">\(f(X)\)</span>.</li>
</ul>
<div id="some-terms" class="section level5 hasAnchor" number="3.2.1.1.1">
<h5><span class="header-section-number">3.2.1.1.1</span> Some terms<a href="linear-models.html#some-terms" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li><span class="math inline">\(p = 1\)</span>: <a href="#">Simple linear regression model</a></li>
<li><span class="math inline">\(p \geq 2\)</span>: <a href="#">Multiple linear regression model</a></li>
<li><span class="math inline">\(\beta_0\)</span>: Intercept</li>
<li><span class="math inline">\(\beta_j\)</span>: Coefficient (or slope) of the <span class="math inline">\(j\)</span>th predictor</li>
</ul>
</div>
</div>
<div id="training-data-y_i-x_i1-x_i2-dots-x_ip_i1n_tr" class="section level4 hasAnchor" number="3.2.1.2">
<h4><span class="header-section-number">3.2.1.2</span> Training Data: <span class="math inline">\(\{(Y_i, X_{i1}, X_{i2}, \dots, X_{ip})\}_{i=1}^{n_{tr}}\)</span><a href="linear-models.html#training-data-y_i-x_i1-x_i2-dots-x_ip_i1n_tr" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Tabular (data frame) format</strong>:</li>
</ul>
<table style="width:100%;">
<colgroup>
<col width="38%" />
<col width="26%" />
<col width="35%" />
</colgroup>
<thead>
<tr class="header">
<th>Training Observation</th>
<th>Target <span class="math inline">\(Y\)</span></th>
<th>Predictors</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td><span class="math inline">\(Y\)</span></td>
<td><span class="math inline">\(X_1\)</span> <span class="math inline">\(X_2\)</span> … <span class="math inline">\(X_p\)</span></td>
</tr>
<tr class="even">
<td>1</td>
<td><span class="math inline">\(Y_1\)</span></td>
<td><span class="math inline">\(X_{11}\)</span> <span class="math inline">\(X_{12}\)</span> … <span class="math inline">\(X_{1p}\)</span></td>
</tr>
<tr class="odd">
<td>2</td>
<td><span class="math inline">\(Y_2\)</span></td>
<td><span class="math inline">\(X_{21}\)</span> <span class="math inline">\(X_{22}\)</span> … <span class="math inline">\(X_{2p}\)</span></td>
</tr>
<tr class="even">
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(n_{tr}\)</span></td>
<td><span class="math inline">\(Y_{n_{tr}}\)</span></td>
<td><span class="math inline">\(X_{n_{tr},1}\)</span> <span class="math inline">\(X_{n_{tr},2}\)</span> … <span class="math inline">\(X_{n_{tr},p}\)</span></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Equation format</strong>:</li>
</ul>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \dots + \beta_p X_{ip} + \varepsilon_i, \quad i = 1, \dots, n_{tr}
\]</span></p>
<ul>
<li><strong>A default assumption</strong>:</li>
</ul>
<p><span class="math display">\[
\varepsilon_i \sim \text{i.i.d. } N(0, \sigma^2)
\]</span></p>
</div>
<div id="model-quantities" class="section level4 hasAnchor" number="3.2.1.3">
<h4><span class="header-section-number">3.2.1.3</span> Model Quantities<a href="linear-models.html#model-quantities" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="on-the-training-set" class="section level5 hasAnchor" number="3.2.1.3.1">
<h5><span class="header-section-number">3.2.1.3.1</span> On the training set<a href="linear-models.html#on-the-training-set" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>Fitted value <span class="math inline">\(\hat{Y}_i = \beta_0 + \beta_1 X_1 + \cdots + \beta_p X_{ip}\)</span></li>
<li>Residual <span class="math inline">\(e_i = Y_i - \hat{Y}_i\)</span> (useful for “diagnosing” a linear model)</li>
<li>Residual SS (RSS): <span class="math inline">\(RSS = \sum_{i} e_i^2\)</span> (the lower, the better the fit to the training set)</li>
</ul>
</div>
<div id="on-the-test-set" class="section level5 hasAnchor" number="3.2.1.3.2">
<h5><span class="header-section-number">3.2.1.3.2</span> On the test set<a href="linear-models.html#on-the-test-set" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>Predicted value <span class="math inline">\(\hat{Y}^* = \beta_0 + \beta_1 X_1^* + \cdots + \beta_p X_p^*\)</span>, where <span class="math inline">\((1, X_1^*, \ldots, X_p^*)\)</span> is a vector of predictor values of interest.</li>
<li>Prediction error <span class="math inline">\(Y^* - \hat{Y}^*\)</span> (the lower, the more predictive the model)</li>
</ul>
</div>
</div>
<div id="model-quantities-cont." class="section level4 hasAnchor" number="3.2.1.4">
<h4><span class="header-section-number">3.2.1.4</span> Model Quantities (Cont.)<a href="linear-models.html#model-quantities-cont." class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="additional-quantities-computed-on-the-training-set" class="section level5 hasAnchor" number="3.2.1.4.1">
<h5><span class="header-section-number">3.2.1.4.1</span> Additional quantities computed on the training set<a href="linear-models.html#additional-quantities-computed-on-the-training-set" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li><strong>t-statistic</strong>: <span class="math inline">\(t(\hat{\beta_j}) = \frac{\hat{\beta_j}}{\text{standard error of } \hat{\beta_j}}\)</span>
<ul>
<li>Can be used to test the significance of <span class="math inline">\(X_j\)</span> in the presence of all other predictors.</li>
<li>The larger in magnitude, the more significant.</li>
</ul></li>
<li><strong>F-statistic</strong>
<ul>
<li>Can be used to assess the joint significance of all of the <span class="math inline">\(p\)</span> predictors, <span class="math inline">\(X_1, \ldots, X_p\)</span>.</li>
<li>The larger, the more significant (but it doesn’t tell which predictors are significant).</li>
</ul></li>
<li><strong>Coefficient of determination</strong>
<ul>
<li>On a scale from 0 to 1.</li>
<li>The larger, the better the fit to the training set.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="model-evaluation-and-validation" class="section level3 hasAnchor" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Model Evaluation and Validation<a href="linear-models.html#model-evaluation-and-validation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="general-performance-metric" class="section level4 hasAnchor" number="3.2.2.1">
<h4><span class="header-section-number">3.2.2.1</span> General Performance Metric<a href="linear-models.html#general-performance-metric" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><span class="math inline">\(Y\)</span> is numeric <span class="math inline">\(\Rightarrow\)</span> Test (R)MSE</li>
</ul>
<p><span class="math display">\[
\sqrt{\frac{1}{n_{\text{test}}} \sum_{i=1}^{n_{\text{test}}} (Y_i - \hat{Y}_i)^2}
\]</span></p>
<p>can be used.</p>
<div id="other-metrics-on-the-test-set" class="section level5 hasAnchor" number="3.2.2.1.1">
<h5><span class="header-section-number">3.2.2.1.1</span> Other metrics on the test set<a href="linear-models.html#other-metrics-on-the-test-set" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>Test <strong>loglikelihood</strong> (Exam STAM)</li>
<li>Test <strong>coefficient of determination</strong> <span class="math inline">\(R^2\)</span></li>
</ul>
</div>
<div id="all-of-them-are-equivalent-because" class="section level5 hasAnchor" number="3.2.2.1.2">
<h5><span class="header-section-number">3.2.2.1.2</span> All of them are equivalent because…<a href="linear-models.html#all-of-them-are-equivalent-because" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>They are all functions of</p>
<p><span class="math display">\[
\sum_{i=1}^{n_{\text{test}}} (Y_i - \hat{Y}_i)^2.
\]</span> #### Performance Metrics based on Penalized Likelihood</p>
<ul>
<li><p>Common structure: <strong>Model fit</strong> (ensures good fit) + <strong>Penalty measuring model complexity</strong> (prevents overfitting)</p></li>
<li><p><strong>Idea</strong>: To balance goodness of fit to the training data with model complexity<br />
</p></li>
<li><p><strong>Criterion</strong>: The smaller, the better the model</p></li>
</ul>
</div>
<div id="aic-akaike-information-criterion" class="section level5 hasAnchor" number="3.2.2.1.3">
<h5><span class="header-section-number">3.2.2.1.3</span> AIC (Akaike Information Criterion)<a href="linear-models.html#aic-akaike-information-criterion" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>Definition: <span class="math inline">\(\text{AIC} = -2l + 2p\)</span> <span class="math inline">\((p = \#\text{parameters})\)</span></li>
</ul>
</div>
<div id="bic-bayesian-information-criterion" class="section level5 hasAnchor" number="3.2.2.1.4">
<h5><span class="header-section-number">3.2.2.1.4</span> BIC (Bayesian Information Criterion)<a href="linear-models.html#bic-bayesian-information-criterion" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>Definition: <span class="math inline">\(\text{BIC} = -2l + p \ln n_{\text{tr}}\)</span></li>
<li>vs. AIC: A heavier penalty per parameter (<span class="math inline">\(\because \ln n_{\text{tr}} &gt; 2 \Leftrightarrow n_{\text{tr}} \geq 8\)</span>)</li>
</ul>
</div>
</div>
<div id="from-past-pa-exams" class="section level4 hasAnchor" number="3.2.2.2">
<h4><span class="header-section-number">3.2.2.2</span> From Past PA Exams<a href="linear-models.html#from-past-pa-exams" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="june-2019-task-6-select-features-using-aic-or-bic" class="section level5 hasAnchor" number="3.2.2.2.1">
<h5><span class="header-section-number">3.2.2.2.1</span> June 2019, Task 6: Select features using AIC or BIC<a href="linear-models.html#june-2019-task-6-select-features-using-aic-or-bic" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>AIC and BIC are among the available techniques for feature selection. Briefly <strong>describe</strong> them and outline the <strong>differences</strong> in the two criteria. Make a recommendation as to which one should be used for this problem.</p>
</div>
<div id="june-17-2020-task-7-select-features-using-stepwise-selection" class="section level5 hasAnchor" number="3.2.2.2.2">
<h5><span class="header-section-number">3.2.2.2.2</span> June 17, 2020, Task 7: Select features using stepwise selection<a href="linear-models.html#june-17-2020-task-7-select-features-using-stepwise-selection" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>When using the stepAIC function, there are two decisions to make: <strong>forward vs. backward</strong> and <strong>AIC vs. BIC</strong>. <strong>Describe</strong> each decision and the <strong>implications</strong> in choosing one option versus the other.</p>
</div>
</div>
<div id="model-diagnostics-based-on-residuals" class="section level4 hasAnchor" number="3.2.2.3">
<h4><span class="header-section-number">3.2.2.3</span> Model Diagnostics based on Residuals<a href="linear-models.html#model-diagnostics-based-on-residuals" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Recall the model assumption by default:</p>
<p><span class="math display">\[
\begin{cases}
Y = X \beta + \varepsilon \\
\varepsilon_i \sim \text{i.i.d. } N(0, \sigma^2)
\end{cases}
\Rightarrow
\begin{cases}
e_i \approx \text{i.i.d. } N(0, \sigma^2) \\
e_i \text{ have no systematic patterns}
\end{cases}
\]</span></p>
<div id="residual-analysis" class="section level5 hasAnchor" number="3.2.2.3.1">
<h5><span class="header-section-number">3.2.2.3.1</span> Residual analysis<a href="linear-models.html#residual-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>Do the residuals behave like this?
<ul>
<li>If <strong>yes</strong>, model looks good!</li>
<li>If <strong>no</strong>, try to <strong>improve the model</strong>!</li>
</ul></li>
</ul>
</div>
</div>
<div id="two-particularly-useful-plots-residuals-vs-fitted-plot" class="section level4 hasAnchor" number="3.2.2.4">
<h4><span class="header-section-number">3.2.2.4</span> Two Particularly Useful Plots: “Residuals vs Fitted” Plot<a href="linear-models.html#two-particularly-useful-plots-residuals-vs-fitted-plot" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>Uses</strong> - Check <strong>model specification</strong> (are the predictors entered properly?) - Check <strong>homogeneity</strong> of the error variance (<strong>homoscedasticity</strong>)</p>
<div id="good" class="section level5 unnumbered hasAnchor">
<h5>Good<a href="linear-models.html#good" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p><img src="assets/images/good_plot.png" alt="Good Residuals Plot" /> - No regular patterns - Same amount of variability</p>
</div>
<div id="bad" class="section level5 unnumbered hasAnchor">
<h5>Bad<a href="linear-models.html#bad" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p><img src="assets/images/bad_plot.png" alt="Bad Residuals Plot" /> - A clear funnel shape <span class="math inline">\(\Rightarrow\)</span> error variance increases with fitted value</p>
</div>
</div>
<div id="two-particularly-useful-plots-q-q-plot" class="section level4 hasAnchor" number="3.2.2.5">
<h4><span class="header-section-number">3.2.2.5</span> Two Particularly Useful Plots: Q-Q Plot<a href="linear-models.html#two-particularly-useful-plots-q-q-plot" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>What it is</strong>: Graphs the <strong>empirical quantiles</strong> of the standardized residuals against theoretical <span class="math inline">\(N(0, 1)\)</span> quantiles.</p>
<p><strong>Use</strong>: Check the <strong>normality</strong> of the random errors</p>
<div id="good-1" class="section level5 unnumbered hasAnchor">
<h5>Good<a href="linear-models.html#good-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p><img src="assets/images/good_qq_plot.png" alt="Good Q-Q Plot" /> - Points <strong>fall</strong> on 45° line closely</p>
</div>
<div id="bad-1" class="section level5 unnumbered hasAnchor">
<h5>Bad<a href="linear-models.html#bad-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p><img src="assets/images/bad_qq_plot.png" alt="Bad Q-Q Plot" /> - Points <strong>deviate</strong> from 45° line substantially</p>
</div>
</div>
</div>
<div id="feature-generation" class="section level3 hasAnchor" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Feature Generation<a href="linear-models.html#feature-generation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="big-picture" class="section level4 unnumbered hasAnchor">
<h4>Big Picture<a href="linear-models.html#big-picture" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>Given</strong>: A list of potentially useful predictors (given on the exam)</p>
<div id="practical-questions-to-be-addressed" class="section level5 unnumbered hasAnchor">
<h5>Practical questions to be addressed<a href="linear-models.html#practical-questions-to-be-addressed" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>How do we want these predictors to enter the model equation to achieve what effects?</li>
</ul>
<p><span class="math display">\[
Y = \beta_0 + \text{[how to fill in this part?]} + \varepsilon
\]</span></p>
<ul>
<li>How to handle <strong>categorical</strong> predictors in a linear model?</li>
</ul>
</div>
<div id="feature-generation-for-linear-models" class="section level5 unnumbered hasAnchor">
<h5>Feature generation for linear models<a href="linear-models.html#feature-generation-for-linear-models" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Generate <strong>new features</strong> to improve the <strong>flexibility</strong> of a linear model<br />
<span class="math inline">\(\Rightarrow\)</span> prediction accuracy <span class="math inline">\(\uparrow\)</span></p>
<hr />
</div>
</div>
<div id="numeric-predictors" class="section level4 hasAnchor" number="3.2.3.1">
<h4><span class="header-section-number">3.2.3.1</span> Numeric Predictors<a href="linear-models.html#numeric-predictors" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let <span class="math inline">\(X_j\)</span> be a numeric predictor.</p>
<div id="simplest-form-assign-a-single-regression-coefficient" class="section level5 unnumbered hasAnchor">
<h5>Simplest form: Assign a single regression coefficient<a href="linear-models.html#simplest-form-assign-a-single-regression-coefficient" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li><strong>Model equation</strong>:<br />
<span class="math display">\[
Y = \beta_0 + \dots + \beta_j X_j + \dots + \varepsilon
\]</span></li>
<li><strong>Interpretation</strong>:
<ul>
<li><span class="math inline">\(\beta_j = \frac{\partial \mathbb{E}[Y]}{\partial X_j}\)</span><br />
</li>
<li><span class="math inline">\(\beta_j\)</span> = the expected change in <span class="math inline">\(Y\)</span> <strong>per unit increase</strong> in <span class="math inline">\(X_j\)</span>, holding all other predictors fixed.</li>
</ul></li>
</ul>
</div>
<div id="polynomial-regression" class="section level5 unnumbered hasAnchor">
<h5>Polynomial regression<a href="linear-models.html#polynomial-regression" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li><strong>Motivation</strong>: To accommodate <strong>non-linear</strong> relationships between <span class="math inline">\(Y\)</span> (e.g., #pedestrians) and <span class="math inline">\(X_j\)</span> (hour)</li>
<li><strong>Model equation</strong>:<br />
<span class="math display">\[
Y = \beta_0 + \beta_1 X_j + \beta_2 X_j^2 + \dots + \beta_m X_j^m + \dots + \varepsilon
\]</span>
<ul>
<li><span class="math inline">\(\quad \quad \quad \quad \quad \quad \uparrow \quad \quad \quad \quad \quad \quad \quad \uparrow\)</span><br />
</li>
<li><span class="math inline">\(\quad \quad \quad\)</span> new features</li>
</ul></li>
<li><strong>Interpretation</strong>:
<ul>
<li><span class="math inline">\(\frac{\partial \mathbb{E}[Y]}{\partial X_j} = \beta_1 + 2\beta_2 X_j + \dots + m\beta_m X_j^{m-1}\)</span></li>
<li>Coefficients are <strong>harder to interpret!</strong></li>
</ul></li>
</ul>
<hr />
</div>
</div>
<div id="categorical-predictors" class="section level4 hasAnchor" number="3.2.3.2">
<h4><span class="header-section-number">3.2.3.2</span> Categorical Predictors<a href="linear-models.html#categorical-predictors" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="binarization" class="section level5 unnumbered hasAnchor">
<h5>Binarization<a href="linear-models.html#binarization" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Can we assign a regression coefficient directly to a categorical predictor?</p>
<p>For Smoking = <span class="math display">\[
\begin{cases}
\text{Smoker} \\
\text{Non-smoker} \\
\text{Unknown}
\end{cases}
\]</span> can we use <span class="math inline">\(Y = \beta_0 + \beta_1 \times \text{Smoking} + \varepsilon\)</span>?</p>
<p>No! Because <span class="math inline">\(\beta_1 \times \text{Smoker}\)</span>, <span class="math inline">\(\beta_1 \times \text{Non-smoker}\)</span>, and <span class="math inline">\(\beta_1 \times \text{Unknown}\)</span> don’t make sense!</p>
</div>
<div id="need-an-extra-operation-binarization" class="section level5 unnumbered hasAnchor">
<h5>Need an extra operation: Binarization<a href="linear-models.html#need-an-extra-operation-binarization" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>A <strong>categorical predictor</strong> <span class="math inline">\(\rightarrow\)</span> A collection of <strong>binary/dummy/indicator variables</strong> indicating one and only one level (= 1 for that level, = 0 otherwise)</p>
<p>Dummy variables are numeric <span class="math inline">\(\Rightarrow\)</span> we can enter them directly in model equation.</p>
<hr />
</div>
<div id="illustrative-example-smoking" class="section level5 unnumbered hasAnchor">
<h5>Illustrative Example: Smoking<a href="linear-models.html#illustrative-example-smoking" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<div id="dummy-variables" class="section level6 unnumbered hasAnchor">
<h6>3 dummy variables<a href="linear-models.html#dummy-variables" class="anchor-section" aria-label="Anchor link to header"></a></h6>
<table>
<colgroup>
<col width="26%" />
<col width="22%" />
<col width="27%" />
<col width="23%" />
</colgroup>
<thead>
<tr class="header">
<th>Level of Smoking</th>
<th>SmokingSmoker</th>
<th>SmokingNon-smoker</th>
<th>SmokingUnknown</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Smoker</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>Non-smoker</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="odd">
<td>Unknown</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
</div>
<div id="sample-dataset" class="section level6 unnumbered hasAnchor">
<h6>Sample dataset<a href="linear-models.html#sample-dataset" class="anchor-section" aria-label="Anchor link to header"></a></h6>
<table>
<colgroup>
<col width="8%" />
<col width="17%" />
<col width="22%" />
<col width="27%" />
<col width="23%" />
</colgroup>
<thead>
<tr class="header">
<th>Obs.</th>
<th>Smoking</th>
<th>SmokingSmoker</th>
<th>SmokingNon-smoker</th>
<th>SmokingUnknown</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Smoker</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>2</td>
<td>Unknown</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<td>3</td>
<td>Non-smoker</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td>4</td>
<td>Smoker</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<hr />
</div>
</div>
<div id="illustrative-example-smoking-cont." class="section level5 unnumbered hasAnchor">
<h5>Illustrative Example: Smoking (Cont.)<a href="linear-models.html#illustrative-example-smoking-cont." class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Possible model configurations:</p>
<p><span class="math display">\[
Y = \beta_0 + \beta_1 \times \text{SmokingSmoker} + \beta_2 \times \text{SmokingUnknown} + \varepsilon
\]</span> <span class="math display">\[
Y = \beta_0 + \beta_1 \times \text{SmokingNon-smoker} + \beta_2 \times \text{SmokingUnknown} + \varepsilon
\]</span> <span class="math display">\[
Y = \beta_0 + \beta_1 \times \text{SmokingSmoker} + \beta_2 \times \text{SmokingNon-smoker} + \varepsilon
\]</span></p>
<p><strong>Question</strong>: Why not use all three dummy variables?</p>
<ul>
<li><strong>Intuitively</strong>: When two of them are known, the third brings <strong>no additional information</strong>.</li>
<li><strong>Technically</strong>: Including all three results in <strong>perfect collinearity</strong> and a <strong>rank-deficient model</strong>.</li>
</ul>
<p><strong>General rule for a linear model</strong>:<br />
A categorical predictor with <span class="math inline">\(k\)</span> levels should be represented by <span class="math inline">\(k - 1\)</span> binary variables.<br />
Left out level = <strong>baseline level</strong>.</p>
<hr />
</div>
<div id="baseline-level" class="section level5 unnumbered hasAnchor">
<h5>Baseline Level<a href="linear-models.html#baseline-level" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li><strong>R’s default</strong>: The first level in <strong>alpha-numerical order</strong> (e.g., “Non-smoker” for smoking)<br />
</li>
<li><strong>Common practice</strong>: The <strong>most common</strong> (populous) level</li>
</ul>
<div id="interpretation-of-regression-coefficients" class="section level6 unnumbered hasAnchor">
<h6>Interpretation of regression coefficients<a href="linear-models.html#interpretation-of-regression-coefficients" class="anchor-section" aria-label="Anchor link to header"></a></h6>
<p>Consider <span class="math display">\[
\mathbb{E}[Y] = \beta_0 + (\beta_1 D_1 + \dots + \beta_j D_j + \dots + \beta_{k-1} D_{k-1}) + \dots
\]</span> where this represents a <span class="math inline">\(k\)</span>-level categorical predictor.</p>
<ul>
<li>In <span class="math inline">\(j\)</span>th level: <span class="math inline">\(\mathbb{E}[Y] = \beta_0 + \beta_j (1)\)</span></li>
<li>In baseline level: <span class="math inline">\(\mathbb{E}[Y] = \beta_0\)</span></li>
<li><strong>Interpretation</strong>: <span class="math inline">\(\beta_j = \mathbb{E}[Y]\)</span> at <span class="math inline">\(j\)</span>th level <span class="math inline">\(- \mathbb{E}[Y]\)</span> at baseline level.</li>
</ul>
<p>The <span class="math inline">\(\beta_j\)</span>’s measure how much the target mean changes over different factor levels compared to the baseline. <strong>They are not change in the target mean per unit change in the dummy variables</strong>.</p>
<hr />
</div>
</div>
</div>
<div id="what-is-interaction" class="section level4 hasAnchor" number="3.2.3.3">
<h4><span class="header-section-number">3.2.3.3</span> What is Interaction?<a href="linear-models.html#what-is-interaction" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Restriction</strong>: In the basic model form, <span class="math inline">\(Y = \beta_0 + \beta_1 X_1 + \dots + \beta_p X_p + \varepsilon\)</span>, the expected effect of each <span class="math inline">\(X_j\)</span> on <span class="math inline">\(Y\)</span> is <strong>independent</strong> of the values of other predictors.</li>
</ul>
<div id="interesting-example-from-introduction-to-statistical-learning" class="section level5 unnumbered hasAnchor">
<h5>Interesting example from <em>Introduction to Statistical Learning</em><a href="linear-models.html#interesting-example-from-introduction-to-statistical-learning" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li><span class="math inline">\(Y\)</span> = number of units produced in a factory</li>
<li><span class="math inline">\(X_1\)</span> = number of production lines in the factory</li>
<li><span class="math inline">\(X_2\)</span> = number of workers in the factory</li>
</ul>
<p><strong>Observation</strong>: The effect of <span class="math inline">\(X_1\)</span> on <span class="math inline">\(\mathbb{E}[Y]\)</span> is likely to <strong>depend on</strong> <span class="math inline">\(X_2\)</span>.</p>
<p><strong>Reason</strong>: If <span class="math inline">\(X_2 = 0\)</span>, then increasing <span class="math inline">\(X_1\)</span> will not raise <span class="math inline">\(Y\)</span> much. (No one is working!)</p>
<p><strong>Interaction</strong>: When the effect of one predictor on the target variable <strong>depends on</strong> the value/level of another predictor.</p>
<p><strong>Suggestion</strong>: Consider <span class="math inline">\(\mathbb{E}[Y] = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_1 X_2\)</span>.</p>
<ul>
<li><strong>Note</strong>:<br />
<span class="math inline">\(\mathbb{E}[Y] = \beta_0 + (\beta_1 + \beta_3 X_2) X_1 + \beta_2 X_2 = \beta_0 + \beta_1 X_1 + (\beta_2 + \beta_3 X_1) X_2\)</span>
<ul>
<li>Here, <span class="math inline">\((\beta_1 + \beta_3 X_2)\)</span> <strong>depends on</strong> <span class="math inline">\(X_2\)</span><br />
</li>
<li>Similarly, <span class="math inline">\((\beta_2 + \beta_3 X_1)\)</span> <strong>depends on</strong> <span class="math inline">\(X_1\)</span></li>
</ul></li>
<li><span class="math inline">\(X_1 X_2\)</span> is the <strong>interaction term</strong>.</li>
</ul>
<hr />
</div>
</div>
<div id="interactions-between-continuous-and-categorical-predictors" class="section level4 unnumbered hasAnchor">
<h4>Interactions between Continuous and Categorical Predictors<a href="linear-models.html#interactions-between-continuous-and-categorical-predictors" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="model-equation-1" class="section level5 unnumbered hasAnchor">
<h5>Model equation:<a href="linear-models.html#model-equation-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p><span class="math display">\[
\mathbb{E}[Y] = \beta_0 + \beta_1 X_1 \text{ (continuous)} + \beta_2 X_2 \text{ (binary)} + \beta_3 X_1 X_2
\]</span></p>
<p><span class="math display">\[
=
\begin{cases}
\beta_0 + \beta_1 X_1, &amp; \text{if } X_2 = 0, \\
(\beta_0 + \beta_2) + (\beta_1 + \beta_3) X_1, &amp; \text{if } X_2 = 1.
\end{cases}
\]</span></p>
</div>
<div id="graphical-illustration-of-interaction" class="section level5 unnumbered hasAnchor">
<h5><strong>Graphical Illustration of Interaction</strong><a href="linear-models.html#graphical-illustration-of-interaction" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<div class="float">
<img src="assets/images/interaction_plot.png" alt="Graphical illustration" />
<div class="figcaption">Graphical illustration</div>
</div>
<p>Breakdown of Graph: - If <span class="math inline">\(X_2 = 0\)</span>: Slope = <span class="math inline">\(\beta_1\)</span>, Intercept = <span class="math inline">\(\beta_0\)</span> - If <span class="math inline">\(X_2 = 1\)</span>: Slope = <span class="math inline">\(\beta_1 + \beta_3\)</span>, Intercept = <span class="math inline">\(\beta_0 + \beta_2\)</span></p>
<ul>
<li><strong>Different intercepts</strong> due to <span class="math inline">\(\beta_2 X_2\)</span></li>
<li><strong>Different slopes</strong> due to <span class="math inline">\(\beta_3 X_1 X_2\)</span><br />
<span class="math inline">\(\Rightarrow\)</span> <strong>interaction effect</strong></li>
</ul>
<hr />
</div>
</div>
<div id="interactions-between-two-categorical-predictors" class="section level4 unnumbered hasAnchor">
<h4>Interactions between Two Categorical Predictors<a href="linear-models.html#interactions-between-two-categorical-predictors" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="model-equation-2" class="section level5 unnumbered hasAnchor">
<h5>Model equation:<a href="linear-models.html#model-equation-2" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p><span class="math display">\[
\mathbb{E}[Y] = \beta_0 + \beta_1 X_1 \text{ (binary)} + \beta_2 X_2 \text{ (binary)} + \beta_3 X_1 X_2
\]</span></p>
<div class="float">
<img src="assets/images/interactions-two-categorical-predictors.png" alt="Four Different Target Means" />
<div class="figcaption">Four Different Target Means</div>
</div>
<hr />
</div>
</div>
</div>
<div id="feature-selection" class="section level3 hasAnchor" number="3.2.4">
<h3><span class="header-section-number">3.2.4</span> Feature Selection<a href="linear-models.html#feature-selection" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<hr />
<div id="featuremodel-selection-big-picture" class="section level4 unnumbered hasAnchor">
<h4>Feature/Model Selection: Big Picture<a href="linear-models.html#featuremodel-selection-big-picture" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p><strong>Given</strong>: A full linear model of <span class="math inline">\(p\)</span> (potentially useful) features: <span class="math display">\[
Y = \beta_0 + \beta_1 X_1 + \dots + \beta_p X_p + \varepsilon.
\]</span></p></li>
<li><p><strong>Task</strong>: Select the <strong>really useful</strong> features, i.e., <span class="math display">\[
Y = \text{?} + \varepsilon.
\]</span></p></li>
<li><p><strong>Motivation</strong>:<br />
Remove features with limited predictive power<br />
<span class="math inline">\(\Downarrow\)</span><br />
Prevent overfitting and <strong>simplify model</strong></p></li>
</ul>
<div id="naive-suggestion" class="section level5 unnumbered hasAnchor">
<h5>Naive suggestion<a href="linear-models.html#naive-suggestion" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>Fit the full model and drop all insignificant features at once.</li>
</ul>
</div>
<div id="caveat" class="section level5 unnumbered hasAnchor">
<h5>Caveat<a href="linear-models.html#caveat" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>Absence of one feature can affect the significance of other features.</li>
</ul>
<hr />
</div>
</div>
<div id="best-subset-selection" class="section level4 unnumbered hasAnchor">
<h4>Best Subset Selection<a href="linear-models.html#best-subset-selection" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="idea" class="section level5 unnumbered hasAnchor">
<h5><strong>Idea</strong><a href="linear-models.html#idea" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>Fit all possible <span class="math inline">\(2^p\)</span> linear models constructed from the <span class="math inline">\(p\)</span> features</li>
<li>Choose the <strong>“best subset”</strong> of predictors (w.r.t. AIC, BIC, etc.) to form the best model</li>
</ul>
</div>
<div id="merits" class="section level5 unnumbered hasAnchor">
<h5><strong>Merits</strong><a href="linear-models.html#merits" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>Conceptually simple</li>
<li>Screens all <span class="math inline">\(2^p\)</span> models</li>
</ul>
</div>
<div id="demerits" class="section level5 unnumbered hasAnchor">
<h5><strong>Demerits</strong><a href="linear-models.html#demerits" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li><strong>Computationally prohibitive</strong>; generally not feasible when <span class="math inline">\(p \geq 10\)</span><br />
(Note: <span class="math inline">\(2^{10} = 1,024\)</span>, <span class="math inline">\(2^{20} = 1,048,576\)</span>!!)</li>
</ul>
</div>
<div id="need-more-efficient-feature-selection-methods" class="section level5 unnumbered hasAnchor">
<h5><strong>Need more efficient feature selection methods!</strong><a href="linear-models.html#need-more-efficient-feature-selection-methods" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li><strong>More efficient solution</strong>: Stepwise selection<br />
To look at a <strong>restricted subset</strong> of all possible models.</li>
</ul>
<hr />
</div>
</div>
<div id="stepwise-selection-algorithms" class="section level4 hasAnchor" number="3.2.4.1">
<h4><span class="header-section-number">3.2.4.1</span> Stepwise Selection Algorithms<a href="linear-models.html#stepwise-selection-algorithms" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<dl>
<dt><strong>Backward Stepwise Selection</strong></dt>
<dd>
<p>Start with a <strong>full model</strong> with all <span class="math inline">\(p\)</span> features</p>
<p><span class="math inline">\(\downarrow\)</span> Go Backward</p>
<p><strong>Drop</strong>, one at a time, the feature to improve the model the most w.r.t. AIC or BIC</p>
<p><span class="math inline">\(\downarrow\)</span> Repeat until</p>
<p>Stop when no features can be <strong>dropped</strong> to improve the model.</p>
</dd>
<dt><strong>Forward Stepwise Selection</strong></dt>
<dd>
<p>Start with a <strong>intercept-only</strong> model (<span class="math inline">\(Y=\beta_0+\epsilon\)</span>)</p>
<p><span class="math inline">\(\downarrow\)</span> Go Forward</p>
<p><strong>Add</strong>, one at a time, the feature to improve the model the most w.r.t. AIC or BIC</p>
<p><span class="math inline">\(\downarrow\)</span> Repeat until</p>
<p>Stop when no features can be <strong>added</strong> to improve the model.</p>
</dd>
</dl>
<hr />
</div>
<div id="discussion" class="section level4 unnumbered hasAnchor">
<h4><strong>Discussion</strong><a href="linear-models.html#discussion" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Backward</strong>: Once dropped, the feature will be gone forever<br />
</li>
<li><strong>Forward</strong>: Once added, the feature will stay forever<br />
</li>
<li><strong>Max. # models fitted</strong>: <span class="math display">\[
1 + \frac{p(p+1)}{2} \quad (p=20 \Rightarrow 211, \text{ vs. } 2^{20} &gt; 1 \text{ million})
\]</span></li>
<li><strong>Drawback</strong>: No guarantee final model is best</li>
</ul>
<div id="two-important-decisions-selection-criterion-and-selection-process" class="section level5 unnumbered hasAnchor">
<h5><strong>Two important decisions: Selection criterion and selection process</strong><a href="linear-models.html#two-important-decisions-selection-criterion-and-selection-process" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<div id="aicbic" class="section level6 unnumbered hasAnchor">
<h6><strong>AIC/BIC</strong><a href="linear-models.html#aicbic" class="anchor-section" aria-label="Anchor link to header"></a></h6>
<ul>
<li>Prefer a <strong>simpler model</strong> <span class="math inline">\(\Rightarrow\)</span> BIC (<strong>more conservative</strong>)</li>
<li>Don’t want to miss important predictors <span class="math inline">\(\Rightarrow\)</span> AIC</li>
<li>No universally superior choice; <strong>keep business problem in mind</strong> (key!)</li>
</ul>
</div>
<div id="backwardforward" class="section level6 unnumbered hasAnchor">
<h6><strong>Backward/Forward</strong><a href="linear-models.html#backwardforward" class="anchor-section" aria-label="Anchor link to header"></a></h6>
<ul>
<li><strong>Forward selection</strong> tends to produce a <strong>simpler model</strong>.</li>
<li><strong>Backward selection</strong> tends to produce a more <strong>complex model</strong>.</li>
<li>Again, no universally superior choice</li>
</ul>
<hr />
</div>
</div>
</div>
</div>
<div id="regularization" class="section level3 hasAnchor" number="3.2.5">
<h3><span class="header-section-number">3.2.5</span> Regularization<a href="linear-models.html#regularization" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="how-does-regularization-a.k.a.-shrinkage-work" class="section level4 unnumbered hasAnchor">
<h4><strong>How Does Regularization (a.k.a. Shrinkage) Work?</strong><a href="linear-models.html#how-does-regularization-a.k.a.-shrinkage-work" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="stepwise-selection" class="section level5 unnumbered hasAnchor">
<h5><strong>Stepwise Selection</strong><a href="linear-models.html#stepwise-selection" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>Search through a <strong>list</strong> of candidate models <span class="math inline">\(\rightarrow\)</span> final model</li>
<li>Set <span class="math inline">\(\beta_j = 0\)</span> for non-predictive features in full model</li>
</ul>
</div>
<div id="regularization-1" class="section level5 unnumbered hasAnchor">
<h5><strong>Regularization</strong><a href="linear-models.html#regularization-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>Fit a <strong>single model</strong> with all <span class="math inline">\(p\)</span> features using a “special technique”</li>
<li><span class="math inline">\(\beta_j \approx 0\)</span> for non-predictive features <span class="math inline">\(\Rightarrow\)</span> smaller effect on target</li>
</ul>
</div>
<div id="ordinary-least-squares-ols" class="section level5 unnumbered hasAnchor">
<h5><strong>Ordinary Least Squares (OLS)</strong><a href="linear-models.html#ordinary-least-squares-ols" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p><span class="math display">\[
\min_{\beta_0, \beta_1, \dots, \beta_p} \sum_{i=1}^{n_{tr}} \left[ Y_i - \left( \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \dots + \beta_p X_{ip} \right) \right]^2
\]</span> - <strong>RSS</strong> (Residual Sum of Squares)</p>
</div>
<div id="loss-penalty-formulation" class="section level5 unnumbered hasAnchor">
<h5><strong>Loss + Penalty Formulation</strong><a href="linear-models.html#loss-penalty-formulation" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p><span class="math display">\[
\min_{\beta_0, \beta_1, \dots, \beta_p} \text{RSS} + \lambda f_R(\beta)
\]</span></p>
<p><strong>Where:</strong></p>
<ul>
<li><span class="math inline">\(\lambda\)</span>: <strong>Regularization parameter</strong>; the larger, the heavier the regularization</li>
<li><span class="math inline">\(f_R(\cdot)\)</span>: <strong>Penalty function</strong>; reflects the size of slope coefficients</li>
<li>Adds a <strong>regularization penalty</strong> to the loss function</li>
</ul>
<p><span class="math inline">\(Idea\)</span><strong>: Make a Trade-Off Between:</strong></p>
<ul>
<li><strong>Goodness-of-Fit to Training Data</strong> (captured by <strong>RSS</strong>): Smaller <span class="math inline">\(\rightarrow\)</span> Better -</li>
<li><strong>Model Complexity</strong> (captured by <strong>Regularization Penalty</strong>): Smaller <span class="math inline">\(\rightarrow\)</span> Better</li>
</ul>
<hr />
</div>
</div>
<div id="how-does-regularization-a.k.a.-shrinkage-work-cont." class="section level4 unnumbered hasAnchor">
<h4><strong>How does Regularization (a.k.a. Shrinkage) Work? (Cont.)</strong><a href="linear-models.html#how-does-regularization-a.k.a.-shrinkage-work-cont." class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Objective function</strong>: <span class="math inline">\(\text{RSS} + \lambda f_R(\beta)\)</span></li>
<li><strong>Output</strong>: A <strong>family</strong> of coefficient estimates <span class="math inline">\(\{\hat{\beta}_\lambda = (\hat{\beta}_{0,\lambda}, \hat{\beta}_{1,\lambda}, \dots, \hat{\beta}_{p,\lambda}) : \lambda \geq 0\}\)</span></li>
</ul>
<div id="effects-of-lambda-bias-variance-trade-off-again" class="section level5 unnumbered hasAnchor">
<h5><strong>Effects of</strong> <span class="math inline">\(\lambda\)</span> (Bias-Variance Trade-Off Again!)<a href="linear-models.html#effects-of-lambda-bias-variance-trade-off-again" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li><strong>Case 1</strong>: When <span class="math inline">\(\lambda = 0\)</span>, coefficient estimates = ordinary least squares estimates.</li>
<li><strong>Case 2</strong>: <span class="math inline">\(\lambda \uparrow \Rightarrow |\hat{\beta}_{j,\lambda}| \downarrow \Rightarrow\)</span> flexibility <span class="math inline">\(\downarrow\)</span>
<ul>
<li>Bias<span class="math inline">\(^2\)</span> <span class="math inline">\(\uparrow\)</span></li>
<li>Variance <span class="math inline">\(\downarrow\)</span></li>
<li><strong>Hopefully</strong> <span class="math inline">\(\Rightarrow\)</span> prediction performance <span class="math inline">\(\uparrow\)</span></li>
</ul></li>
<li><strong>Case 3</strong>: When <span class="math inline">\(\lambda \to \infty\)</span>, <span class="math inline">\(\hat{\beta}_{j,\lambda} \to 0\)</span> for all <span class="math inline">\(j = 1, \dots, p\)</span> (intercept-only model).</li>
</ul>
</div>
<div id="different-indexes-of-model-complexity" class="section level5 unnumbered hasAnchor">
<h5><strong>Different Indexes of Model Complexity</strong><a href="linear-models.html#different-indexes-of-model-complexity" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li><strong>Stepwise selection</strong>: <span class="math inline">\(p\)</span> (# features)</li>
<li><strong>Regularization</strong>: <span class="math inline">\(\lambda\)</span></li>
</ul>
<hr />
</div>
</div>
<div id="different-choices-of-f_rbeta-penalty-function" class="section level4 unnumbered hasAnchor">
<h4><strong>Different Choices of</strong> <span class="math inline">\(f_R(\beta)\)</span> (Penalty Function)<a href="linear-models.html#different-choices-of-f_rbeta-penalty-function" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Ridge Regression</strong>: <span class="math inline">\(f_R(\beta) = \sum_{j=1}^{p} \beta_j^2\)</span></li>
<li><strong>Lasso</strong>: <span class="math inline">\(f_R(\beta) = \sum_{j=1}^{p} |\beta_j|\)</span></li>
<li><strong>Elastic Net</strong>: <span class="math inline">\(f_R(\beta) = (1 - \alpha) \sum_{j=1}^{p} \beta_j^2 + \alpha \sum_{j=1}^{p} |\beta_j|\)</span>
<ul>
<li><span class="math inline">\(\alpha \in [0, 1]\)</span> is the mixing coefficient</li>
<li><span class="math inline">\(\alpha = 0\)</span>: Ridge regression</li>
<li><span class="math inline">\(\alpha = 1\)</span>: Lasso</li>
</ul></li>
</ul>
<div id="feature-selection-property-of-elastic-net" class="section level5 unnumbered hasAnchor">
<h5><strong>Feature Selection Property of Elastic Net</strong><a href="linear-models.html#feature-selection-property-of-elastic-net" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>For lasso (and elastic net with <span class="math inline">\(\alpha \neq 0\)</span>):
<ul>
<li><span class="math inline">\(\lambda\)</span> large enough <span class="math inline">\(\Rightarrow\)</span> some <span class="math inline">\(\hat{\beta}_{j,\lambda} = 0\)</span> exactly <span class="math inline">\(\Rightarrow\)</span>
<ul>
<li><strong>features dropped</strong></li>
<li><strong>model simplified!</strong></li>
</ul></li>
</ul></li>
</ul>
<p><strong>Note:</strong> Ridge regression never drops the features entirely. If the business problem wants you to identify the key factors effecting the target variable, then it makes sense to use the lasso or elastic net with a positive <span class="math inline">\(\alpha\)</span> so that your model will drop the features with limited predictive power and become easier to interpret.</p>
<hr />
</div>
</div>
<div id="hyperparameter-tuning" class="section level4 unnumbered hasAnchor">
<h4><strong>Hyperparameter Tuning</strong><a href="linear-models.html#hyperparameter-tuning" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\alpha\)</span> are hyperparameters, so they are not determined as part of the optimization procedure.</p>
<div id="tuning-lambda-and-alpha-by-cv" class="section level5 unnumbered hasAnchor">
<h5><strong>Tuning</strong> <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\alpha\)</span> by CV<a href="linear-models.html#tuning-lambda-and-alpha-by-cv" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>Divide training data into <span class="math inline">\(k\)</span> folds (e.g., <span class="math inline">\(k = 10\)</span>).</li>
<li>For each pair of candidate values of <span class="math inline">\((\lambda, \alpha)\)</span>, train the model on all but one fold and measure performance on the left-out fold.
<ul>
<li>Repeat and compute the average (R)MSE.</li>
</ul></li>
</ul>
<table>
<thead>
<tr class="header">
<th>Combination</th>
<th><span class="math inline">\(\alpha\)</span></th>
<th><span class="math inline">\(\lambda\)</span></th>
<th>CV error (RMSE)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0.1</td>
<td>0.01</td>
<td>XXX</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.1</td>
<td>0.02</td>
<td>XXX</td>
</tr>
<tr class="odd">
<td>3</td>
<td>0.1</td>
<td>0.03</td>
<td>XXX</td>
</tr>
<tr class="even">
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<ul>
<li>Choose the pair with the <strong>lowest CV error</strong>.</li>
</ul>
<hr />
</div>
</div>
<div id="pros-and-cons-of-regularization" class="section level4 unnumbered hasAnchor">
<h4><strong>Pros and Cons of Regularization</strong><a href="linear-models.html#pros-and-cons-of-regularization" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="merits-1" class="section level5 unnumbered hasAnchor">
<h5><strong>Merits</strong><a href="linear-models.html#merits-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ol style="list-style-type: decimal">
<li><p><strong>Binarization</strong>: The <code>glmnet()</code> function automatically binarizes categorical predictors.</p>
<ul>
<li>Each factor level is treated as a separate feature to be removed.</li>
</ul></li>
<li><p><strong>Tuned by cross-validation</strong>: Uses the same criterion (RMSE) that will ultimately be used to judge the model against unseen test data.</p></li>
<li><p><strong>Variable selection</strong>: For lasso (and elastic nets), increasing <span class="math inline">\(\lambda\)</span> sufficiently can perform variable selection.</p></li>
</ol>
</div>
<div id="demerits-1" class="section level5 unnumbered hasAnchor">
<h5><strong>Demerits</strong><a href="linear-models.html#demerits-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ol style="list-style-type: decimal">
<li><p><strong>Restricted model forms</strong>: The <code>glmnet()</code> function can accommodate some, but not all, distributions for GLMs (e.g., gamma).</p></li>
<li><p><strong>Interpretation</strong>: Features are standardized, making coefficient estimates for standardized features harder to interpret.</p></li>
</ol>
<hr />
</div>
</div>
</div>
</div>
<div id="case-study-1-fitting-linear-models-in-r" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Case Study 1: Fitting Linear Models in R<a href="linear-models.html#case-study-1-fitting-linear-models-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="about-this-case-study" class="section level3 unnumbered hasAnchor">
<h3><strong>About this Case Study</strong><a href="linear-models.html#about-this-case-study" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="dataset" class="section level4 unnumbered hasAnchor">
<h4><strong>Dataset</strong><a href="linear-models.html#dataset" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Advertising dataset</strong> from ISLR
<ul>
<li>Simulated (i.e., not real data)</li>
<li>Involves a <strong>marketing</strong> context</li>
<li>Useful for illustrating many <strong>modeling concepts</strong>, e.g., <strong>polynomial regression</strong> and <strong>interaction effects</strong>.</li>
</ul></li>
</ul>
</div>
<div id="objectives" class="section level4 unnumbered hasAnchor">
<h4><strong>Objectives</strong><a href="linear-models.html#objectives" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Know how to fit a linear model using the <code>lm()</code> function and <strong>interpret its output</strong>.</li>
<li>Appreciate why variable significance may change as a result of <strong>correlations</strong> between variables.</li>
<li>Generate additional features, e.g., <strong>interaction</strong> and <strong>polynomial</strong> terms.</li>
<li>Generate <strong>predictions</strong> on the test set using the <code>predict()</code> function.</li>
</ul>
<hr />
</div>
<div id="setting" class="section level4 unnumbered hasAnchor">
<h4><strong>Setting</strong><a href="linear-models.html#setting" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Sales</strong> (target variable): The model aims to predict sales.</li>
<li><strong>Predictors</strong>: TV, radio, and newspaper are the potential predictors.
<ul>
<li>The question to answer: Which of them is/are useful?</li>
</ul></li>
</ul>
<div id="strategic-value-of-the-model" class="section level5 unnumbered hasAnchor">
<h5><strong>Strategic Value of the Model</strong><a href="linear-models.html#strategic-value-of-the-model" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>Develop a profitable <strong>marketing plan</strong> by specifying how much should be spent on the three media channels to <strong>maximize sales</strong>.</li>
</ul>
<p>We start off by loading the advertising dataset into a variable named <code>ad</code>. We preview the data using the <code>head()</code> function and notice there is an index column <code>X</code>, so we remove the data by setting <code>ad$X &lt;- NULL</code>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="linear-models.html#cb2-1" tabindex="-1"></a><span class="co"># Read and view the data</span></span>
<span id="cb2-2"><a href="linear-models.html#cb2-2" tabindex="-1"></a>ad <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="fu">url</span>(<span class="st">&quot;https://www.statlearning.com/s/Advertising.csv&quot;</span>))</span>
<span id="cb2-3"><a href="linear-models.html#cb2-3" tabindex="-1"></a><span class="fu">head</span>(ad)</span>
<span id="cb2-4"><a href="linear-models.html#cb2-4" tabindex="-1"></a><span class="co">#&gt;   X    TV radio newspaper sales</span></span>
<span id="cb2-5"><a href="linear-models.html#cb2-5" tabindex="-1"></a><span class="co">#&gt; 1 1 230.1  37.8      69.2  22.1</span></span>
<span id="cb2-6"><a href="linear-models.html#cb2-6" tabindex="-1"></a><span class="co">#&gt; 2 2  44.5  39.3      45.1  10.4</span></span>
<span id="cb2-7"><a href="linear-models.html#cb2-7" tabindex="-1"></a><span class="co">#&gt; 3 3  17.2  45.9      69.3   9.3</span></span>
<span id="cb2-8"><a href="linear-models.html#cb2-8" tabindex="-1"></a><span class="co">#&gt; 4 4 151.5  41.3      58.5  18.5</span></span>
<span id="cb2-9"><a href="linear-models.html#cb2-9" tabindex="-1"></a><span class="co">#&gt; 5 5 180.8  10.8      58.4  12.9</span></span>
<span id="cb2-10"><a href="linear-models.html#cb2-10" tabindex="-1"></a><span class="co">#&gt; 6 6   8.7  48.9      75.0   7.2</span></span>
<span id="cb2-11"><a href="linear-models.html#cb2-11" tabindex="-1"></a></span>
<span id="cb2-12"><a href="linear-models.html#cb2-12" tabindex="-1"></a><span class="co"># We remove the column `X` as it is just an index column</span></span>
<span id="cb2-13"><a href="linear-models.html#cb2-13" tabindex="-1"></a>ad<span class="sc">$</span>X <span class="ot">&lt;-</span> <span class="cn">NULL</span></span></code></pre></div>
<hr />
</div>
</div>
</div>
<div id="exploratory-data-analysis" class="section level3 hasAnchor" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Exploratory Data Analysis<a href="linear-models.html#exploratory-data-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="task-1-explore-the-data" class="section level4 unnumbered hasAnchor">
<h4><strong>TASK 1: Explore the Data</strong><a href="linear-models.html#task-1-explore-the-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>Task Statement:</strong> Examine the distribution of the four variables. For each, perform the following:</p>
<ul>
<li>Show key <strong>descriptive statistics</strong>.</li>
<li>Create <strong>visual representations</strong>.</li>
<li>State your observations from the descriptive statistics and visual representations. In particular, form preliminary conclusions regarding which variables are likely to have <strong>significant predictive power</strong>.</li>
</ul>
<hr />
</div>
<div id="univariate-exploration" class="section level4 unnumbered hasAnchor">
<h4><strong>Univariate Exploration</strong><a href="linear-models.html#univariate-exploration" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The following code creates a summary of descriptive statistics:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="linear-models.html#cb3-1" tabindex="-1"></a><span class="co"># Create a summary of the data to show the descriptive statistics</span></span>
<span id="cb3-2"><a href="linear-models.html#cb3-2" tabindex="-1"></a><span class="fu">summary</span>(ad)</span>
<span id="cb3-3"><a href="linear-models.html#cb3-3" tabindex="-1"></a><span class="co">#&gt;        TV            radio         newspaper    </span></span>
<span id="cb3-4"><a href="linear-models.html#cb3-4" tabindex="-1"></a><span class="co">#&gt;  Min.   :  0.7   Min.   : 0.00   Min.   :  0.3  </span></span>
<span id="cb3-5"><a href="linear-models.html#cb3-5" tabindex="-1"></a><span class="co">#&gt;  1st Qu.: 74.4   1st Qu.: 9.97   1st Qu.: 12.8  </span></span>
<span id="cb3-6"><a href="linear-models.html#cb3-6" tabindex="-1"></a><span class="co">#&gt;  Median :149.8   Median :22.90   Median : 25.8  </span></span>
<span id="cb3-7"><a href="linear-models.html#cb3-7" tabindex="-1"></a><span class="co">#&gt;  Mean   :147.0   Mean   :23.26   Mean   : 30.6  </span></span>
<span id="cb3-8"><a href="linear-models.html#cb3-8" tabindex="-1"></a><span class="co">#&gt;  3rd Qu.:218.8   3rd Qu.:36.52   3rd Qu.: 45.1  </span></span>
<span id="cb3-9"><a href="linear-models.html#cb3-9" tabindex="-1"></a><span class="co">#&gt;  Max.   :296.4   Max.   :49.60   Max.   :114.0  </span></span>
<span id="cb3-10"><a href="linear-models.html#cb3-10" tabindex="-1"></a><span class="co">#&gt;      sales     </span></span>
<span id="cb3-11"><a href="linear-models.html#cb3-11" tabindex="-1"></a><span class="co">#&gt;  Min.   : 1.6  </span></span>
<span id="cb3-12"><a href="linear-models.html#cb3-12" tabindex="-1"></a><span class="co">#&gt;  1st Qu.:10.4  </span></span>
<span id="cb3-13"><a href="linear-models.html#cb3-13" tabindex="-1"></a><span class="co">#&gt;  Median :12.9  </span></span>
<span id="cb3-14"><a href="linear-models.html#cb3-14" tabindex="-1"></a><span class="co">#&gt;  Mean   :14.0  </span></span>
<span id="cb3-15"><a href="linear-models.html#cb3-15" tabindex="-1"></a><span class="co">#&gt;  3rd Qu.:17.4  </span></span>
<span id="cb3-16"><a href="linear-models.html#cb3-16" tabindex="-1"></a><span class="co">#&gt;  Max.   :27.0</span></span></code></pre></div>
<p>Observations:</p>
<ul>
<li>The distribution of <code>sales</code> goes from 1.60 to 27.00 and the mean and median are pretty close to each other, implying that the distribution is symmetrical.</li>
<li>The same goes for <code>TV</code> and <code>radio</code>, their mean and median are pretty close, and therefore somewhat symmetrical.</li>
<li>For <code>newspaper</code>, the mean is greater than the median, implying that the distribution is right-skewed.</li>
</ul>
<p>The following code graphs the distributions of target variable and predictors using histograms. Histograms are appropriate here, because we have 4 numeric variables:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="linear-models.html#cb4-1" tabindex="-1"></a><span class="co"># CHUNK 3</span></span>
<span id="cb4-2"><a href="linear-models.html#cb4-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb4-3"><a href="linear-models.html#cb4-3" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb4-4"><a href="linear-models.html#cb4-4" tabindex="-1"></a></span>
<span id="cb4-5"><a href="linear-models.html#cb4-5" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(ad, <span class="fu">aes</span>(<span class="at">x =</span> sales)) <span class="sc">+</span></span>
<span id="cb4-6"><a href="linear-models.html#cb4-6" tabindex="-1"></a>  <span class="fu">geom_histogram</span>()</span>
<span id="cb4-7"><a href="linear-models.html#cb4-7" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(ad, <span class="fu">aes</span>(<span class="at">x =</span> TV)) <span class="sc">+</span></span>
<span id="cb4-8"><a href="linear-models.html#cb4-8" tabindex="-1"></a>  <span class="fu">geom_histogram</span>()</span>
<span id="cb4-9"><a href="linear-models.html#cb4-9" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(ad, <span class="fu">aes</span>(<span class="at">x =</span> radio)) <span class="sc">+</span></span>
<span id="cb4-10"><a href="linear-models.html#cb4-10" tabindex="-1"></a>  <span class="fu">geom_histogram</span>()</span>
<span id="cb4-11"><a href="linear-models.html#cb4-11" tabindex="-1"></a>p4 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(ad, <span class="fu">aes</span>(<span class="at">x =</span> newspaper)) <span class="sc">+</span></span>
<span id="cb4-12"><a href="linear-models.html#cb4-12" tabindex="-1"></a>  <span class="fu">geom_histogram</span>()</span>
<span id="cb4-13"><a href="linear-models.html#cb4-13" tabindex="-1"></a></span>
<span id="cb4-14"><a href="linear-models.html#cb4-14" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, p3, p4, <span class="at">ncol=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="figures/unnamed-chunk-8-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Observations: - The distribution of <code>sales</code> is approximately symmetrical, which is good because a linear model implicitly assumes a normal distribution. - There is a fair amount of right-skewness for <code>newspaper</code>, so if you like, you could apply a log-transformation.</p>
</div>
<div id="bivariate-exploration" class="section level4 unnumbered hasAnchor">
<h4><strong>Bivariate Exploration</strong><a href="linear-models.html#bivariate-exploration" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Because all of the variables are numeric, we will use scatterplots and correlation matrix to perform bivariate exploration.</p>
<div id="correlation-matrix" class="section level5 unnumbered hasAnchor">
<h5><strong>Correlation Matrix</strong><a href="linear-models.html#correlation-matrix" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The following code creates a correlation matrix:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="linear-models.html#cb5-1" tabindex="-1"></a><span class="co"># Create a correlation matrix</span></span>
<span id="cb5-2"><a href="linear-models.html#cb5-2" tabindex="-1"></a><span class="fu">cor</span>(ad)</span>
<span id="cb5-3"><a href="linear-models.html#cb5-3" tabindex="-1"></a><span class="co">#&gt;                TV   radio newspaper  sales</span></span>
<span id="cb5-4"><a href="linear-models.html#cb5-4" tabindex="-1"></a><span class="co">#&gt; TV        1.00000 0.05481   0.05665 0.7822</span></span>
<span id="cb5-5"><a href="linear-models.html#cb5-5" tabindex="-1"></a><span class="co">#&gt; radio     0.05481 1.00000   0.35410 0.5762</span></span>
<span id="cb5-6"><a href="linear-models.html#cb5-6" tabindex="-1"></a><span class="co">#&gt; newspaper 0.05665 0.35410   1.00000 0.2283</span></span>
<span id="cb5-7"><a href="linear-models.html#cb5-7" tabindex="-1"></a><span class="co">#&gt; sales     0.78222 0.57622   0.22830 1.0000</span></span></code></pre></div>
<p>Since the target variable is <code>sales</code>, the correlation coefficients in the last row or last column are of interest. If you look at the correlations of the three predictors, you can see that <code>sales</code> has a strong correlation with the predictor <code>TV</code>, and a mildly positive correlation with <code>radio</code>.</p>
<p>So on the basis of correlations, we can say that <code>TV</code> and <code>radio</code> are likely to be important predictors of <code>sales</code>.</p>
<p>These findings will be confirmed by the linear models we are going to construct later on. Those models will confirm the predictive power of <code>tv</code> and <code>radio</code>, but <code>newspaper</code> is not a very useful predictor of <code>sales</code>.</p>
</div>
<div id="scatterplots" class="section level5 unnumbered hasAnchor">
<h5><strong>Scatterplots</strong><a href="linear-models.html#scatterplots" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The following code creates scatterplots of the predictor variables against the target variable:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="linear-models.html#cb6-1" tabindex="-1"></a><span class="co"># Create scatterplots of the predictor variables against the target variable</span></span>
<span id="cb6-2"><a href="linear-models.html#cb6-2" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(ad, <span class="fu">aes</span>(<span class="at">x =</span> TV, <span class="at">y =</span> sales)) <span class="sc">+</span></span>
<span id="cb6-3"><a href="linear-models.html#cb6-3" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb6-4"><a href="linear-models.html#cb6-4" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>)</span>
<span id="cb6-5"><a href="linear-models.html#cb6-5" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(ad, <span class="fu">aes</span>(<span class="at">x =</span> radio, <span class="at">y =</span> sales)) <span class="sc">+</span></span>
<span id="cb6-6"><a href="linear-models.html#cb6-6" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb6-7"><a href="linear-models.html#cb6-7" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>)</span>
<span id="cb6-8"><a href="linear-models.html#cb6-8" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(ad, <span class="fu">aes</span>(<span class="at">x =</span> newspaper, <span class="at">y =</span> sales)) <span class="sc">+</span></span>
<span id="cb6-9"><a href="linear-models.html#cb6-9" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb6-10"><a href="linear-models.html#cb6-10" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>)</span>
<span id="cb6-11"><a href="linear-models.html#cb6-11" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, p3, <span class="at">ncol=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="figures/unnamed-chunk-10-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>The association between <code>sales</code> and <code>TV</code> is quite strong and positive. The blue line is the linear regression line fitted to the data. If we spend more on <code>TV</code>, there is a strong tendancy for <code>sales</code> to go up as well.</p>
<p>The same for <code>radio</code>, we can see a mild positive relationship between <code>sales</code> and <code>radio</code>. For <code>newspaper</code>, the relationship is more ambiguous, still positive, but much weaker than <code>TV</code> and <code>radio</code>.</p>
<p>What we’ve observed in the scatterplots is consistent with the correlation matrix previously analyzed.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="linear-models.html#cb7-1" tabindex="-1"></a><span class="co"># Alternative: Create a scatterplot matrix</span></span>
<span id="cb7-2"><a href="linear-models.html#cb7-2" tabindex="-1"></a><span class="fu">pairs</span>(ad)</span></code></pre></div>
<p><img src="figures/unnamed-chunk-11-1.png" width="100%" style="display: block; margin: auto;" /></p>
<hr />
</div>
</div>
</div>
<div id="simple-linear-regression" class="section level3 hasAnchor" number="3.3.2">
<h3><span class="header-section-number">3.3.2</span> Simple Linear Regression<a href="linear-models.html#simple-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="task-2-construct-simple-linear-regression-models" class="section level4 unnumbered hasAnchor">
<h4><strong>TASK 2: Construct Simple Linear Regression Models</strong><a href="linear-models.html#task-2-construct-simple-linear-regression-models" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>Task Statement</strong> - Fit three separate <strong>simple linear regression</strong> models for <strong>sales</strong> on each of <strong>TV</strong>, <strong>radio</strong>, and <strong>newspaper</strong>. Run the summary function on each model and provide the output.</p>
<p>Using the model for sales on TV as an illustration, perform the following: - <strong>Interpret</strong> the estimated coefficient for TV. - Comment on the <strong>statistical significance</strong> of TV. - Comment on the goodness of fit of this model and interpret the value of the <strong>coefficient of determination</strong>. - <strong>Predict</strong> the value of sales when TV equals 0, 100, 200, or 300.</p>
<p>If one and only one of the three advertising media can be included as a predictor for sales, <strong>recommend which medium</strong> you would choose.</p>
<hr />
<p>In CHUNK 6, we are going to fit a simple linear regression model for <code>sales</code> against <code>TV</code>. In R, linear models are fitted using the <code>lm()</code> function. In the <code>lm()</code> function, we provide an equation providing the target variable and the predictors.</p>
<p>We use the <code>~</code> tilde character to separate the target variable on the left, and the predictors on the right. In this case, we have only one predictor, <code>TV</code>. We also have to tell R where the variables are stored, through the <code>data =</code> parameter.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="linear-models.html#cb8-1" tabindex="-1"></a><span class="co"># CHUNK 6</span></span>
<span id="cb8-2"><a href="linear-models.html#cb8-2" tabindex="-1"></a>slr.TV <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> TV, <span class="at">data =</span> ad)</span>
<span id="cb8-3"><a href="linear-models.html#cb8-3" tabindex="-1"></a>slr.TV</span>
<span id="cb8-4"><a href="linear-models.html#cb8-4" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-5"><a href="linear-models.html#cb8-5" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb8-6"><a href="linear-models.html#cb8-6" tabindex="-1"></a><span class="co">#&gt; lm(formula = sales ~ TV, data = ad)</span></span>
<span id="cb8-7"><a href="linear-models.html#cb8-7" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-8"><a href="linear-models.html#cb8-8" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb8-9"><a href="linear-models.html#cb8-9" tabindex="-1"></a><span class="co">#&gt; (Intercept)           TV  </span></span>
<span id="cb8-10"><a href="linear-models.html#cb8-10" tabindex="-1"></a><span class="co">#&gt;      7.0326       0.0475</span></span></code></pre></div>
<p>We can interpret the slope for <code>TV</code> (=0.04754) as for every unit increase in the predictor <code>TV</code>, sales is expected to go up by 0.04754.</p>
<p>We can interpret the intercept of the linear model as, if <code>TV</code> is zero, then sales is expected to be 7.03259.</p>
<p>To get more useful information about our fitted linear model, we can run the <code>summary()</code> function on an <code>lm()</code> object.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="linear-models.html#cb9-1" tabindex="-1"></a><span class="co"># CHUNK 7</span></span>
<span id="cb9-2"><a href="linear-models.html#cb9-2" tabindex="-1"></a><span class="fu">summary</span>(slr.TV)</span>
<span id="cb9-3"><a href="linear-models.html#cb9-3" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb9-4"><a href="linear-models.html#cb9-4" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb9-5"><a href="linear-models.html#cb9-5" tabindex="-1"></a><span class="co">#&gt; lm(formula = sales ~ TV, data = ad)</span></span>
<span id="cb9-6"><a href="linear-models.html#cb9-6" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb9-7"><a href="linear-models.html#cb9-7" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb9-8"><a href="linear-models.html#cb9-8" tabindex="-1"></a><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></span>
<span id="cb9-9"><a href="linear-models.html#cb9-9" tabindex="-1"></a><span class="co">#&gt; -8.386 -1.955 -0.191  2.067  7.212 </span></span>
<span id="cb9-10"><a href="linear-models.html#cb9-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb9-11"><a href="linear-models.html#cb9-11" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb9-12"><a href="linear-models.html#cb9-12" tabindex="-1"></a><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb9-13"><a href="linear-models.html#cb9-13" tabindex="-1"></a><span class="co">#&gt; (Intercept)  7.03259    0.45784    15.4   &lt;2e-16 ***</span></span>
<span id="cb9-14"><a href="linear-models.html#cb9-14" tabindex="-1"></a><span class="co">#&gt; TV           0.04754    0.00269    17.7   &lt;2e-16 ***</span></span>
<span id="cb9-15"><a href="linear-models.html#cb9-15" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb9-16"><a href="linear-models.html#cb9-16" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  </span></span>
<span id="cb9-17"><a href="linear-models.html#cb9-17" tabindex="-1"></a><span class="co">#&gt; 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb9-18"><a href="linear-models.html#cb9-18" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb9-19"><a href="linear-models.html#cb9-19" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 3.26 on 198 degrees of freedom</span></span>
<span id="cb9-20"><a href="linear-models.html#cb9-20" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.612,  Adjusted R-squared:  0.61 </span></span>
<span id="cb9-21"><a href="linear-models.html#cb9-21" tabindex="-1"></a><span class="co">#&gt; F-statistic:  312 on 1 and 198 DF,  p-value: &lt;2e-16</span></span></code></pre></div>
<p>This summary provides additional useful columns regarding the coefficients, the <code>Std. Error</code> column and the <code>t value</code> column, which is the ratio of <code>Estimates</code> column to the <code>Std. Error</code> column. The last column, <code>Pr(&gt;|t|)</code> is the p-value for testing hypothesis of whether the true coefficient is zero or not.</p>
<p>Here the p-values are very small and close to zero, and the smaller the p-value, the more evidence we have against the null hypothesis in favor of the alternative.</p>
<p>So in this case, we have very strong evidence to say that <code>TV</code> is extremely significant due to having a lot of <code>***</code> next to it. The more <code>*</code> next to a variable, the more significant the variable is.</p>
<p>The last three lines contain information on more global aspects of the linear model. The most important one is the <strong>Multiple R-Squared</strong> which is the <strong>Coefficient of Determination</strong>.</p>
<p>For this fitted model, the <strong>Multiple R-Squared</strong> or <strong>Coefficient of Determination</strong> = 0.6119, therefore 61.19% of the variation in <code>sales</code> is explained by the presence of <code>TV</code>.</p>
<p>The next code chunk provides a confidence interval for the intercept and coefficients:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="linear-models.html#cb10-1" tabindex="-1"></a><span class="co"># CHUNK 8</span></span>
<span id="cb10-2"><a href="linear-models.html#cb10-2" tabindex="-1"></a><span class="fu">confint</span>(slr.TV)</span>
<span id="cb10-3"><a href="linear-models.html#cb10-3" tabindex="-1"></a><span class="co">#&gt;               2.5 %  97.5 %</span></span>
<span id="cb10-4"><a href="linear-models.html#cb10-4" tabindex="-1"></a><span class="co">#&gt; (Intercept) 6.12972 7.93547</span></span>
<span id="cb10-5"><a href="linear-models.html#cb10-5" tabindex="-1"></a><span class="co">#&gt; TV          0.04223 0.05284</span></span></code></pre></div>
<p>The next code chunk uses the <code>predict()</code> function on the simple linear regression model of <code>sales</code> on <code>TV</code> and use the <code>head()</code> function to look at the first six predictions:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="linear-models.html#cb11-1" tabindex="-1"></a><span class="co"># CHUNK 9</span></span>
<span id="cb11-2"><a href="linear-models.html#cb11-2" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">predict</span>(slr.TV))</span>
<span id="cb11-3"><a href="linear-models.html#cb11-3" tabindex="-1"></a><span class="co">#&gt;      1      2      3      4      5      6 </span></span>
<span id="cb11-4"><a href="linear-models.html#cb11-4" tabindex="-1"></a><span class="co">#&gt; 17.971  9.148  7.850 14.234 15.627  7.446</span></span></code></pre></div>
<p>When the <code>predict()</code> function is used on a model without any additional arguments, what we will get are the predicted values on the training set.</p>
<p>In the next code chunk, we supply some new data where we want to make some predictions, using the simple linear model. This is done by supplying the <code>newdata</code> argument.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="linear-models.html#cb12-1" tabindex="-1"></a><span class="co"># CHUNK 10</span></span>
<span id="cb12-2"><a href="linear-models.html#cb12-2" tabindex="-1"></a><span class="fu">predict</span>(slr.TV, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">TV =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">300</span>, <span class="at">by =</span> <span class="dv">100</span>)))</span>
<span id="cb12-3"><a href="linear-models.html#cb12-3" tabindex="-1"></a><span class="co">#&gt;      1      2      3      4 </span></span>
<span id="cb12-4"><a href="linear-models.html#cb12-4" tabindex="-1"></a><span class="co">#&gt;  7.033 11.786 16.540 21.294</span></span></code></pre></div>
<p>Similarly, we create simple linear regression models for <code>radio</code> and <code>newspaper</code>, and print the model summaries of both:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="linear-models.html#cb13-1" tabindex="-1"></a><span class="co"># CHUNK 11</span></span>
<span id="cb13-2"><a href="linear-models.html#cb13-2" tabindex="-1"></a>slr.radio <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> radio, <span class="at">data =</span> ad)</span>
<span id="cb13-3"><a href="linear-models.html#cb13-3" tabindex="-1"></a>slr.newspaper <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> newspaper, <span class="at">data =</span> ad)</span>
<span id="cb13-4"><a href="linear-models.html#cb13-4" tabindex="-1"></a></span>
<span id="cb13-5"><a href="linear-models.html#cb13-5" tabindex="-1"></a><span class="fu">summary</span>(slr.radio)</span>
<span id="cb13-6"><a href="linear-models.html#cb13-6" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-7"><a href="linear-models.html#cb13-7" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb13-8"><a href="linear-models.html#cb13-8" tabindex="-1"></a><span class="co">#&gt; lm(formula = sales ~ radio, data = ad)</span></span>
<span id="cb13-9"><a href="linear-models.html#cb13-9" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-10"><a href="linear-models.html#cb13-10" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb13-11"><a href="linear-models.html#cb13-11" tabindex="-1"></a><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span id="cb13-12"><a href="linear-models.html#cb13-12" tabindex="-1"></a><span class="co">#&gt; -15.730  -2.132   0.771   2.778   8.181 </span></span>
<span id="cb13-13"><a href="linear-models.html#cb13-13" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-14"><a href="linear-models.html#cb13-14" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb13-15"><a href="linear-models.html#cb13-15" tabindex="-1"></a><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb13-16"><a href="linear-models.html#cb13-16" tabindex="-1"></a><span class="co">#&gt; (Intercept)   9.3116     0.5629   16.54   &lt;2e-16 ***</span></span>
<span id="cb13-17"><a href="linear-models.html#cb13-17" tabindex="-1"></a><span class="co">#&gt; radio         0.2025     0.0204    9.92   &lt;2e-16 ***</span></span>
<span id="cb13-18"><a href="linear-models.html#cb13-18" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb13-19"><a href="linear-models.html#cb13-19" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  </span></span>
<span id="cb13-20"><a href="linear-models.html#cb13-20" tabindex="-1"></a><span class="co">#&gt; 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb13-21"><a href="linear-models.html#cb13-21" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-22"><a href="linear-models.html#cb13-22" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 4.27 on 198 degrees of freedom</span></span>
<span id="cb13-23"><a href="linear-models.html#cb13-23" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.332,  Adjusted R-squared:  0.329 </span></span>
<span id="cb13-24"><a href="linear-models.html#cb13-24" tabindex="-1"></a><span class="co">#&gt; F-statistic: 98.4 on 1 and 198 DF,  p-value: &lt;2e-16</span></span>
<span id="cb13-25"><a href="linear-models.html#cb13-25" tabindex="-1"></a><span class="fu">summary</span>(slr.newspaper)</span>
<span id="cb13-26"><a href="linear-models.html#cb13-26" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-27"><a href="linear-models.html#cb13-27" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb13-28"><a href="linear-models.html#cb13-28" tabindex="-1"></a><span class="co">#&gt; lm(formula = sales ~ newspaper, data = ad)</span></span>
<span id="cb13-29"><a href="linear-models.html#cb13-29" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-30"><a href="linear-models.html#cb13-30" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb13-31"><a href="linear-models.html#cb13-31" tabindex="-1"></a><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span id="cb13-32"><a href="linear-models.html#cb13-32" tabindex="-1"></a><span class="co">#&gt; -11.227  -3.387  -0.839   3.506  12.775 </span></span>
<span id="cb13-33"><a href="linear-models.html#cb13-33" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-34"><a href="linear-models.html#cb13-34" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb13-35"><a href="linear-models.html#cb13-35" tabindex="-1"></a><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb13-36"><a href="linear-models.html#cb13-36" tabindex="-1"></a><span class="co">#&gt; (Intercept)  12.3514     0.6214    19.9   &lt;2e-16 ***</span></span>
<span id="cb13-37"><a href="linear-models.html#cb13-37" tabindex="-1"></a><span class="co">#&gt; newspaper     0.0547     0.0166     3.3   0.0011 ** </span></span>
<span id="cb13-38"><a href="linear-models.html#cb13-38" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb13-39"><a href="linear-models.html#cb13-39" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  </span></span>
<span id="cb13-40"><a href="linear-models.html#cb13-40" tabindex="-1"></a><span class="co">#&gt; 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb13-41"><a href="linear-models.html#cb13-41" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-42"><a href="linear-models.html#cb13-42" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 5.09 on 198 degrees of freedom</span></span>
<span id="cb13-43"><a href="linear-models.html#cb13-43" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.0521, Adjusted R-squared:  0.0473 </span></span>
<span id="cb13-44"><a href="linear-models.html#cb13-44" tabindex="-1"></a><span class="co">#&gt; F-statistic: 10.9 on 1 and 198 DF,  p-value: 0.00115</span></span></code></pre></div>
<p>The model summaries show that both <code>radio</code> and <code>newspaper</code> are statistically significant, however, the <strong>Multiple R-Squared</strong> or <strong>Coefficient of Determination</strong> is only 33.20% for <code>radio</code> and 5.212% for <code>newspaper</code>, which means a smaller amount of variation in <code>sales</code> is explained by the presence of <code>radio</code> and <code>newspaper</code>, then is for <code>TV</code>.</p>
<p>Since all three models have the same level of complexity, if we had to choose one, then we would choose the SLR model for <code>TV</code>, since it has the highest Multiple R-Squared, because it has the best fit to the training data.</p>
<hr />
</div>
</div>
<div id="multiple-linear-regression" class="section level3 hasAnchor" number="3.3.3">
<h3><span class="header-section-number">3.3.3</span> Multiple Linear Regression<a href="linear-models.html#multiple-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="task-3-construct-a-basic-multiple-linear-regression-model" class="section level4 unnumbered hasAnchor">
<h4><strong>TASK 3: Construct a Basic Multiple Linear Regression Model</strong><a href="linear-models.html#task-3-construct-a-basic-multiple-linear-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>Task Statement</strong></p>
<p>Fit a multiple linear regression model for <strong>sales</strong> on <strong>TV</strong>, <strong>radio</strong>, and <strong>newspaper</strong>. Then do the following:</p>
<ul>
<li><strong>Interpret</strong> the estimated coefficients.</li>
<li>Comment on the <strong>goodness of fit</strong> of this model.</li>
<li>Discuss how the statistical significance of <strong>newspaper</strong> in this model <strong>differs</strong> from that in the simple linear regression model in Task 2. Based on your observations in Task 1, explain why this might be the case.</li>
<li>Refit the model by <strong>dropping the insignificant variable(s)</strong>.</li>
</ul>
<p>In the following code chunk, we will fit the linear model for <code>sales</code> on all of the three advertising mediums.</p>
<p>There are two ways to specify the model formula. The longer method uses the addition sign <code>~ X1 + ... + Xn</code> to include each of the predictors, while the shorter method uses the period character, <code>~ .</code>, to mean “all other variables”.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="linear-models.html#cb14-1" tabindex="-1"></a><span class="co"># CHUNK 12</span></span>
<span id="cb14-2"><a href="linear-models.html#cb14-2" tabindex="-1"></a><span class="co"># Long way</span></span>
<span id="cb14-3"><a href="linear-models.html#cb14-3" tabindex="-1"></a>model<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio <span class="sc">+</span> newspaper, <span class="at">data =</span> ad)</span>
<span id="cb14-4"><a href="linear-models.html#cb14-4" tabindex="-1"></a><span class="co"># OR the shorthand...</span></span>
<span id="cb14-5"><a href="linear-models.html#cb14-5" tabindex="-1"></a>model<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> ., <span class="at">data =</span> ad)</span>
<span id="cb14-6"><a href="linear-models.html#cb14-6" tabindex="-1"></a></span>
<span id="cb14-7"><a href="linear-models.html#cb14-7" tabindex="-1"></a><span class="co"># View summary of linear model</span></span>
<span id="cb14-8"><a href="linear-models.html#cb14-8" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.1</span>)</span>
<span id="cb14-9"><a href="linear-models.html#cb14-9" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb14-10"><a href="linear-models.html#cb14-10" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb14-11"><a href="linear-models.html#cb14-11" tabindex="-1"></a><span class="co">#&gt; lm(formula = sales ~ ., data = ad)</span></span>
<span id="cb14-12"><a href="linear-models.html#cb14-12" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb14-13"><a href="linear-models.html#cb14-13" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb14-14"><a href="linear-models.html#cb14-14" tabindex="-1"></a><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></span>
<span id="cb14-15"><a href="linear-models.html#cb14-15" tabindex="-1"></a><span class="co">#&gt; -8.828 -0.891  0.242  1.189  2.829 </span></span>
<span id="cb14-16"><a href="linear-models.html#cb14-16" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb14-17"><a href="linear-models.html#cb14-17" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb14-18"><a href="linear-models.html#cb14-18" tabindex="-1"></a><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb14-19"><a href="linear-models.html#cb14-19" tabindex="-1"></a><span class="co">#&gt; (Intercept)  2.93889    0.31191    9.42   &lt;2e-16 ***</span></span>
<span id="cb14-20"><a href="linear-models.html#cb14-20" tabindex="-1"></a><span class="co">#&gt; TV           0.04576    0.00139   32.81   &lt;2e-16 ***</span></span>
<span id="cb14-21"><a href="linear-models.html#cb14-21" tabindex="-1"></a><span class="co">#&gt; radio        0.18853    0.00861   21.89   &lt;2e-16 ***</span></span>
<span id="cb14-22"><a href="linear-models.html#cb14-22" tabindex="-1"></a><span class="co">#&gt; newspaper   -0.00104    0.00587   -0.18     0.86    </span></span>
<span id="cb14-23"><a href="linear-models.html#cb14-23" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb14-24"><a href="linear-models.html#cb14-24" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  </span></span>
<span id="cb14-25"><a href="linear-models.html#cb14-25" tabindex="-1"></a><span class="co">#&gt; 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb14-26"><a href="linear-models.html#cb14-26" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb14-27"><a href="linear-models.html#cb14-27" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 1.69 on 196 degrees of freedom</span></span>
<span id="cb14-28"><a href="linear-models.html#cb14-28" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.897,  Adjusted R-squared:  0.896 </span></span>
<span id="cb14-29"><a href="linear-models.html#cb14-29" tabindex="-1"></a><span class="co">#&gt; F-statistic:  570 on 3 and 196 DF,  p-value: &lt;2e-16</span></span></code></pre></div>
<p>The Multiple R-Squared, or Coefficient of Determination, is 0.8972. Therefore, 89.72% of the variation in <code>sales</code> can be explained by the presence of <code>TV</code>, <code>radio</code>, and <code>newspaper</code> together.</p>
<p>Compared to the Multiple R-Squared from the individual simple linear regression models, where the highest Multiple R-Squared was 61.19%, there is a <strong>huge improvement in the goodness-of-fit</strong>. The information contributed from providing the two additional advertisement mediums is useful for explaining the behavior of <code>sales</code>.</p>
<p>In the summary output, we can see that now only two of the predictors, <code>TV</code> and <code>radio</code> are statistically significant (indicated by the <code>***</code>), while <code>newspaper</code> is not. The multiple linear regression model and the simple linear regression model disagree on the significance of <code>newspaper</code>.</p>
<p><strong>Question:</strong> Is <code>newspaper</code> significant or insignificant for sales after all?</p>
<ul>
<li><strong>Different Conditions</strong>:
<ul>
<li><strong>Simple Linear Regression:</strong> <code>newspaper</code> is an important predictor of sales <strong>without</strong> accounting for effects of <code>TV</code> and <code>radio</code> (i.e., their values are <strong>not fixed</strong>).</li>
<li><strong>Multiple Linear Regression:</strong> <code>newspaper</code> is an unimportant predictor of sales <strong>after</strong> accounting for effects of <code>TV</code> and <code>radio</code> (i.e., their values are <strong>fixed</strong>).</li>
</ul></li>
<li><strong>From the Correlation Matrix</strong>:
<ul>
<li><strong><code>radio</code></strong> <span class="math inline">\(\uparrow\)</span> <span class="math inline">\(\Rightarrow\)</span> <strong><code>sales</code></strong> <span class="math inline">\(\uparrow\)</span> (based on multiple linear regression)</li>
<li><strong><code>radio</code></strong> <span class="math inline">\(\uparrow\)</span> <span class="math inline">\(\Rightarrow\)</span> <strong><code>newpaper</code></strong> <span class="math inline">\(\uparrow\)</span> (based on correlation matrix)</li>
<li><span class="math inline">\(\therefore\)</span> <strong><code>sales</code></strong> and <strong><code>newspaper</code></strong> (“surrogate” for radio) tend to <span class="math inline">\(\uparrow\)</span> together</li>
</ul></li>
</ul>
<p>This can be seen calculating the correlation of residuals between a linear model with of <code>sales</code> on <code>TV</code> and <code>radio</code> against a linear model of <code>newspaper</code> on <code>TV</code> and <code>radio</code>:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="linear-models.html#cb15-1" tabindex="-1"></a><span class="co"># CHUNK 13</span></span>
<span id="cb15-2"><a href="linear-models.html#cb15-2" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio, <span class="at">data =</span> ad)</span>
<span id="cb15-3"><a href="linear-models.html#cb15-3" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(newspaper <span class="sc">~</span> TV <span class="sc">+</span> radio, <span class="at">data =</span> ad)</span>
<span id="cb15-4"><a href="linear-models.html#cb15-4" tabindex="-1"></a></span>
<span id="cb15-5"><a href="linear-models.html#cb15-5" tabindex="-1"></a><span class="fu">cor</span>(m1<span class="sc">$</span>residuals, m2<span class="sc">$</span>residuals)</span>
<span id="cb15-6"><a href="linear-models.html#cb15-6" tabindex="-1"></a><span class="co">#&gt; [1] -0.01262</span></span></code></pre></div>
<p>The next code chunk drops the insignificant variable (<code>newspaper</code>) and refits the model, then prints a summary of the new linear model:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="linear-models.html#cb16-1" tabindex="-1"></a><span class="co"># CHUNK 14</span></span>
<span id="cb16-2"><a href="linear-models.html#cb16-2" tabindex="-1"></a>model<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio, <span class="at">data =</span> ad)</span>
<span id="cb16-3"><a href="linear-models.html#cb16-3" tabindex="-1"></a></span>
<span id="cb16-4"><a href="linear-models.html#cb16-4" tabindex="-1"></a><span class="co"># OR regress sales on all media except newspaper</span></span>
<span id="cb16-5"><a href="linear-models.html#cb16-5" tabindex="-1"></a><span class="co"># model.2 &lt;- lm(sales ~ . - newspaper, data = ad)</span></span>
<span id="cb16-6"><a href="linear-models.html#cb16-6" tabindex="-1"></a></span>
<span id="cb16-7"><a href="linear-models.html#cb16-7" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.2</span>)</span>
<span id="cb16-8"><a href="linear-models.html#cb16-8" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb16-9"><a href="linear-models.html#cb16-9" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb16-10"><a href="linear-models.html#cb16-10" tabindex="-1"></a><span class="co">#&gt; lm(formula = sales ~ TV + radio, data = ad)</span></span>
<span id="cb16-11"><a href="linear-models.html#cb16-11" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb16-12"><a href="linear-models.html#cb16-12" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb16-13"><a href="linear-models.html#cb16-13" tabindex="-1"></a><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></span>
<span id="cb16-14"><a href="linear-models.html#cb16-14" tabindex="-1"></a><span class="co">#&gt; -8.798 -0.875  0.242  1.171  2.833 </span></span>
<span id="cb16-15"><a href="linear-models.html#cb16-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb16-16"><a href="linear-models.html#cb16-16" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb16-17"><a href="linear-models.html#cb16-17" tabindex="-1"></a><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb16-18"><a href="linear-models.html#cb16-18" tabindex="-1"></a><span class="co">#&gt; (Intercept)  2.92110    0.29449    9.92   &lt;2e-16 ***</span></span>
<span id="cb16-19"><a href="linear-models.html#cb16-19" tabindex="-1"></a><span class="co">#&gt; TV           0.04575    0.00139   32.91   &lt;2e-16 ***</span></span>
<span id="cb16-20"><a href="linear-models.html#cb16-20" tabindex="-1"></a><span class="co">#&gt; radio        0.18799    0.00804   23.38   &lt;2e-16 ***</span></span>
<span id="cb16-21"><a href="linear-models.html#cb16-21" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb16-22"><a href="linear-models.html#cb16-22" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  </span></span>
<span id="cb16-23"><a href="linear-models.html#cb16-23" tabindex="-1"></a><span class="co">#&gt; 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb16-24"><a href="linear-models.html#cb16-24" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb16-25"><a href="linear-models.html#cb16-25" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 1.68 on 197 degrees of freedom</span></span>
<span id="cb16-26"><a href="linear-models.html#cb16-26" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.897,  Adjusted R-squared:  0.896 </span></span>
<span id="cb16-27"><a href="linear-models.html#cb16-27" tabindex="-1"></a><span class="co">#&gt; F-statistic:  860 on 2 and 197 DF,  p-value: &lt;2e-16</span></span></code></pre></div>
<p>The model summary for <code>model.2</code> shows that <code>TV</code> and <code>radio</code> continue to be significant predictors of <code>sales</code> based on the very small p-values (indicated by <code>***</code> in the coefficient summary).</p>
<p>The Multiple R-Squared or Coefficient of Determination is 89.72%, which is the same as the previous model up to four decimal places <span class="math inline">\(\Rightarrow\)</span> Removing <code>newspaper</code> has a negligible impact on the goodness-of-fit of the linear model.</p>
<p>In the rest of this case study, we will use <code>model.2</code> as the starting point and add new features to make the model more flexible and more predictive.</p>
<hr />
</div>
<div id="task-4-construct-a-multiple-linear-model-with-interaction" class="section level4 unnumbered hasAnchor">
<h4><strong>TASK 4: Construct a Multiple Linear Model with Interaction</strong><a href="linear-models.html#task-4-construct-a-multiple-linear-model-with-interaction" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>Task Statement</strong></p>
<p>CHUNK 15 shows a three-dimensional scatterplot for sales against TV and radio.</p>
<ul>
<li>Explain why the scatterplot suggests that there may be an interaction between TV and radio.</li>
<li>Fit a multiple linear regression model for sales against TV and radio <em>with interaction</em>. Provide the summary output.</li>
<li>Interpret the estimated coefficient for the interaction term.</li>
<li>Provide evidence that the interaction is significant.</li>
</ul>
<p>The following code chunk creates a three-dimensional scatterplot the linear model of <code>sales</code> against <code>TV</code> and <code>radio</code>:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="linear-models.html#cb17-1" tabindex="-1"></a><span class="co"># CHUNK 15</span></span>
<span id="cb17-2"><a href="linear-models.html#cb17-2" tabindex="-1"></a></span>
<span id="cb17-3"><a href="linear-models.html#cb17-3" tabindex="-1"></a><span class="co"># Uncomment these lines the first time you run this chunk</span></span>
<span id="cb17-4"><a href="linear-models.html#cb17-4" tabindex="-1"></a><span class="co">#install.packages(&quot;car&quot;)  </span></span>
<span id="cb17-5"><a href="linear-models.html#cb17-5" tabindex="-1"></a><span class="co">#install.packages(&quot;rgl&quot;)</span></span>
<span id="cb17-6"><a href="linear-models.html#cb17-6" tabindex="-1"></a></span>
<span id="cb17-7"><a href="linear-models.html#cb17-7" tabindex="-1"></a><span class="co"># Load the car and rgl packages</span></span>
<span id="cb17-8"><a href="linear-models.html#cb17-8" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb17-9"><a href="linear-models.html#cb17-9" tabindex="-1"></a><span class="fu">library</span>(rgl)</span>
<span id="cb17-10"><a href="linear-models.html#cb17-10" tabindex="-1"></a></span>
<span id="cb17-11"><a href="linear-models.html#cb17-11" tabindex="-1"></a><span class="co"># Create a 3D scatterplot of the linear model `sales` on `TV` and `radio`</span></span>
<span id="cb17-12"><a href="linear-models.html#cb17-12" tabindex="-1"></a><span class="fu">scatter3d</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio, <span class="at">data =</span> ad)</span></code></pre></div>
<p>In the plot, purple plane is the signal function and the dots are the data from the <code>ad</code> dataset.</p>
<p>If we rotate the three-dimensional plot to a birds-eye view, the observations above the regression plane are represented by the yellow-colored dots and have a positive residual and display a systematic pattern – they lie along the 45-degree line on the x-y plane and represent the instances where the company allocates advertising expenditures to <strong>both</strong> <code>TV</code> and <code>radio</code> and are under-predicted.</p>
<p>The observations below the regression plane are represented by the gray-colored dots and have a negative residual, and represent observations where the marketing company allocates advertising expenditures to either <code>TV</code> or <code>radio</code>, but not both, and are over-predicted.</p>
<p>These findings suggest that there may be a synergy effect between <code>TV</code> and <code>radio</code>. If the company combines both <code>TV</code> and <code>radio</code>, it may lead to a bigger boost in <code>sales</code> than using just one advertising medium.</p>
<p>However, this synergy is not taken into consideration by <code>model.2</code> which assumes that <code>TV</code> and <code>radio</code> contribute to <code>sales</code> independently. We know that <code>model.2</code> is fairly good, considering that the Multiple R-Squared is 89.72%, but we may be able to adapt it to include interaction effects to make it even better.</p>
<p>In the next code chunk, we fit the linear model for <code>sales</code> against <code>TV</code> and <code>radio</code>, together with the interaction term <code>TV * radio</code>. Two methods in R for doing so are provided:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="linear-models.html#cb18-1" tabindex="-1"></a><span class="co"># CHUNK 16</span></span>
<span id="cb18-2"><a href="linear-models.html#cb18-2" tabindex="-1"></a>model<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">*</span> radio, <span class="at">data =</span> ad)</span>
<span id="cb18-3"><a href="linear-models.html#cb18-3" tabindex="-1"></a></span>
<span id="cb18-4"><a href="linear-models.html#cb18-4" tabindex="-1"></a><span class="co"># OR</span></span>
<span id="cb18-5"><a href="linear-models.html#cb18-5" tabindex="-1"></a><span class="co"># model.3 &lt;- lm(sales ~ TV + radio + TV:radio, data = ad)</span></span>
<span id="cb18-6"><a href="linear-models.html#cb18-6" tabindex="-1"></a></span>
<span id="cb18-7"><a href="linear-models.html#cb18-7" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.3</span>)</span>
<span id="cb18-8"><a href="linear-models.html#cb18-8" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb18-9"><a href="linear-models.html#cb18-9" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb18-10"><a href="linear-models.html#cb18-10" tabindex="-1"></a><span class="co">#&gt; lm(formula = sales ~ TV * radio, data = ad)</span></span>
<span id="cb18-11"><a href="linear-models.html#cb18-11" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb18-12"><a href="linear-models.html#cb18-12" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb18-13"><a href="linear-models.html#cb18-13" tabindex="-1"></a><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></span>
<span id="cb18-14"><a href="linear-models.html#cb18-14" tabindex="-1"></a><span class="co">#&gt; -6.337 -0.403  0.183  0.595  1.525 </span></span>
<span id="cb18-15"><a href="linear-models.html#cb18-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb18-16"><a href="linear-models.html#cb18-16" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb18-17"><a href="linear-models.html#cb18-17" tabindex="-1"></a><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb18-18"><a href="linear-models.html#cb18-18" tabindex="-1"></a><span class="co">#&gt; (Intercept) 6.75e+00   2.48e-01   27.23   &lt;2e-16 ***</span></span>
<span id="cb18-19"><a href="linear-models.html#cb18-19" tabindex="-1"></a><span class="co">#&gt; TV          1.91e-02   1.50e-03   12.70   &lt;2e-16 ***</span></span>
<span id="cb18-20"><a href="linear-models.html#cb18-20" tabindex="-1"></a><span class="co">#&gt; radio       2.89e-02   8.91e-03    3.24   0.0014 ** </span></span>
<span id="cb18-21"><a href="linear-models.html#cb18-21" tabindex="-1"></a><span class="co">#&gt; TV:radio    1.09e-03   5.24e-05   20.73   &lt;2e-16 ***</span></span>
<span id="cb18-22"><a href="linear-models.html#cb18-22" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb18-23"><a href="linear-models.html#cb18-23" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  </span></span>
<span id="cb18-24"><a href="linear-models.html#cb18-24" tabindex="-1"></a><span class="co">#&gt; 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb18-25"><a href="linear-models.html#cb18-25" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb18-26"><a href="linear-models.html#cb18-26" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 0.944 on 196 degrees of freedom</span></span>
<span id="cb18-27"><a href="linear-models.html#cb18-27" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.968,  Adjusted R-squared:  0.967 </span></span>
<span id="cb18-28"><a href="linear-models.html#cb18-28" tabindex="-1"></a><span class="co">#&gt; F-statistic: 1.96e+03 on 3 and 196 DF,  p-value: &lt;2e-16</span></span></code></pre></div>
<p>Based on the model summary for <code>model.3</code>, all of the terms (<code>TV</code>, <code>radio</code>, and <code>TV:radio</code>) are statistically significant (indicated by the <code>***</code> and the small p-values).</p>
<p>The interaction term <code>TV:radio</code> has a larger <code>t-value</code> (20.727) than the individual terms <code>TV</code> (12.699) and <code>radio</code> (3.241), so it’s the most statistically significant term in the model.</p>
<p><strong>How can we interpret the coefficient estimate of the interaction term <code>TV:radio</code> (1.086e-03)?</strong></p>
<p>If you differentiate the expected value of <code>sales</code> with respect to <code>radio</code> (e.g., you want to look at the effect of radio on sales), then this expression involves <code>TV</code> because of the interaction term:</p>
<p><span class="math display">\[
\frac{\partial}{\partial \text{radio}} \hat{\text{sales}} = 0.02886 + 0.001086 \times \text{TV}
\]</span></p>
<p><span class="math inline">\(\Rightarrow\)</span> For every unit increase in <code>TV</code>, the effect of <code>radio</code> on <code>sales</code> will increase by <span class="math inline">\(\fbox{0.001086}\)</span>.</p>
<p>Similarly, we can say that the effect of <code>TV</code> on <code>sales</code> will increase by <span class="math inline">\(\fbox{0.001086}\)</span> for every unit increase of <code>radio</code>:</p>
<p><span class="math display">\[
\frac{\partial}{\partial \text{TV}} \hat{\text{sales}} = 0.02886 + 0.001086 \times \text{radio}
\]</span></p>
<p>In addition, the Multiple R-Squared or Coefficient of Determination is 0.9678 or 96.78%, which is a significant improvement from <code>model.2</code>, which only had an <span class="math inline">\(R^2 = 89.72\)</span>% <span class="math inline">\(\Rightarrow\)</span> We can say that <code>model.3</code> fits the training data much better than <code>model.2</code>. The improvement in the goodness-of-fit is remarkable when including the interaction term.</p>
<p>In the remainder of the case study, we will see that the interaction term will improve the prediction performance of the linear model quite substantially.</p>
<hr />
</div>
</div>
<div id="evaluation-of-linear-models" class="section level3 hasAnchor" number="3.3.4">
<h3><span class="header-section-number">3.3.4</span> Evaluation of Linear Models<a href="linear-models.html#evaluation-of-linear-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="task-5-evaluate-three-marketing-plans" class="section level4 unnumbered hasAnchor">
<h4>TASK 5: Evaluate Three Marketing Plans<a href="linear-models.html#task-5-evaluate-three-marketing-plans" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="task-statement" class="section level5 unnumbered hasAnchor">
<h5><strong>Task statement</strong><a href="linear-models.html#task-statement" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Suppose that as the manager of the company, you are given a total of $100,000 to spend on advertising. Three ways to allocate the budget between TV and radio advertising:</p>
<ol style="list-style-type: decimal">
<li>Spending the <strong>entire amount</strong> on radio advertising.</li>
<li><strong>Splitting</strong> the budget <strong>evenly</strong> between TV and radio advertising.</li>
<li>Spending <strong>$70,000</strong> on radio advertising and <strong>$30,000</strong> on TV advertising.</li>
</ol>
<p>Evaluate these three marketing plans using the interaction model constructed in Task 4.</p>
<table>
<caption><strong>Task 5 Table:</strong> Combinations of <code>TV</code> and <code>radio</code> to use in <code>model.3</code></caption>
<thead>
<tr class="header">
<th align="center">Plan</th>
<th align="center"><code>TV</code></th>
<th align="center"><code>radio</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">0</td>
<td align="center">100</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">50</td>
<td align="center">50</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">30</td>
<td align="center">70</td>
</tr>
</tbody>
</table>
<p>In the following code chunk, we first set up a data frame containing the three pairs of predictor values. Then we put this data frame in the <code>newdata</code> argument of the <code>predict()</code> function and make predictions:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="linear-models.html#cb19-1" tabindex="-1"></a><span class="co"># CHUNK 17</span></span>
<span id="cb19-2"><a href="linear-models.html#cb19-2" tabindex="-1"></a>dat.budget <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">TV =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">50</span>, <span class="dv">30</span>), <span class="at">radio =</span> <span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">50</span>, <span class="dv">70</span>))</span>
<span id="cb19-3"><a href="linear-models.html#cb19-3" tabindex="-1"></a><span class="fu">predict</span>(model<span class="fl">.3</span>, <span class="at">newdata =</span> dat.budget)</span>
<span id="cb19-4"><a href="linear-models.html#cb19-4" tabindex="-1"></a><span class="co">#&gt;      1      2      3 </span></span>
<span id="cb19-5"><a href="linear-models.html#cb19-5" tabindex="-1"></a><span class="co">#&gt;  9.636 11.865 11.625</span></span></code></pre></div>
<p>Based on the predicted sales amount, the marketing strategy consisting of splitting the budget evenly between <code>TV</code> and <code>radio</code> results in the largest predicted value of <code>sales</code> <span class="math inline">\(\Rightarrow\)</span> Our recommendation is to use the second marketing plan.</p>
<hr />
</div>
</div>
<div id="task-6-construct-a-model-with-interaction-and-polynomial-terms" class="section level4 unnumbered hasAnchor">
<h4>TASK 6: Construct a Model with Interaction and Polynomial Terms<a href="linear-models.html#task-6-construct-a-model-with-interaction-and-polynomial-terms" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="task-statement-1" class="section level5 unnumbered hasAnchor">
<h5>Task statement<a href="linear-models.html#task-statement-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Your supervisor has suggested that adding the <strong>square of TV</strong> as a feature may improve the multiple linear regression model.</p>
<ul>
<li>Explain, without running any models, why this is or is not a reasonable suggestion.</li>
<li>Regardless of your conclusion, fit a multiple linear regression model for sales against TV and radio with interaction and the <strong>square of TV</strong> added. Provide the summary output.</li>
</ul>
</div>
<div id="model-4" class="section level5 unnumbered hasAnchor">
<h5>Model 4<a href="linear-models.html#model-4" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p><span class="math display">\[
\text{sales} = \beta_0 + \beta_1 \times \text{TV} + \beta_2 \times \text{radio} + \beta_3 \times \text{TV}^2 + \beta_4 \times \text{TV} \times \text{radio} + \epsilon
\]</span></p>
<p>In the following code chunk, we will refine <code>model.3</code> by adding the square of <code>TV</code> added as an additional feature:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="linear-models.html#cb20-1" tabindex="-1"></a>model<span class="fl">.4</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">*</span> radio <span class="sc">+</span> <span class="fu">I</span>(TV<span class="sc">^</span><span class="dv">2</span>), <span class="at">data=</span>ad)</span>
<span id="cb20-2"><a href="linear-models.html#cb20-2" tabindex="-1"></a><span class="fu">summary</span>(model<span class="fl">.4</span>)</span>
<span id="cb20-3"><a href="linear-models.html#cb20-3" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb20-4"><a href="linear-models.html#cb20-4" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb20-5"><a href="linear-models.html#cb20-5" tabindex="-1"></a><span class="co">#&gt; lm(formula = sales ~ TV * radio + I(TV^2), data = ad)</span></span>
<span id="cb20-6"><a href="linear-models.html#cb20-6" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb20-7"><a href="linear-models.html#cb20-7" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb20-8"><a href="linear-models.html#cb20-8" tabindex="-1"></a><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></span>
<span id="cb20-9"><a href="linear-models.html#cb20-9" tabindex="-1"></a><span class="co">#&gt; -4.995 -0.297 -0.007  0.380  1.169 </span></span>
<span id="cb20-10"><a href="linear-models.html#cb20-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb20-11"><a href="linear-models.html#cb20-11" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb20-12"><a href="linear-models.html#cb20-12" tabindex="-1"></a><span class="co">#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb20-13"><a href="linear-models.html#cb20-13" tabindex="-1"></a><span class="co">#&gt; (Intercept)  5.14e+00   1.93e-01   26.66  &lt; 2e-16 ***</span></span>
<span id="cb20-14"><a href="linear-models.html#cb20-14" tabindex="-1"></a><span class="co">#&gt; TV           5.09e-02   2.23e-03   22.81  &lt; 2e-16 ***</span></span>
<span id="cb20-15"><a href="linear-models.html#cb20-15" tabindex="-1"></a><span class="co">#&gt; radio        3.52e-02   5.90e-03    5.96  1.2e-08 ***</span></span>
<span id="cb20-16"><a href="linear-models.html#cb20-16" tabindex="-1"></a><span class="co">#&gt; I(TV^2)     -1.10e-04   6.89e-06  -15.92  &lt; 2e-16 ***</span></span>
<span id="cb20-17"><a href="linear-models.html#cb20-17" tabindex="-1"></a><span class="co">#&gt; TV:radio     1.08e-03   3.47e-05   31.06  &lt; 2e-16 ***</span></span>
<span id="cb20-18"><a href="linear-models.html#cb20-18" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb20-19"><a href="linear-models.html#cb20-19" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  </span></span>
<span id="cb20-20"><a href="linear-models.html#cb20-20" tabindex="-1"></a><span class="co">#&gt; 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb20-21"><a href="linear-models.html#cb20-21" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb20-22"><a href="linear-models.html#cb20-22" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 0.624 on 195 degrees of freedom</span></span>
<span id="cb20-23"><a href="linear-models.html#cb20-23" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.986,  Adjusted R-squared:  0.986 </span></span>
<span id="cb20-24"><a href="linear-models.html#cb20-24" tabindex="-1"></a><span class="co">#&gt; F-statistic: 3.43e+03 on 4 and 195 DF,  p-value: &lt;2e-16</span></span></code></pre></div>
<p><strong>Note:</strong> The <code>I()</code> function in R will process its interior contents in arithmetic manner.</p>
<p>Based on the output of the model summary, all terms of the linear model are statistically significant (indicated by the <code>***</code> and small p-values).</p>
<p>The coefficient of <code>I(TV^2)</code> is negative (-1.097e-04), so <code>sales</code> and <code>TV</code> are related by a downward parabola in <code>model.4</code>, consistent with what we saw in CHUNK 5.</p>
<p>The Multiple R-Squared or Coefficient of Determination for <code>model.4</code> is 0.986 or 98.6%, which is higher than the Multiple R-Squared produced by <code>model.3</code> <span class="math inline">\(\Rightarrow\)</span> The goodness-of-fit of <code>model.4</code> is almost perfect (e.g., the <span class="math inline">\(R^2\)</span> is almost 1) thanks to including the interaction term and the square term.</p>
<p>So in this case study, both the interaction term and square term are useful features for describing the data, and we will further confirm their usefulness in the last task of the case study.</p>
<hr />
</div>
</div>
<div id="task-7-choose-a-model" class="section level4 unnumbered hasAnchor">
<h4>TASK 7: Choose a Model<a href="linear-models.html#task-7-choose-a-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>Task statement</strong></p>
<ol style="list-style-type: decimal">
<li>Split the data into <strong>training</strong> and <strong>test</strong> sets.</li>
<li>Evaluate the <strong>prediction performance</strong> of the models in Tasks 3, 4, and 6. Recommend which model should be used.</li>
</ol>
<table>
<thead>
<tr class="header">
<th>Model</th>
<th>Task</th>
<th>Formula</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>2</td>
<td>sales ~ TV + radio + newspaper</td>
</tr>
<tr class="even">
<td>2</td>
<td>3</td>
<td>sales ~ TV + radio</td>
</tr>
<tr class="odd">
<td>3</td>
<td>4</td>
<td>sales ~ TV * radio</td>
</tr>
<tr class="even">
<td>4</td>
<td>6</td>
<td>sales ~ TV * radio + I(TV^2)</td>
</tr>
<tr class="odd">
<td>5</td>
<td>–</td>
<td>sales ~ TV * radio + I(TV^2) + I(radio^2)</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Note:</strong> The <code>I()</code> function is used in R to indicate mathematical operations within formulas.</li>
</ul>
<p><strong>Steps</strong></p>
<ul>
<li><strong>Data Split:</strong> Use a predefined split ratio (e.g., 70/30) to separate the data into training and test sets.</li>
<li><strong>Model Evaluation:</strong> Use a metric such as RMSE to compare prediction accuracy on the test set across the models.</li>
<li><strong>Model Recommendation:</strong> Select the model with the best balance between complexity and predictive accuracy.</li>
</ul>
<p>In the following code chunk, we use the <code>caret</code> package to split the data into a training and test set:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="linear-models.html#cb21-1" tabindex="-1"></a><span class="co"># CHUNK 19</span></span>
<span id="cb21-2"><a href="linear-models.html#cb21-2" tabindex="-1"></a><span class="co"># Install packages</span></span>
<span id="cb21-3"><a href="linear-models.html#cb21-3" tabindex="-1"></a><span class="co"># Uncomment this line the first time you use caret</span></span>
<span id="cb21-4"><a href="linear-models.html#cb21-4" tabindex="-1"></a><span class="co">#install.packages(&quot;caret&quot;)</span></span>
<span id="cb21-5"><a href="linear-models.html#cb21-5" tabindex="-1"></a></span>
<span id="cb21-6"><a href="linear-models.html#cb21-6" tabindex="-1"></a><span class="co"># Load packages</span></span>
<span id="cb21-7"><a href="linear-models.html#cb21-7" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb21-8"><a href="linear-models.html#cb21-8" tabindex="-1"></a></span>
<span id="cb21-9"><a href="linear-models.html#cb21-9" tabindex="-1"></a><span class="co"># Set the random seed so that the results are reproducible</span></span>
<span id="cb21-10"><a href="linear-models.html#cb21-10" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb21-11"><a href="linear-models.html#cb21-11" tabindex="-1"></a></span>
<span id="cb21-12"><a href="linear-models.html#cb21-12" tabindex="-1"></a><span class="co"># Create a data partition</span></span>
<span id="cb21-13"><a href="linear-models.html#cb21-13" tabindex="-1"></a>partition <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(ad<span class="sc">$</span>sales, <span class="at">p =</span> <span class="fl">0.7</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb21-14"><a href="linear-models.html#cb21-14" tabindex="-1"></a></span>
<span id="cb21-15"><a href="linear-models.html#cb21-15" tabindex="-1"></a><span class="co"># Split the data into training and test sets</span></span>
<span id="cb21-16"><a href="linear-models.html#cb21-16" tabindex="-1"></a>data.train <span class="ot">&lt;-</span> ad[partition, ]</span>
<span id="cb21-17"><a href="linear-models.html#cb21-17" tabindex="-1"></a>data.test <span class="ot">&lt;-</span> ad[<span class="sc">-</span>partition, ]</span></code></pre></div>
<p>You can see that there are 142 observations in the training set (~70%), and 58 observations in the test set (~30%).</p>
<p>The <code>createDataPartition()</code> function from the <code>caret</code> package has built-in functionality to ensure that the target variable follows the same distribution both the training set and the test set. This way the two sets will be representative of the target variable.</p>
<p>We can check this by applying the <code>summary()</code> function on the target variable in each of the two sets:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="linear-models.html#cb22-1" tabindex="-1"></a><span class="co"># CHUNK 20</span></span>
<span id="cb22-2"><a href="linear-models.html#cb22-2" tabindex="-1"></a><span class="fu">print</span>(<span class="st">&quot;TRAIN&quot;</span>)</span>
<span id="cb22-3"><a href="linear-models.html#cb22-3" tabindex="-1"></a><span class="co">#&gt; [1] &quot;TRAIN&quot;</span></span>
<span id="cb22-4"><a href="linear-models.html#cb22-4" tabindex="-1"></a><span class="fu">summary</span>(data.train<span class="sc">$</span>sales)</span>
<span id="cb22-5"><a href="linear-models.html#cb22-5" tabindex="-1"></a><span class="co">#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span></span>
<span id="cb22-6"><a href="linear-models.html#cb22-6" tabindex="-1"></a><span class="co">#&gt;     1.6    10.4    12.9    14.0    17.3    26.2</span></span>
<span id="cb22-7"><a href="linear-models.html#cb22-7" tabindex="-1"></a></span>
<span id="cb22-8"><a href="linear-models.html#cb22-8" tabindex="-1"></a><span class="fu">print</span>(<span class="st">&quot;TEST&quot;</span>)</span>
<span id="cb22-9"><a href="linear-models.html#cb22-9" tabindex="-1"></a><span class="co">#&gt; [1] &quot;TEST&quot;</span></span>
<span id="cb22-10"><a href="linear-models.html#cb22-10" tabindex="-1"></a><span class="fu">summary</span>(data.test<span class="sc">$</span>sales)</span>
<span id="cb22-11"><a href="linear-models.html#cb22-11" tabindex="-1"></a><span class="co">#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span></span>
<span id="cb22-12"><a href="linear-models.html#cb22-12" tabindex="-1"></a><span class="co">#&gt;     3.2    10.3    12.6    14.2    17.4    27.0</span></span></code></pre></div>
<p>In the following code chunk, we will fit all models considered on the training set of data:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="linear-models.html#cb23-1" tabindex="-1"></a>model.<span class="fl">1.</span>tr <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio <span class="sc">+</span> newspaper, <span class="at">data=</span>data.train)</span>
<span id="cb23-2"><a href="linear-models.html#cb23-2" tabindex="-1"></a>model.<span class="fl">2.</span>tr <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio, <span class="at">data=</span>data.train)</span>
<span id="cb23-3"><a href="linear-models.html#cb23-3" tabindex="-1"></a>model.<span class="fl">3.</span>tr <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">*</span> radio <span class="sc">+</span> newspaper, <span class="at">data=</span>data.train)</span>
<span id="cb23-4"><a href="linear-models.html#cb23-4" tabindex="-1"></a>model.<span class="fl">4.</span>tr <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">*</span> radio <span class="sc">+</span> <span class="fu">I</span>(TV<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> newspaper, <span class="at">data=</span>data.train)</span>
<span id="cb23-5"><a href="linear-models.html#cb23-5" tabindex="-1"></a>model.<span class="fl">5.</span>tr <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">*</span> radio <span class="sc">+</span> <span class="fu">I</span>(TV<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(radio<span class="sc">^</span><span class="dv">2</span>), <span class="at">data=</span>data.train)</span></code></pre></div>
<p><strong>Training RMSE</strong></p>
<p>In the following code chunk, we will use the <code>RMSE()</code> function in the <code>caret</code> package to calculate the training RMSE for each of the five trained models.</p>
<p>The <code>RMSE()</code> function takes a vector of target variable values, and a vector of predicted fitted-values, and we will see what we can observe from the results:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="linear-models.html#cb24-1" tabindex="-1"></a><span class="co"># CHUNK 22</span></span>
<span id="cb24-2"><a href="linear-models.html#cb24-2" tabindex="-1"></a><span class="fu">print</span>(<span class="st">&quot;TRAIN&quot;</span>)</span>
<span id="cb24-3"><a href="linear-models.html#cb24-3" tabindex="-1"></a><span class="co">#&gt; [1] &quot;TRAIN&quot;</span></span>
<span id="cb24-4"><a href="linear-models.html#cb24-4" tabindex="-1"></a><span class="fu">RMSE</span>(data.train<span class="sc">$</span>sales, <span class="fu">predict</span>(model.<span class="fl">1.</span>tr))</span>
<span id="cb24-5"><a href="linear-models.html#cb24-5" tabindex="-1"></a><span class="co">#&gt; [1] 1.702</span></span>
<span id="cb24-6"><a href="linear-models.html#cb24-6" tabindex="-1"></a><span class="fu">RMSE</span>(data.train<span class="sc">$</span>sales, <span class="fu">predict</span>(model.<span class="fl">2.</span>tr))</span>
<span id="cb24-7"><a href="linear-models.html#cb24-7" tabindex="-1"></a><span class="co">#&gt; [1] 1.704</span></span>
<span id="cb24-8"><a href="linear-models.html#cb24-8" tabindex="-1"></a><span class="fu">RMSE</span>(data.train<span class="sc">$</span>sales, <span class="fu">predict</span>(model.<span class="fl">3.</span>tr))</span>
<span id="cb24-9"><a href="linear-models.html#cb24-9" tabindex="-1"></a><span class="co">#&gt; [1] 0.9613</span></span>
<span id="cb24-10"><a href="linear-models.html#cb24-10" tabindex="-1"></a><span class="fu">RMSE</span>(data.train<span class="sc">$</span>sales, <span class="fu">predict</span>(model.<span class="fl">4.</span>tr))</span>
<span id="cb24-11"><a href="linear-models.html#cb24-11" tabindex="-1"></a><span class="co">#&gt; [1] 0.641</span></span>
<span id="cb24-12"><a href="linear-models.html#cb24-12" tabindex="-1"></a><span class="fu">RMSE</span>(data.train<span class="sc">$</span>sales, <span class="fu">predict</span>(model.<span class="fl">5.</span>tr))</span>
<span id="cb24-13"><a href="linear-models.html#cb24-13" tabindex="-1"></a><span class="co">#&gt; [1] 0.6394</span></span></code></pre></div>
<p>Based on the results of the <code>RMSE()</code> function, the RMSE decreases as we go from <code>model.2.tr</code> to <code>model.5.tr</code>. This makes sense, as <code>model.2.tr</code> is the simplest model, and become more complex as we move to <code>model.1.tr</code> and then <code>model.3.tr</code>, <code>model.4.tr</code>, and finally <code>model.5.tr</code>.</p>
<p>The more complex the model, the smaller the training error in general.</p>
<p><strong>What about the Test RMSE?</strong></p>
<p>We know that performance in the test set is what we actually care about. We generate the five test RMSE statistics in the following code chunk.</p>
<p>Note that we use the <code>data.test$sales</code> as the vector of target variable values, and use <code>predict(model.#.tr, newdata=data.test)</code> as the vector of predicted fitted-values, specifying the <code>newdata</code> argument to use the <code>data.test</code> test set observations:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="linear-models.html#cb25-1" tabindex="-1"></a><span class="co"># CHUNK 23</span></span>
<span id="cb25-2"><a href="linear-models.html#cb25-2" tabindex="-1"></a><span class="fu">print</span>(<span class="st">&quot;TEST&quot;</span>)</span>
<span id="cb25-3"><a href="linear-models.html#cb25-3" tabindex="-1"></a><span class="co">#&gt; [1] &quot;TEST&quot;</span></span>
<span id="cb25-4"><a href="linear-models.html#cb25-4" tabindex="-1"></a><span class="fu">RMSE</span>(data.test<span class="sc">$</span>sales, <span class="fu">predict</span>(model.<span class="fl">1.</span>tr, <span class="at">newdata =</span> data.test))</span>
<span id="cb25-5"><a href="linear-models.html#cb25-5" tabindex="-1"></a><span class="co">#&gt; [1] 1.603</span></span>
<span id="cb25-6"><a href="linear-models.html#cb25-6" tabindex="-1"></a><span class="fu">RMSE</span>(data.test<span class="sc">$</span>sales, <span class="fu">predict</span>(model.<span class="fl">2.</span>tr, <span class="at">newdata =</span> data.test))</span>
<span id="cb25-7"><a href="linear-models.html#cb25-7" tabindex="-1"></a><span class="co">#&gt; [1] 1.582</span></span>
<span id="cb25-8"><a href="linear-models.html#cb25-8" tabindex="-1"></a><span class="fu">RMSE</span>(data.test<span class="sc">$</span>sales, <span class="fu">predict</span>(model.<span class="fl">3.</span>tr, <span class="at">newdata =</span> data.test))</span>
<span id="cb25-9"><a href="linear-models.html#cb25-9" tabindex="-1"></a><span class="co">#&gt; [1] 0.8765</span></span>
<span id="cb25-10"><a href="linear-models.html#cb25-10" tabindex="-1"></a><span class="fu">RMSE</span>(data.test<span class="sc">$</span>sales, <span class="fu">predict</span>(model.<span class="fl">4.</span>tr, <span class="at">newdata =</span> data.test))</span>
<span id="cb25-11"><a href="linear-models.html#cb25-11" tabindex="-1"></a><span class="co">#&gt; [1] 0.5383</span></span>
<span id="cb25-12"><a href="linear-models.html#cb25-12" tabindex="-1"></a><span class="fu">RMSE</span>(data.test<span class="sc">$</span>sales, <span class="fu">predict</span>(model.<span class="fl">5.</span>tr, <span class="at">newdata =</span> data.test))</span>
<span id="cb25-13"><a href="linear-models.html#cb25-13" tabindex="-1"></a><span class="co">#&gt; [1] 0.5589</span></span></code></pre></div>
<p>Based on the results of the above code chunk, the lowest test RMSE is achieved by <code>model.4.tr</code>, and therefore has the best perdiction performance.</p>
<p>The most complex model, <code>model.5.tr</code>, is not the best prediction performance and may have overfitted the data, so don’t think that using the most complex model is always the best idea as far as prediction is concerned.</p>
<p>If we have to recommend one model out of these five models, our recommendation would be to use <code>model.4.tr</code> as it produces the best prediction performance on the test set, is flexible enough to capture the signal in the data, but is not too complex.</p>
<hr />
</div>
</div>
</div>
<div id="case-study-2-feature-selection-and-regularization" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Case Study 2: Feature Selection and Regularization<a href="linear-models.html#case-study-2-feature-selection-and-regularization" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="about-this-case-study-1" class="section level3 unnumbered hasAnchor">
<h3>About this Case Study<a href="linear-models.html#about-this-case-study-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Dataset:</strong></p>
<ul>
<li><strong>Credit dataset from ISLR</strong>
<ul>
<li>More predictors (numeric + <strong>categorical</strong>)</li>
<li><strong>Feature selection</strong> is important</li>
</ul></li>
</ul>
<p><strong>Objectives</strong>:</p>
<ul>
<li>Know how to fit a linear model with <strong>categorical</strong> predictors in R.</li>
<li>Perform <strong>explicit binarization</strong> of categorical predictors in R and understand why doing so may be beneficial.</li>
<li>Perform <strong>stepwise selection</strong> using the <code>stepAIC()</code> function and be familiar with the options of this function.</li>
<li>Generate and interpret <strong>diagnostic plots</strong> for a linear model.</li>
<li>Fit <strong>regularized linear models</strong> in R.</li>
</ul>
<hr />
</div>
<div id="data-dictionary" class="section level3 unnumbered hasAnchor">
<h3>Data Dictionary<a href="linear-models.html#data-dictionary" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<thead>
<tr class="header">
<th>Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Income</td>
<td>Income ($10,000’s)</td>
</tr>
<tr class="even">
<td>Limit</td>
<td>Credit limit</td>
</tr>
<tr class="odd">
<td>Rating</td>
<td>Credit rating</td>
</tr>
<tr class="even">
<td>Cards</td>
<td>Number of credit cards</td>
</tr>
<tr class="odd">
<td>Age</td>
<td>Age in years</td>
</tr>
<tr class="even">
<td>Education</td>
<td>Number of years of education</td>
</tr>
<tr class="odd">
<td>Gender</td>
<td>Indicator of the individual’s gender</td>
</tr>
<tr class="even">
<td>Student</td>
<td>Indicator of whether individual was a student</td>
</tr>
<tr class="odd">
<td>Married</td>
<td>Indicator of whether individual was married</td>
</tr>
<tr class="even">
<td>Ethnicity</td>
<td>Indicator of the individual’s ethnicity</td>
</tr>
<tr class="odd">
<td>Balance</td>
<td>Average credit card balance ($) (target)</td>
</tr>
</tbody>
</table>
<p><strong>Objective</strong>: To identify and interpret <strong>key factors</strong> for Balance via appropriate linear models.</p>
<hr />
</div>
<div id="preparatory-work" class="section level3 hasAnchor" number="3.4.1">
<h3><span class="header-section-number">3.4.1</span> Preparatory Work<a href="linear-models.html#preparatory-work" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="task-1-consider-a-data-issue" class="section level3 unnumbered hasAnchor">
<h3>TASK 1: Consider a Data Issue<a href="linear-models.html#task-1-consider-a-data-issue" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="task-statement-2" class="section level4 unnumbered hasAnchor">
<h4>Task Statement<a href="linear-models.html#task-statement-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Identify a variable that may have potential <strong>ethical concerns</strong>. - Discuss the <strong>considerations</strong> (pros and cons) related to using this variable in a model for this business problem. - Regardless of any concerns, continue to use this variable in subsequent analyses.</p>
</div>
<div id="example-ethnicity" class="section level4 unnumbered hasAnchor">
<h4>Example: Ethnicity<a href="linear-models.html#example-ethnicity" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Pros</strong>: May provide potentially <strong>useful information</strong> for understanding/predicting credit card balance.</li>
<li><strong>Cons</strong>: Making ethnicity-based predictions may be criticized on grounds of <strong>discrimination</strong> and raise <strong>legal concerns</strong>.</li>
</ul>
<hr />
</div>
</div>
<div id="task-2-explore-the-numeric-variables" class="section level3 unnumbered hasAnchor">
<h3>TASK 2: Explore the Numeric Variables<a href="linear-models.html#task-2-explore-the-numeric-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="task-statement-3" class="section level4 unnumbered hasAnchor">
<h4>Task Statement<a href="linear-models.html#task-statement-3" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Investigate the distribution of the <strong>target variable</strong>.</li>
<li>Create a <strong>correlation matrix</strong>.
<ul>
<li>Examine the pairwise correlations.</li>
<li>Explain whether it is reasonable to delete the <strong>Limit</strong> variable. Regardless, delete this variable.</li>
</ul></li>
<li>Create <strong>visual representations</strong> to identify variables most likely to predict the target.</li>
</ul>
<p>In CHUNK 1, we load the <code>ISLR</code> package and attach the <code>Credit</code> data. We observe that the <code>Credit$ID</code> is an index column, so we set its values to <code>NULL</code> to remove it from the data. Then we print a summary of the dataset to preview key statistics about the fields in the data.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="linear-models.html#cb26-1" tabindex="-1"></a><span class="co"># CHUNK 1</span></span>
<span id="cb26-2"><a href="linear-models.html#cb26-2" tabindex="-1"></a><span class="co"># Uncomment the next line the first time you use ISLR</span></span>
<span id="cb26-3"><a href="linear-models.html#cb26-3" tabindex="-1"></a><span class="co">#install.packages(&quot;ISLR&quot;)</span></span>
<span id="cb26-4"><a href="linear-models.html#cb26-4" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb26-5"><a href="linear-models.html#cb26-5" tabindex="-1"></a><span class="fu">data</span>(Credit)</span>
<span id="cb26-6"><a href="linear-models.html#cb26-6" tabindex="-1"></a></span>
<span id="cb26-7"><a href="linear-models.html#cb26-7" tabindex="-1"></a><span class="co"># Delete the first column containing row indices</span></span>
<span id="cb26-8"><a href="linear-models.html#cb26-8" tabindex="-1"></a>Credit<span class="sc">$</span>ID <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb26-9"><a href="linear-models.html#cb26-9" tabindex="-1"></a></span>
<span id="cb26-10"><a href="linear-models.html#cb26-10" tabindex="-1"></a><span class="fu">summary</span>(Credit)</span>
<span id="cb26-11"><a href="linear-models.html#cb26-11" tabindex="-1"></a><span class="co">#&gt;      Income          Limit           Rating   </span></span>
<span id="cb26-12"><a href="linear-models.html#cb26-12" tabindex="-1"></a><span class="co">#&gt;  Min.   : 10.3   Min.   :  855   Min.   : 93  </span></span>
<span id="cb26-13"><a href="linear-models.html#cb26-13" tabindex="-1"></a><span class="co">#&gt;  1st Qu.: 21.0   1st Qu.: 3088   1st Qu.:247  </span></span>
<span id="cb26-14"><a href="linear-models.html#cb26-14" tabindex="-1"></a><span class="co">#&gt;  Median : 33.1   Median : 4622   Median :344  </span></span>
<span id="cb26-15"><a href="linear-models.html#cb26-15" tabindex="-1"></a><span class="co">#&gt;  Mean   : 45.2   Mean   : 4736   Mean   :355  </span></span>
<span id="cb26-16"><a href="linear-models.html#cb26-16" tabindex="-1"></a><span class="co">#&gt;  3rd Qu.: 57.5   3rd Qu.: 5873   3rd Qu.:437  </span></span>
<span id="cb26-17"><a href="linear-models.html#cb26-17" tabindex="-1"></a><span class="co">#&gt;  Max.   :186.6   Max.   :13913   Max.   :982  </span></span>
<span id="cb26-18"><a href="linear-models.html#cb26-18" tabindex="-1"></a><span class="co">#&gt;      Cards           Age         Education   </span></span>
<span id="cb26-19"><a href="linear-models.html#cb26-19" tabindex="-1"></a><span class="co">#&gt;  Min.   :1.00   Min.   :23.0   Min.   : 5.0  </span></span>
<span id="cb26-20"><a href="linear-models.html#cb26-20" tabindex="-1"></a><span class="co">#&gt;  1st Qu.:2.00   1st Qu.:41.8   1st Qu.:11.0  </span></span>
<span id="cb26-21"><a href="linear-models.html#cb26-21" tabindex="-1"></a><span class="co">#&gt;  Median :3.00   Median :56.0   Median :14.0  </span></span>
<span id="cb26-22"><a href="linear-models.html#cb26-22" tabindex="-1"></a><span class="co">#&gt;  Mean   :2.96   Mean   :55.7   Mean   :13.4  </span></span>
<span id="cb26-23"><a href="linear-models.html#cb26-23" tabindex="-1"></a><span class="co">#&gt;  3rd Qu.:4.00   3rd Qu.:70.0   3rd Qu.:16.0  </span></span>
<span id="cb26-24"><a href="linear-models.html#cb26-24" tabindex="-1"></a><span class="co">#&gt;  Max.   :9.00   Max.   :98.0   Max.   :20.0  </span></span>
<span id="cb26-25"><a href="linear-models.html#cb26-25" tabindex="-1"></a><span class="co">#&gt;     Gender    Student   Married  </span></span>
<span id="cb26-26"><a href="linear-models.html#cb26-26" tabindex="-1"></a><span class="co">#&gt;   Male :193   No :360   No :155  </span></span>
<span id="cb26-27"><a href="linear-models.html#cb26-27" tabindex="-1"></a><span class="co">#&gt;  Female:207   Yes: 40   Yes:245  </span></span>
<span id="cb26-28"><a href="linear-models.html#cb26-28" tabindex="-1"></a><span class="co">#&gt;                                  </span></span>
<span id="cb26-29"><a href="linear-models.html#cb26-29" tabindex="-1"></a><span class="co">#&gt;                                  </span></span>
<span id="cb26-30"><a href="linear-models.html#cb26-30" tabindex="-1"></a><span class="co">#&gt;                                  </span></span>
<span id="cb26-31"><a href="linear-models.html#cb26-31" tabindex="-1"></a><span class="co">#&gt;                                  </span></span>
<span id="cb26-32"><a href="linear-models.html#cb26-32" tabindex="-1"></a><span class="co">#&gt;             Ethnicity      Balance      </span></span>
<span id="cb26-33"><a href="linear-models.html#cb26-33" tabindex="-1"></a><span class="co">#&gt;  African American: 99   Min.   :   0.0  </span></span>
<span id="cb26-34"><a href="linear-models.html#cb26-34" tabindex="-1"></a><span class="co">#&gt;  Asian           :102   1st Qu.:  68.8  </span></span>
<span id="cb26-35"><a href="linear-models.html#cb26-35" tabindex="-1"></a><span class="co">#&gt;  Caucasian       :199   Median : 459.5  </span></span>
<span id="cb26-36"><a href="linear-models.html#cb26-36" tabindex="-1"></a><span class="co">#&gt;                         Mean   : 520.0  </span></span>
<span id="cb26-37"><a href="linear-models.html#cb26-37" tabindex="-1"></a><span class="co">#&gt;                         3rd Qu.: 863.0  </span></span>
<span id="cb26-38"><a href="linear-models.html#cb26-38" tabindex="-1"></a><span class="co">#&gt;                         Max.   :1999.0</span></span></code></pre></div>
<p>The summary output shows key statistics of the numeric variables, and counts of observations in each factor level for categorical variables.</p>
<p>The target variable, <code>balance</code>, ranges from 0.00 to 1999.00 and the mean is higher than the median by quite a lot. From these two numbers, you can deduce that the distribution of <code>balance</code> has a heavy tail.</p>
<p>We can visualize the distribution of <code>balance</code> by creating a histogram.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="linear-models.html#cb27-1" tabindex="-1"></a><span class="co"># CHUNK 2</span></span>
<span id="cb27-2"><a href="linear-models.html#cb27-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb27-3"><a href="linear-models.html#cb27-3" tabindex="-1"></a><span class="fu">ggplot</span>(Credit, <span class="fu">aes</span>(<span class="at">x =</span> Balance)) <span class="sc">+</span></span>
<span id="cb27-4"><a href="linear-models.html#cb27-4" tabindex="-1"></a>  <span class="fu">geom_histogram</span>()</span></code></pre></div>
<p><img src="figures/unnamed-chunk-31-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>From the histogram, we see there are an abundance of observations where <code>balance</code> is zero. We can check the number of observations with <code>balance</code> of zero by running the following code chunk:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="linear-models.html#cb28-1" tabindex="-1"></a><span class="fu">nrow</span>(Credit[Credit<span class="sc">$</span>Balance <span class="sc">==</span> <span class="dv">0</span>, ])  <span class="co"># OR sum(Credit$Balance == 0)</span></span>
<span id="cb28-2"><a href="linear-models.html#cb28-2" tabindex="-1"></a><span class="co">#&gt; [1] 90</span></span></code></pre></div>
<p>Your first instinct may be to perform a log-transformation on <code>balance</code> since the histogram shows a severe right-skew, however, we cannot perform a log-transformation, since there are quite a lot of observations that have a <code>balance</code> of zero.</p>
<p>For this case study, we will not adjust <code>balance</code> – we will take it as is. If you are interested, you can take a transformation like square-root to reduce the right-skew of the <code>balance</code> target variable and repeat the whole case study.</p>
<p>Next, we will turn to the relationship of each numeric predictor and the target variable by performing bivariate exploration. We create a correlation matrix on the numeric variables.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="linear-models.html#cb29-1" tabindex="-1"></a><span class="co"># CHUNK 3</span></span>
<span id="cb29-2"><a href="linear-models.html#cb29-2" tabindex="-1"></a><span class="co"># Calculate the correlation matrix for numeric variables</span></span>
<span id="cb29-3"><a href="linear-models.html#cb29-3" tabindex="-1"></a><span class="co"># The numeric predictors are in the first 6 columns</span></span>
<span id="cb29-4"><a href="linear-models.html#cb29-4" tabindex="-1"></a>cor.matrix <span class="ot">&lt;-</span> <span class="fu">cor</span>(Credit[, <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="dv">11</span>)])</span>
<span id="cb29-5"><a href="linear-models.html#cb29-5" tabindex="-1"></a><span class="fu">print</span>(<span class="st">&quot;Correlation Matrix&quot;</span>)</span>
<span id="cb29-6"><a href="linear-models.html#cb29-6" tabindex="-1"></a><span class="co">#&gt; [1] &quot;Correlation Matrix&quot;</span></span>
<span id="cb29-7"><a href="linear-models.html#cb29-7" tabindex="-1"></a><span class="fu">round</span>(cor.matrix, <span class="at">digits =</span> <span class="dv">4</span>)</span>
<span id="cb29-8"><a href="linear-models.html#cb29-8" tabindex="-1"></a><span class="co">#&gt;            Income   Limit  Rating   Cards    Age</span></span>
<span id="cb29-9"><a href="linear-models.html#cb29-9" tabindex="-1"></a><span class="co">#&gt; Income     1.0000  0.7921  0.7914 -0.0183 0.1753</span></span>
<span id="cb29-10"><a href="linear-models.html#cb29-10" tabindex="-1"></a><span class="co">#&gt; Limit      0.7921  1.0000  0.9969  0.0102 0.1009</span></span>
<span id="cb29-11"><a href="linear-models.html#cb29-11" tabindex="-1"></a><span class="co">#&gt; Rating     0.7914  0.9969  1.0000  0.0532 0.1032</span></span>
<span id="cb29-12"><a href="linear-models.html#cb29-12" tabindex="-1"></a><span class="co">#&gt; Cards     -0.0183  0.0102  0.0532  1.0000 0.0429</span></span>
<span id="cb29-13"><a href="linear-models.html#cb29-13" tabindex="-1"></a><span class="co">#&gt; Age        0.1753  0.1009  0.1032  0.0429 1.0000</span></span>
<span id="cb29-14"><a href="linear-models.html#cb29-14" tabindex="-1"></a><span class="co">#&gt; Education -0.0277 -0.0235 -0.0301 -0.0511 0.0036</span></span>
<span id="cb29-15"><a href="linear-models.html#cb29-15" tabindex="-1"></a><span class="co">#&gt; Balance    0.4637  0.8617  0.8636  0.0865 0.0018</span></span>
<span id="cb29-16"><a href="linear-models.html#cb29-16" tabindex="-1"></a><span class="co">#&gt;           Education Balance</span></span>
<span id="cb29-17"><a href="linear-models.html#cb29-17" tabindex="-1"></a><span class="co">#&gt; Income      -0.0277  0.4637</span></span>
<span id="cb29-18"><a href="linear-models.html#cb29-18" tabindex="-1"></a><span class="co">#&gt; Limit       -0.0235  0.8617</span></span>
<span id="cb29-19"><a href="linear-models.html#cb29-19" tabindex="-1"></a><span class="co">#&gt; Rating      -0.0301  0.8636</span></span>
<span id="cb29-20"><a href="linear-models.html#cb29-20" tabindex="-1"></a><span class="co">#&gt; Cards       -0.0511  0.0865</span></span>
<span id="cb29-21"><a href="linear-models.html#cb29-21" tabindex="-1"></a><span class="co">#&gt; Age          0.0036  0.0018</span></span>
<span id="cb29-22"><a href="linear-models.html#cb29-22" tabindex="-1"></a><span class="co">#&gt; Education    1.0000 -0.0081</span></span>
<span id="cb29-23"><a href="linear-models.html#cb29-23" tabindex="-1"></a><span class="co">#&gt; Balance     -0.0081  1.0000</span></span></code></pre></div>
<p><strong>What can we tell from the correlations between the target and predictors?</strong></p>
<p>Based on the correlation matrix, we can see that the variables <code>Limit</code>, and <code>Rating</code> have a strong linear positive relationship with <code>Balance</code> since those predictors have a large correlation in absolute value that is close to 1, and <code>Income</code> is moderately related to <code>Balance</code>.</p>
<p>At this point, we can conjecture that <code>Income</code>, <code>Rating</code> and <code>Limit</code> are important predictors of <code>Balance</code>.</p>
<p><strong>What about the correlations between the predictors?</strong></p>
<p>Some correlations between predictors, such as <code>Limit</code> and <code>Rating</code> which is almost 1 <span class="math inline">\(\Rightarrow\)</span> <code>Limit</code> and <code>Rating</code> are almost perfectly linearly related.</p>
<p>We can confirm this by making a scatterplot for these two variables, which is done in the following code chunk:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="linear-models.html#cb30-1" tabindex="-1"></a><span class="co"># CHUNK 4</span></span>
<span id="cb30-2"><a href="linear-models.html#cb30-2" tabindex="-1"></a><span class="fu">ggplot</span>(Credit, <span class="fu">aes</span>(<span class="at">x =</span> Limit, <span class="at">y =</span> Rating)) <span class="sc">+</span></span>
<span id="cb30-3"><a href="linear-models.html#cb30-3" tabindex="-1"></a>  <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="figures/unnamed-chunk-34-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Since the scatterplot almost perfectly follows the 45-degree line. If we know the value of one variable, we know the value of the other variable almost exactly. The other variable does not contribute that much extra information. Therefore, it is reasonable to keep only one of the variables and we can remove the other variables to avoid <strong>collinearity</strong>, or duplication of information.</p>
<p>If you go back to correlation matrix, <code>Rating</code> has a slightly higher correlation with <code>Balance</code>, so we remove the <code>Limit</code> variable from the dataset:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="linear-models.html#cb31-1" tabindex="-1"></a><span class="co"># Delete Limit</span></span>
<span id="cb31-2"><a href="linear-models.html#cb31-2" tabindex="-1"></a>Credit<span class="sc">$</span>Limit <span class="ot">&lt;-</span> <span class="cn">NULL</span></span></code></pre></div>
<p>Correlations are only a summary of the linear relationship between the target variable and each of the numeric predictors.</p>
<p>We can use scatterplots to visualize the relationships. If the relationships are more complex, and far from linear, the scatterplots can also help review that much more effectively than the correlation matrix.</p>
<p>In the following code chunk, we use a <code>for-loop</code> to make a scatterplot for <code>Balance</code> against each of the numeric predictors:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="linear-models.html#cb32-1" tabindex="-1"></a><span class="co"># CHUNK 5</span></span>
<span id="cb32-2"><a href="linear-models.html#cb32-2" tabindex="-1"></a><span class="co"># first save the names of the numeric predictors as a vector</span></span>
<span id="cb32-3"><a href="linear-models.html#cb32-3" tabindex="-1"></a>vars.numeric <span class="ot">&lt;-</span> <span class="fu">colnames</span>(Credit[, <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>])</span>
<span id="cb32-4"><a href="linear-models.html#cb32-4" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> vars.numeric) {</span>
<span id="cb32-5"><a href="linear-models.html#cb32-5" tabindex="-1"></a>  plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(Credit, <span class="fu">aes</span>(<span class="at">x =</span> Credit[, i], <span class="at">y =</span> Balance)) <span class="sc">+</span></span>
<span id="cb32-6"><a href="linear-models.html#cb32-6" tabindex="-1"></a>    <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb32-7"><a href="linear-models.html#cb32-7" tabindex="-1"></a>    <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb32-8"><a href="linear-models.html#cb32-8" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">x =</span> i)</span>
<span id="cb32-9"><a href="linear-models.html#cb32-9" tabindex="-1"></a>  <span class="fu">print</span>(plot)</span>
<span id="cb32-10"><a href="linear-models.html#cb32-10" tabindex="-1"></a>}</span></code></pre></div>
<p><img src="figures/unnamed-chunk-36-1.png" width="100%" style="display: block; margin: auto;" /><img src="figures/unnamed-chunk-36-2.png" width="100%" style="display: block; margin: auto;" /><img src="figures/unnamed-chunk-36-3.png" width="100%" style="display: block; margin: auto;" /><img src="figures/unnamed-chunk-36-4.png" width="100%" style="display: block; margin: auto;" /><img src="figures/unnamed-chunk-36-5.png" width="100%" style="display: block; margin: auto;" /></p>
<p>From these scatterplots, you can have a sense of which predictors have a strong effect on <code>Balance</code>:</p>
<ul>
<li><code>Income</code> is strong; slight upward trend.</li>
<li><code>Rating</code> is very strong; strong upward trend.</li>
<li>The other three do not seem that strong; almost flat. That means that balance doesn’t respond much to these three predictors.</li>
</ul>
<p>These graphs suggest that only <code>Income</code> and <code>Rating</code> seem to be important predictors of <code>Balance</code>, which is consistent with what we saw in the correlation matrix.</p>
<hr />
</div>
</div>
<div id="task-3-explore-the-factor-variables" class="section level3 unnumbered hasAnchor">
<h3>TASK 3: Explore the Factor Variables<a href="linear-models.html#task-3-explore-the-factor-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="task-statement-4" class="section level4 unnumbered hasAnchor">
<h4>Task Statement<a href="linear-models.html#task-statement-4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Identify a <strong>factor</strong> variable that is likely to predict the target. For this factor variable, perform the following:</p>
<ul>
<li>Show key <strong>descriptive statistics</strong>.</li>
<li>Create <strong>visual representations</strong> (e.g., graphs, charts).</li>
<li>Explain why you selected this variable and how the variable relates to the target variable.</li>
</ul>
<p>In the following code chunk, we produce the summary statistics in relation to the target variable for each factor level of the categorical variables. These means and medians will tell us which factor variables are likely to have predictive power:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="linear-models.html#cb33-1" tabindex="-1"></a><span class="co"># CHUNK 6</span></span>
<span id="cb33-2"><a href="linear-models.html#cb33-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb33-3"><a href="linear-models.html#cb33-3" tabindex="-1"></a></span>
<span id="cb33-4"><a href="linear-models.html#cb33-4" tabindex="-1"></a><span class="co"># Save the names of the categorical predictors as a vector</span></span>
<span id="cb33-5"><a href="linear-models.html#cb33-5" tabindex="-1"></a>vars.categorical <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Gender&quot;</span>, <span class="st">&quot;Student&quot;</span>, <span class="st">&quot;Married&quot;</span>, <span class="st">&quot;Ethnicity&quot;</span>)</span>
<span id="cb33-6"><a href="linear-models.html#cb33-6" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> vars.categorical) {</span>
<span id="cb33-7"><a href="linear-models.html#cb33-7" tabindex="-1"></a>  x <span class="ot">&lt;-</span> Credit <span class="sc">%&gt;%</span></span>
<span id="cb33-8"><a href="linear-models.html#cb33-8" tabindex="-1"></a>    <span class="fu">group_by_</span>(i) <span class="sc">%&gt;%</span></span>
<span id="cb33-9"><a href="linear-models.html#cb33-9" tabindex="-1"></a>    <span class="fu">summarize</span>(</span>
<span id="cb33-10"><a href="linear-models.html#cb33-10" tabindex="-1"></a>      <span class="at">mean =</span> <span class="fu">mean</span>(Balance),</span>
<span id="cb33-11"><a href="linear-models.html#cb33-11" tabindex="-1"></a>      <span class="at">median =</span> <span class="fu">median</span>(Balance),</span>
<span id="cb33-12"><a href="linear-models.html#cb33-12" tabindex="-1"></a>      <span class="at">n =</span> <span class="fu">n</span>()</span>
<span id="cb33-13"><a href="linear-models.html#cb33-13" tabindex="-1"></a>      )</span>
<span id="cb33-14"><a href="linear-models.html#cb33-14" tabindex="-1"></a>  <span class="fu">print</span>(x)</span>
<span id="cb33-15"><a href="linear-models.html#cb33-15" tabindex="-1"></a>}</span>
<span id="cb33-16"><a href="linear-models.html#cb33-16" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 × 4</span></span>
<span id="cb33-17"><a href="linear-models.html#cb33-17" tabindex="-1"></a><span class="co">#&gt;   Gender    mean median     n</span></span>
<span id="cb33-18"><a href="linear-models.html#cb33-18" tabindex="-1"></a><span class="co">#&gt;   &lt;fct&gt;    &lt;dbl&gt;  &lt;int&gt; &lt;int&gt;</span></span>
<span id="cb33-19"><a href="linear-models.html#cb33-19" tabindex="-1"></a><span class="co">#&gt; 1 &quot; Male&quot;   510.    463   193</span></span>
<span id="cb33-20"><a href="linear-models.html#cb33-20" tabindex="-1"></a><span class="co">#&gt; 2 &quot;Female&quot;  530.    456   207</span></span>
<span id="cb33-21"><a href="linear-models.html#cb33-21" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 × 4</span></span>
<span id="cb33-22"><a href="linear-models.html#cb33-22" tabindex="-1"></a><span class="co">#&gt;   Student  mean median     n</span></span>
<span id="cb33-23"><a href="linear-models.html#cb33-23" tabindex="-1"></a><span class="co">#&gt;   &lt;fct&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;</span></span>
<span id="cb33-24"><a href="linear-models.html#cb33-24" tabindex="-1"></a><span class="co">#&gt; 1 No       480.    424   360</span></span>
<span id="cb33-25"><a href="linear-models.html#cb33-25" tabindex="-1"></a><span class="co">#&gt; 2 Yes      877.    953    40</span></span>
<span id="cb33-26"><a href="linear-models.html#cb33-26" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 × 4</span></span>
<span id="cb33-27"><a href="linear-models.html#cb33-27" tabindex="-1"></a><span class="co">#&gt;   Married  mean median     n</span></span>
<span id="cb33-28"><a href="linear-models.html#cb33-28" tabindex="-1"></a><span class="co">#&gt;   &lt;fct&gt;   &lt;dbl&gt;  &lt;int&gt; &lt;int&gt;</span></span>
<span id="cb33-29"><a href="linear-models.html#cb33-29" tabindex="-1"></a><span class="co">#&gt; 1 No       523.    467   155</span></span>
<span id="cb33-30"><a href="linear-models.html#cb33-30" tabindex="-1"></a><span class="co">#&gt; 2 Yes      518.    454   245</span></span>
<span id="cb33-31"><a href="linear-models.html#cb33-31" tabindex="-1"></a><span class="co">#&gt; # A tibble: 3 × 4</span></span>
<span id="cb33-32"><a href="linear-models.html#cb33-32" tabindex="-1"></a><span class="co">#&gt;   Ethnicity         mean median     n</span></span>
<span id="cb33-33"><a href="linear-models.html#cb33-33" tabindex="-1"></a><span class="co">#&gt;   &lt;fct&gt;            &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;</span></span>
<span id="cb33-34"><a href="linear-models.html#cb33-34" tabindex="-1"></a><span class="co">#&gt; 1 African American  531     480    99</span></span>
<span id="cb33-35"><a href="linear-models.html#cb33-35" tabindex="-1"></a><span class="co">#&gt; 2 Asian             512.    414   102</span></span>
<span id="cb33-36"><a href="linear-models.html#cb33-36" tabindex="-1"></a><span class="co">#&gt; 3 Caucasian         518.    465   199</span></span></code></pre></div>
<p>From the summary output, you can see the mean and median for <code>Student</code> is much higher for those that are students than for those who are not students. The characteristic of being a student says a lot about the behavior of the target variable <code>Balance</code>. This demonstrates the predictive power of <code>Student</code> as a predictor.</p>
<p>For the other three factor variables, <code>Gender</code>, <code>Married</code> and <code>Ethnicity</code>, the mean and median are relatively close across factor levels. That means the information contained in these variablesis not very effective for understanding or predicting the target variable <code>Balance</code>.</p>
<p>We can reinforce our observations by constructing boxplots for <code>Balance</code> split by the factor variables, which is performed in the next code chunk:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="linear-models.html#cb34-1" tabindex="-1"></a><span class="co"># CHUNK 7</span></span>
<span id="cb34-2"><a href="linear-models.html#cb34-2" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> vars.categorical) {</span>
<span id="cb34-3"><a href="linear-models.html#cb34-3" tabindex="-1"></a>  plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(Credit, <span class="fu">aes</span>(<span class="at">x =</span> Credit[, i], <span class="at">y =</span> Balance)) <span class="sc">+</span></span>
<span id="cb34-4"><a href="linear-models.html#cb34-4" tabindex="-1"></a>    <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb34-5"><a href="linear-models.html#cb34-5" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">x =</span> i)</span>
<span id="cb34-6"><a href="linear-models.html#cb34-6" tabindex="-1"></a>  <span class="fu">print</span>(plot)</span>
<span id="cb34-7"><a href="linear-models.html#cb34-7" tabindex="-1"></a>}</span></code></pre></div>
<p><img src="figures/unnamed-chunk-38-1.png" width="100%" style="display: block; margin: auto;" /><img src="figures/unnamed-chunk-38-2.png" width="100%" style="display: block; margin: auto;" /><img src="figures/unnamed-chunk-38-3.png" width="100%" style="display: block; margin: auto;" /><img src="figures/unnamed-chunk-38-4.png" width="100%" style="display: block; margin: auto;" /></p>
<p>From the boxplots, you can see that for <code>Student</code>, the boxplot is situated much higher for those observations that are students than for those who are non-students.</p>
<p>For the other factor variables, the boxes have very similar levels and very close medians. These variables cannot differentiate high and low values of balance effectively.</p>
<p>So out of the four factor variables, only <code>Student</code> seems to be a significant predictor for <code>Balance</code>.</p>
<hr />
</div>
</div>
<div id="task-4-consider-two-graphs" class="section level3 unnumbered hasAnchor">
<h3>TASK 4: Consider Two Graphs<a href="linear-models.html#task-4-consider-two-graphs" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="task-statement-5" class="section level4 unnumbered hasAnchor">
<h4>Task Statement<a href="linear-models.html#task-statement-5" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Your assistant has built the following two plots and asked for your comments:</p>
<ol style="list-style-type: decimal">
<li>A boxplot of <strong>Age</strong> by <strong>Student</strong>.</li>
<li>A scatterplot of <strong>Balance</strong> against <strong>Income</strong> colored by <strong>Student</strong>.
<ul>
<li>Run the code to make them.</li>
<li>Include them in your response.</li>
<li>State your <strong>observations</strong> and discuss the <strong>impact</strong>, if any, of each plot on your later modeling.</li>
</ul></li>
</ol>
<p>In the following code chunk, we create a boxplot of <code>Student</code> against <code>Age</code>:</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="linear-models.html#cb35-1" tabindex="-1"></a><span class="co"># CHUNK 8</span></span>
<span id="cb35-2"><a href="linear-models.html#cb35-2" tabindex="-1"></a><span class="fu">ggplot</span>(Credit, <span class="fu">aes</span>(<span class="at">x =</span> Student, <span class="at">y =</span> Age)) <span class="sc">+</span></span>
<span id="cb35-3"><a href="linear-models.html#cb35-3" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>()</span></code></pre></div>
<p><img src="figures/unnamed-chunk-39-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>From the boxplot, we can see that <code>Age</code> <u>does not</u> seem to be an important predictor of <code>Balance</code> since the boxplots do not show much information being gained. This was also confirmed in our correlation matrix.</p>
<p>If we use both <code>Age</code> and <code>Student</code> variables at the same time, then our model may have difficulty separating the individual effects of the two variables on <code>Balance</code>.</p>
<p>In the following code chunk, we make a scatterplot of <code>Balance</code> against <code>Income</code> colored by <code>Student</code>:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="linear-models.html#cb36-1" tabindex="-1"></a><span class="fu">ggplot</span>(Credit, <span class="fu">aes</span>(<span class="at">x =</span> Income, <span class="at">y =</span> Balance, <span class="at">color =</span> Student)) <span class="sc">+</span></span>
<span id="cb36-2"><a href="linear-models.html#cb36-2" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb36-3"><a href="linear-models.html#cb36-3" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="figures/unnamed-chunk-40-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>We can see that the two slopes for the different factor levels of <code>Student</code> are quite different from each other. This graph suggests that <code>Income</code> has a different effect on <code>Balance</code> for students and non-students.</p>
<p>From what we have previously learned, there may be an <strong>interaction</strong> between <code>Income</code> and <code>Student</code> when they serve as predictors for <code>Balance</code>.</p>
<p>In the later part of this case study, we will consider the interaction between <code>Income</code> and <code>Student</code> into account when we construct linear models.</p>
<hr />
</div>
</div>
<div id="task-5-explore-the-effect-of-releveling-factor-variables" class="section level3 unnumbered hasAnchor">
<h3>TASK 5: Explore the Effect of Releveling Factor Variables<a href="linear-models.html#task-5-explore-the-effect-of-releveling-factor-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="task-statement-6" class="section level4 unnumbered hasAnchor">
<h4>Task Statement<a href="linear-models.html#task-statement-6" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Split the data into training and test sets.</li>
<li>Fit a multiple linear regression model for <strong>Balance</strong> on all variables (except <strong>Limit</strong>) on the training set. Be sure to take note of the implications in Task 4. Interpret the <strong>coefficient estimates</strong> for <strong>Married</strong> and for the <strong>Asian</strong> level of <strong>Ethnicity</strong>.</li>
<li><strong>Relevel</strong> the factor variables so that the most frequent level becomes the baseline level and refit the multiple linear regression model. Interpret the coefficient estimates for <strong>Married</strong> and for the <strong>Asian</strong> level of <strong>Ethnicity</strong> again.</li>
</ul>
<div id="overall-objective" class="section level5 unnumbered hasAnchor">
<h5>Overall Objective<a href="linear-models.html#overall-objective" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>To understand how <strong>categorical predictors</strong> are handled by the <code>lm()</code> function.</p>
<p>We’ll start this task by performing the training/test set split and comparing the mean of the target variable <code>Balance</code> in each of the data sets:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="linear-models.html#cb37-1" tabindex="-1"></a><span class="co"># CHUNK 9</span></span>
<span id="cb37-2"><a href="linear-models.html#cb37-2" tabindex="-1"></a><span class="co"># Load packages</span></span>
<span id="cb37-3"><a href="linear-models.html#cb37-3" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb37-4"><a href="linear-models.html#cb37-4" tabindex="-1"></a></span>
<span id="cb37-5"><a href="linear-models.html#cb37-5" tabindex="-1"></a><span class="co"># Set a random seed</span></span>
<span id="cb37-6"><a href="linear-models.html#cb37-6" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">8964</span>)</span>
<span id="cb37-7"><a href="linear-models.html#cb37-7" tabindex="-1"></a></span>
<span id="cb37-8"><a href="linear-models.html#cb37-8" tabindex="-1"></a><span class="co"># Split the data into training and test sets</span></span>
<span id="cb37-9"><a href="linear-models.html#cb37-9" tabindex="-1"></a>partition <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(Credit<span class="sc">$</span>Balance, <span class="at">p =</span> <span class="fl">0.75</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb37-10"><a href="linear-models.html#cb37-10" tabindex="-1"></a>data.train <span class="ot">&lt;-</span> Credit[partition, ]</span>
<span id="cb37-11"><a href="linear-models.html#cb37-11" tabindex="-1"></a>data.test <span class="ot">&lt;-</span> Credit[<span class="sc">-</span>partition, ]</span>
<span id="cb37-12"><a href="linear-models.html#cb37-12" tabindex="-1"></a></span>
<span id="cb37-13"><a href="linear-models.html#cb37-13" tabindex="-1"></a><span class="co"># Compare the distribution of the target variable in each set</span></span>
<span id="cb37-14"><a href="linear-models.html#cb37-14" tabindex="-1"></a><span class="fu">print</span>(<span class="st">&quot;TRAIN&quot;</span>)</span>
<span id="cb37-15"><a href="linear-models.html#cb37-15" tabindex="-1"></a><span class="co">#&gt; [1] &quot;TRAIN&quot;</span></span>
<span id="cb37-16"><a href="linear-models.html#cb37-16" tabindex="-1"></a><span class="fu">mean</span>(data.train<span class="sc">$</span>Balance)</span>
<span id="cb37-17"><a href="linear-models.html#cb37-17" tabindex="-1"></a><span class="co">#&gt; [1] 520.4</span></span>
<span id="cb37-18"><a href="linear-models.html#cb37-18" tabindex="-1"></a></span>
<span id="cb37-19"><a href="linear-models.html#cb37-19" tabindex="-1"></a><span class="fu">print</span>(<span class="st">&quot;TEST&quot;</span>)</span>
<span id="cb37-20"><a href="linear-models.html#cb37-20" tabindex="-1"></a><span class="co">#&gt; [1] &quot;TEST&quot;</span></span>
<span id="cb37-21"><a href="linear-models.html#cb37-21" tabindex="-1"></a><span class="fu">mean</span>(data.test<span class="sc">$</span>Balance)</span>
<span id="cb37-22"><a href="linear-models.html#cb37-22" tabindex="-1"></a><span class="co">#&gt; [1] 518.7</span></span></code></pre></div>
<p>Next, we fit a multiple linear regression model for <strong>Balance</strong> on all variables (except <strong>Limit</strong>) on the training set and take note of the implications in Task 4. We then Interpret the <strong>coefficient estimates</strong> for <strong>Married</strong> and for the <strong>Asian</strong> level of <strong>Ethnicity</strong>.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="linear-models.html#cb38-1" tabindex="-1"></a><span class="co"># CHUNK 10</span></span>
<span id="cb38-2"><a href="linear-models.html#cb38-2" tabindex="-1"></a>model.full <span class="ot">&lt;-</span> <span class="fu">lm</span>(Balance <span class="sc">~</span> . <span class="sc">+</span> Income<span class="sc">:</span>Student, <span class="at">data =</span> data.train)</span>
<span id="cb38-3"><a href="linear-models.html#cb38-3" tabindex="-1"></a><span class="fu">summary</span>(model.full)</span>
<span id="cb38-4"><a href="linear-models.html#cb38-4" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb38-5"><a href="linear-models.html#cb38-5" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb38-6"><a href="linear-models.html#cb38-6" tabindex="-1"></a><span class="co">#&gt; lm(formula = Balance ~ . + Income:Student, data = data.train)</span></span>
<span id="cb38-7"><a href="linear-models.html#cb38-7" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb38-8"><a href="linear-models.html#cb38-8" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb38-9"><a href="linear-models.html#cb38-9" tabindex="-1"></a><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></span>
<span id="cb38-10"><a href="linear-models.html#cb38-10" tabindex="-1"></a><span class="co">#&gt; -189.2  -76.5  -15.6   66.7  296.2 </span></span>
<span id="cb38-11"><a href="linear-models.html#cb38-11" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb38-12"><a href="linear-models.html#cb38-12" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb38-13"><a href="linear-models.html#cb38-13" tabindex="-1"></a><span class="co">#&gt;                     Estimate Std. Error t value</span></span>
<span id="cb38-14"><a href="linear-models.html#cb38-14" tabindex="-1"></a><span class="co">#&gt; (Intercept)        -552.3435    40.3454  -13.69</span></span>
<span id="cb38-15"><a href="linear-models.html#cb38-15" tabindex="-1"></a><span class="co">#&gt; Income               -7.9386     0.2946  -26.94</span></span>
<span id="cb38-16"><a href="linear-models.html#cb38-16" tabindex="-1"></a><span class="co">#&gt; Rating                4.0125     0.0642   62.54</span></span>
<span id="cb38-17"><a href="linear-models.html#cb38-17" tabindex="-1"></a><span class="co">#&gt; Cards                 2.8977     4.6917    0.62</span></span>
<span id="cb38-18"><a href="linear-models.html#cb38-18" tabindex="-1"></a><span class="co">#&gt; Age                  -0.7878     0.3599   -2.19</span></span>
<span id="cb38-19"><a href="linear-models.html#cb38-19" tabindex="-1"></a><span class="co">#&gt; Education             0.8892     1.9204    0.46</span></span>
<span id="cb38-20"><a href="linear-models.html#cb38-20" tabindex="-1"></a><span class="co">#&gt; GenderFemale        -18.3703    12.0087   -1.53</span></span>
<span id="cb38-21"><a href="linear-models.html#cb38-21" tabindex="-1"></a><span class="co">#&gt; StudentYes          395.6774    30.7230   12.88</span></span>
<span id="cb38-22"><a href="linear-models.html#cb38-22" tabindex="-1"></a><span class="co">#&gt; MarriedYes          -20.4647    12.3974   -1.65</span></span>
<span id="cb38-23"><a href="linear-models.html#cb38-23" tabindex="-1"></a><span class="co">#&gt; EthnicityAsian        6.5327    17.1379    0.38</span></span>
<span id="cb38-24"><a href="linear-models.html#cb38-24" tabindex="-1"></a><span class="co">#&gt; EthnicityCaucasian   11.9539    14.8244    0.81</span></span>
<span id="cb38-25"><a href="linear-models.html#cb38-25" tabindex="-1"></a><span class="co">#&gt; Income:StudentYes     0.5010     0.5003    1.00</span></span>
<span id="cb38-26"><a href="linear-models.html#cb38-26" tabindex="-1"></a><span class="co">#&gt;                    Pr(&gt;|t|)    </span></span>
<span id="cb38-27"><a href="linear-models.html#cb38-27" tabindex="-1"></a><span class="co">#&gt; (Intercept)          &lt;2e-16 ***</span></span>
<span id="cb38-28"><a href="linear-models.html#cb38-28" tabindex="-1"></a><span class="co">#&gt; Income               &lt;2e-16 ***</span></span>
<span id="cb38-29"><a href="linear-models.html#cb38-29" tabindex="-1"></a><span class="co">#&gt; Rating               &lt;2e-16 ***</span></span>
<span id="cb38-30"><a href="linear-models.html#cb38-30" tabindex="-1"></a><span class="co">#&gt; Cards                 0.537    </span></span>
<span id="cb38-31"><a href="linear-models.html#cb38-31" tabindex="-1"></a><span class="co">#&gt; Age                   0.029 *  </span></span>
<span id="cb38-32"><a href="linear-models.html#cb38-32" tabindex="-1"></a><span class="co">#&gt; Education             0.644    </span></span>
<span id="cb38-33"><a href="linear-models.html#cb38-33" tabindex="-1"></a><span class="co">#&gt; GenderFemale          0.127    </span></span>
<span id="cb38-34"><a href="linear-models.html#cb38-34" tabindex="-1"></a><span class="co">#&gt; StudentYes           &lt;2e-16 ***</span></span>
<span id="cb38-35"><a href="linear-models.html#cb38-35" tabindex="-1"></a><span class="co">#&gt; MarriedYes            0.100 .  </span></span>
<span id="cb38-36"><a href="linear-models.html#cb38-36" tabindex="-1"></a><span class="co">#&gt; EthnicityAsian        0.703    </span></span>
<span id="cb38-37"><a href="linear-models.html#cb38-37" tabindex="-1"></a><span class="co">#&gt; EthnicityCaucasian    0.421    </span></span>
<span id="cb38-38"><a href="linear-models.html#cb38-38" tabindex="-1"></a><span class="co">#&gt; Income:StudentYes     0.317    </span></span>
<span id="cb38-39"><a href="linear-models.html#cb38-39" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb38-40"><a href="linear-models.html#cb38-40" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  </span></span>
<span id="cb38-41"><a href="linear-models.html#cb38-41" tabindex="-1"></a><span class="co">#&gt; 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb38-42"><a href="linear-models.html#cb38-42" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb38-43"><a href="linear-models.html#cb38-43" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 103 on 289 degrees of freedom</span></span>
<span id="cb38-44"><a href="linear-models.html#cb38-44" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.952,  Adjusted R-squared:  0.95 </span></span>
<span id="cb38-45"><a href="linear-models.html#cb38-45" tabindex="-1"></a><span class="co">#&gt; F-statistic:  521 on 11 and 289 DF,  p-value: &lt;2e-16</span></span></code></pre></div>
<p>Based on the summary out, the <code>Income</code>, <code>Rating</code>, <code>Age</code> and/or <code>Student</code> variables are statistically signifcant. The Multiple R-Squared for <code>model.full</code> is 0.952 or 95.2% which means the goodness-of-fit is fairly high.</p>
<p>By default, R will use alphabetical ordering of factor levels to determine the baseline level for each factor variable.</p>
<p>Based on the coefficients of the factor variables, we can see that the <code>Balance</code> is, on average, 20.46469 lower for married observations than the balance for unmarried observations.</p>
<p>We can also say that the <code>Balance</code> for Asian is higher than the <code>Balance</code> of African (the baseline level), by an average of 6.53269, all else equal.</p>
<p><strong>For factor variables, the comparisons of coefficients are always with respect to the baseline level.</strong></p>
<p>The following code chunk relevels the factor variables by making the most common factor level the baseline level:</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="linear-models.html#cb39-1" tabindex="-1"></a><span class="co"># CHUNK 11</span></span>
<span id="cb39-2"><a href="linear-models.html#cb39-2" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> vars.categorical){</span>
<span id="cb39-3"><a href="linear-models.html#cb39-3" tabindex="-1"></a>  <span class="co"># Use the table() function to calculate the frequencies for each factor</span></span>
<span id="cb39-4"><a href="linear-models.html#cb39-4" tabindex="-1"></a>  table <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">table</span>(Credit[, i]))</span>
<span id="cb39-5"><a href="linear-models.html#cb39-5" tabindex="-1"></a>  <span class="co"># Determine the level with the highest frequency</span></span>
<span id="cb39-6"><a href="linear-models.html#cb39-6" tabindex="-1"></a>  max <span class="ot">&lt;-</span> <span class="fu">which.max</span>(table[, <span class="dv">2</span>])</span>
<span id="cb39-7"><a href="linear-models.html#cb39-7" tabindex="-1"></a>  <span class="co"># Save the name of the level with the highest frequency</span></span>
<span id="cb39-8"><a href="linear-models.html#cb39-8" tabindex="-1"></a>  level.name <span class="ot">&lt;-</span> <span class="fu">as.character</span>(table[max, <span class="dv">1</span>])</span>
<span id="cb39-9"><a href="linear-models.html#cb39-9" tabindex="-1"></a>  <span class="co"># Set the baseline level to the most populous level</span></span>
<span id="cb39-10"><a href="linear-models.html#cb39-10" tabindex="-1"></a>  Credit[, i] <span class="ot">&lt;-</span> <span class="fu">relevel</span>(Credit[, i], <span class="at">ref =</span> level.name)</span>
<span id="cb39-11"><a href="linear-models.html#cb39-11" tabindex="-1"></a>}</span>
<span id="cb39-12"><a href="linear-models.html#cb39-12" tabindex="-1"></a></span>
<span id="cb39-13"><a href="linear-models.html#cb39-13" tabindex="-1"></a><span class="fu">summary</span>(Credit[, vars.categorical])</span>
<span id="cb39-14"><a href="linear-models.html#cb39-14" tabindex="-1"></a><span class="co">#&gt;     Gender    Student   Married  </span></span>
<span id="cb39-15"><a href="linear-models.html#cb39-15" tabindex="-1"></a><span class="co">#&gt;  Female:207   No :360   Yes:245  </span></span>
<span id="cb39-16"><a href="linear-models.html#cb39-16" tabindex="-1"></a><span class="co">#&gt;   Male :193   Yes: 40   No :155  </span></span>
<span id="cb39-17"><a href="linear-models.html#cb39-17" tabindex="-1"></a><span class="co">#&gt;                                  </span></span>
<span id="cb39-18"><a href="linear-models.html#cb39-18" tabindex="-1"></a><span class="co">#&gt;             Ethnicity  </span></span>
<span id="cb39-19"><a href="linear-models.html#cb39-19" tabindex="-1"></a><span class="co">#&gt;  Caucasian       :199  </span></span>
<span id="cb39-20"><a href="linear-models.html#cb39-20" tabindex="-1"></a><span class="co">#&gt;  African American: 99  </span></span>
<span id="cb39-21"><a href="linear-models.html#cb39-21" tabindex="-1"></a><span class="co">#&gt;  Asian           :102</span></span></code></pre></div>
<p>When the summary function is called, the baseline level is always printed first.</p>
<p>We then refit the linear model after doing the releveling and observe the differences in summary output:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="linear-models.html#cb40-1" tabindex="-1"></a><span class="co"># CHUNK 12</span></span>
<span id="cb40-2"><a href="linear-models.html#cb40-2" tabindex="-1"></a><span class="co"># To make sure factors in the training set are releveled</span></span>
<span id="cb40-3"><a href="linear-models.html#cb40-3" tabindex="-1"></a>data.train <span class="ot">&lt;-</span> Credit[partition, ]</span>
<span id="cb40-4"><a href="linear-models.html#cb40-4" tabindex="-1"></a></span>
<span id="cb40-5"><a href="linear-models.html#cb40-5" tabindex="-1"></a>model.full <span class="ot">&lt;-</span> <span class="fu">lm</span>(Balance <span class="sc">~</span> . <span class="sc">+</span> Income<span class="sc">:</span>Student, <span class="at">data =</span> data.train)</span>
<span id="cb40-6"><a href="linear-models.html#cb40-6" tabindex="-1"></a><span class="fu">summary</span>(model.full)</span>
<span id="cb40-7"><a href="linear-models.html#cb40-7" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb40-8"><a href="linear-models.html#cb40-8" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb40-9"><a href="linear-models.html#cb40-9" tabindex="-1"></a><span class="co">#&gt; lm(formula = Balance ~ . + Income:Student, data = data.train)</span></span>
<span id="cb40-10"><a href="linear-models.html#cb40-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb40-11"><a href="linear-models.html#cb40-11" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb40-12"><a href="linear-models.html#cb40-12" tabindex="-1"></a><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></span>
<span id="cb40-13"><a href="linear-models.html#cb40-13" tabindex="-1"></a><span class="co">#&gt; -189.2  -76.5  -15.6   66.7  296.2 </span></span>
<span id="cb40-14"><a href="linear-models.html#cb40-14" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb40-15"><a href="linear-models.html#cb40-15" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb40-16"><a href="linear-models.html#cb40-16" tabindex="-1"></a><span class="co">#&gt;                            Estimate Std. Error t value</span></span>
<span id="cb40-17"><a href="linear-models.html#cb40-17" tabindex="-1"></a><span class="co">#&gt; (Intercept)               -579.2247    40.0860  -14.45</span></span>
<span id="cb40-18"><a href="linear-models.html#cb40-18" tabindex="-1"></a><span class="co">#&gt; Income                      -7.9386     0.2946  -26.94</span></span>
<span id="cb40-19"><a href="linear-models.html#cb40-19" tabindex="-1"></a><span class="co">#&gt; Rating                       4.0125     0.0642   62.54</span></span>
<span id="cb40-20"><a href="linear-models.html#cb40-20" tabindex="-1"></a><span class="co">#&gt; Cards                        2.8977     4.6917    0.62</span></span>
<span id="cb40-21"><a href="linear-models.html#cb40-21" tabindex="-1"></a><span class="co">#&gt; Age                         -0.7878     0.3599   -2.19</span></span>
<span id="cb40-22"><a href="linear-models.html#cb40-22" tabindex="-1"></a><span class="co">#&gt; Education                    0.8892     1.9204    0.46</span></span>
<span id="cb40-23"><a href="linear-models.html#cb40-23" tabindex="-1"></a><span class="co">#&gt; Gender Male                 18.3703    12.0087    1.53</span></span>
<span id="cb40-24"><a href="linear-models.html#cb40-24" tabindex="-1"></a><span class="co">#&gt; StudentYes                 395.6774    30.7230   12.88</span></span>
<span id="cb40-25"><a href="linear-models.html#cb40-25" tabindex="-1"></a><span class="co">#&gt; MarriedNo                   20.4647    12.3974    1.65</span></span>
<span id="cb40-26"><a href="linear-models.html#cb40-26" tabindex="-1"></a><span class="co">#&gt; EthnicityAfrican American  -11.9539    14.8244   -0.81</span></span>
<span id="cb40-27"><a href="linear-models.html#cb40-27" tabindex="-1"></a><span class="co">#&gt; EthnicityAsian              -5.4212    14.6852   -0.37</span></span>
<span id="cb40-28"><a href="linear-models.html#cb40-28" tabindex="-1"></a><span class="co">#&gt; Income:StudentYes            0.5010     0.5003    1.00</span></span>
<span id="cb40-29"><a href="linear-models.html#cb40-29" tabindex="-1"></a><span class="co">#&gt;                           Pr(&gt;|t|)    </span></span>
<span id="cb40-30"><a href="linear-models.html#cb40-30" tabindex="-1"></a><span class="co">#&gt; (Intercept)                 &lt;2e-16 ***</span></span>
<span id="cb40-31"><a href="linear-models.html#cb40-31" tabindex="-1"></a><span class="co">#&gt; Income                      &lt;2e-16 ***</span></span>
<span id="cb40-32"><a href="linear-models.html#cb40-32" tabindex="-1"></a><span class="co">#&gt; Rating                      &lt;2e-16 ***</span></span>
<span id="cb40-33"><a href="linear-models.html#cb40-33" tabindex="-1"></a><span class="co">#&gt; Cards                        0.537    </span></span>
<span id="cb40-34"><a href="linear-models.html#cb40-34" tabindex="-1"></a><span class="co">#&gt; Age                          0.029 *  </span></span>
<span id="cb40-35"><a href="linear-models.html#cb40-35" tabindex="-1"></a><span class="co">#&gt; Education                    0.644    </span></span>
<span id="cb40-36"><a href="linear-models.html#cb40-36" tabindex="-1"></a><span class="co">#&gt; Gender Male                  0.127    </span></span>
<span id="cb40-37"><a href="linear-models.html#cb40-37" tabindex="-1"></a><span class="co">#&gt; StudentYes                  &lt;2e-16 ***</span></span>
<span id="cb40-38"><a href="linear-models.html#cb40-38" tabindex="-1"></a><span class="co">#&gt; MarriedNo                    0.100 .  </span></span>
<span id="cb40-39"><a href="linear-models.html#cb40-39" tabindex="-1"></a><span class="co">#&gt; EthnicityAfrican American    0.421    </span></span>
<span id="cb40-40"><a href="linear-models.html#cb40-40" tabindex="-1"></a><span class="co">#&gt; EthnicityAsian               0.712    </span></span>
<span id="cb40-41"><a href="linear-models.html#cb40-41" tabindex="-1"></a><span class="co">#&gt; Income:StudentYes            0.317    </span></span>
<span id="cb40-42"><a href="linear-models.html#cb40-42" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb40-43"><a href="linear-models.html#cb40-43" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  </span></span>
<span id="cb40-44"><a href="linear-models.html#cb40-44" tabindex="-1"></a><span class="co">#&gt; 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb40-45"><a href="linear-models.html#cb40-45" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb40-46"><a href="linear-models.html#cb40-46" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 103 on 289 degrees of freedom</span></span>
<span id="cb40-47"><a href="linear-models.html#cb40-47" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.952,  Adjusted R-squared:  0.95 </span></span>
<span id="cb40-48"><a href="linear-models.html#cb40-48" tabindex="-1"></a><span class="co">#&gt; F-statistic:  521 on 11 and 289 DF,  p-value: &lt;2e-16</span></span></code></pre></div>
<p>We can see in the new summary output, the coefficients for <code>Married</code> and <code>Ethnicity</code> have flipped as there is a new baseline level of these factor variables.</p>
<hr />
</div>
</div>
</div>
<div id="task-6-binarize-factor-variables-manually" class="section level3 unnumbered hasAnchor">
<h3>TASK 6: Binarize Factor Variables Manually<a href="linear-models.html#task-6-binarize-factor-variables-manually" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="task-statement-7" class="section level4 unnumbered hasAnchor">
<h4>Task Statement<a href="linear-models.html#task-statement-7" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Describe the <strong>advantages and disadvantages</strong> of <strong>manually binarizing</strong> the factor variables before performing feature selection.</li>
<li>Regardless, <strong>binarize the factor variables manually</strong> and refit the multiple linear regression model in Task 5.</li>
</ul>
</div>
<div id="advantage-to-avoid-all-or-nothing" class="section level4 unnumbered hasAnchor">
<h4>Advantage: To avoid “all or nothing”<a href="linear-models.html#advantage-to-avoid-all-or-nothing" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Many feature selection functions treat factor variables as a <strong>single feature</strong> and either:
- Retain the variable with <strong>all of its levels</strong>
- Remove the variable <strong>completely</strong></p>
<p>Binarization allows the ability to <strong>drop individual factor levels</strong> if not significant with respect to the baseline.</p>
</div>
<div id="disadvantages" class="section level4 unnumbered hasAnchor">
<h4>Disadvantages<a href="linear-models.html#disadvantages" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li>Each factor level is considered a <strong>separate feature</strong> to add/drop, which can make <strong>stepwise selection</strong> take considerably longer to complete.</li>
<li>(Less important; see Dec 2019 Task 8) It’s possible to have <strong>nonsensical results</strong> when only a <strong>handful of levels</strong> of a categorical predictor are selected.</li>
</ol>
<p>In the following code chunk, we start the binarization process by generating the dummary variables for the four factor variables in the data.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="linear-models.html#cb41-1" tabindex="-1"></a><span class="co"># CHUNK 13</span></span>
<span id="cb41-2"><a href="linear-models.html#cb41-2" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb41-3"><a href="linear-models.html#cb41-3" tabindex="-1"></a>binarizer <span class="ot">&lt;-</span> <span class="fu">dummyVars</span>(<span class="fu">paste</span>(<span class="st">&quot;~&quot;</span>, <span class="fu">paste</span>(vars.categorical, <span class="at">collapse =</span> <span class="st">&quot;+&quot;</span>)),</span>
<span id="cb41-4"><a href="linear-models.html#cb41-4" tabindex="-1"></a>                       <span class="at">data =</span> Credit, <span class="at">fullRank =</span> <span class="cn">TRUE</span>)</span>
<span id="cb41-5"><a href="linear-models.html#cb41-5" tabindex="-1"></a><span class="co"># OR type out the categorical predictors one by one</span></span>
<span id="cb41-6"><a href="linear-models.html#cb41-6" tabindex="-1"></a><span class="co">#binarizer &lt;- dummyVars(~ Gender + Student + Married + Ethnicity,</span></span>
<span id="cb41-7"><a href="linear-models.html#cb41-7" tabindex="-1"></a><span class="co">#                       data = Credit, fullRank = TRUE)</span></span>
<span id="cb41-8"><a href="linear-models.html#cb41-8" tabindex="-1"></a>binarized_vars <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">predict</span>(binarizer, <span class="at">newdata =</span> Credit))</span>
<span id="cb41-9"><a href="linear-models.html#cb41-9" tabindex="-1"></a><span class="fu">head</span>(binarized_vars)</span>
<span id="cb41-10"><a href="linear-models.html#cb41-10" tabindex="-1"></a><span class="co">#&gt;   Gender..Male Student.Yes Married.No</span></span>
<span id="cb41-11"><a href="linear-models.html#cb41-11" tabindex="-1"></a><span class="co">#&gt; 1            1           0          0</span></span>
<span id="cb41-12"><a href="linear-models.html#cb41-12" tabindex="-1"></a><span class="co">#&gt; 2            0           1          0</span></span>
<span id="cb41-13"><a href="linear-models.html#cb41-13" tabindex="-1"></a><span class="co">#&gt; 3            1           0          1</span></span>
<span id="cb41-14"><a href="linear-models.html#cb41-14" tabindex="-1"></a><span class="co">#&gt; 4            0           0          1</span></span>
<span id="cb41-15"><a href="linear-models.html#cb41-15" tabindex="-1"></a><span class="co">#&gt; 5            1           0          0</span></span>
<span id="cb41-16"><a href="linear-models.html#cb41-16" tabindex="-1"></a><span class="co">#&gt; 6            1           0          1</span></span>
<span id="cb41-17"><a href="linear-models.html#cb41-17" tabindex="-1"></a><span class="co">#&gt;   Ethnicity.African.American Ethnicity.Asian</span></span>
<span id="cb41-18"><a href="linear-models.html#cb41-18" tabindex="-1"></a><span class="co">#&gt; 1                          0               0</span></span>
<span id="cb41-19"><a href="linear-models.html#cb41-19" tabindex="-1"></a><span class="co">#&gt; 2                          0               1</span></span>
<span id="cb41-20"><a href="linear-models.html#cb41-20" tabindex="-1"></a><span class="co">#&gt; 3                          0               1</span></span>
<span id="cb41-21"><a href="linear-models.html#cb41-21" tabindex="-1"></a><span class="co">#&gt; 4                          0               1</span></span>
<span id="cb41-22"><a href="linear-models.html#cb41-22" tabindex="-1"></a><span class="co">#&gt; 5                          0               0</span></span>
<span id="cb41-23"><a href="linear-models.html#cb41-23" tabindex="-1"></a><span class="co">#&gt; 6                          0               0</span></span></code></pre></div>
<p>Then we attach the binarized variables to the dataset and set the original variables to <code>NULL</code> to remove them, and create training/test sets on the new dataset:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="linear-models.html#cb42-1" tabindex="-1"></a><span class="co"># CHUNK 14</span></span>
<span id="cb42-2"><a href="linear-models.html#cb42-2" tabindex="-1"></a>Credit.bin <span class="ot">&lt;-</span> <span class="fu">cbind</span>(Credit, binarized_vars)</span>
<span id="cb42-3"><a href="linear-models.html#cb42-3" tabindex="-1"></a><span class="fu">head</span>(Credit.bin)</span>
<span id="cb42-4"><a href="linear-models.html#cb42-4" tabindex="-1"></a><span class="co">#&gt;   Income Rating Cards Age Education Gender Student</span></span>
<span id="cb42-5"><a href="linear-models.html#cb42-5" tabindex="-1"></a><span class="co">#&gt; 1  14.89    283     2  34        11   Male      No</span></span>
<span id="cb42-6"><a href="linear-models.html#cb42-6" tabindex="-1"></a><span class="co">#&gt; 2 106.03    483     3  82        15 Female     Yes</span></span>
<span id="cb42-7"><a href="linear-models.html#cb42-7" tabindex="-1"></a><span class="co">#&gt; 3 104.59    514     4  71        11   Male      No</span></span>
<span id="cb42-8"><a href="linear-models.html#cb42-8" tabindex="-1"></a><span class="co">#&gt; 4 148.92    681     3  36        11 Female      No</span></span>
<span id="cb42-9"><a href="linear-models.html#cb42-9" tabindex="-1"></a><span class="co">#&gt; 5  55.88    357     2  68        16   Male      No</span></span>
<span id="cb42-10"><a href="linear-models.html#cb42-10" tabindex="-1"></a><span class="co">#&gt; 6  80.18    569     4  77        10   Male      No</span></span>
<span id="cb42-11"><a href="linear-models.html#cb42-11" tabindex="-1"></a><span class="co">#&gt;   Married Ethnicity Balance Gender..Male Student.Yes</span></span>
<span id="cb42-12"><a href="linear-models.html#cb42-12" tabindex="-1"></a><span class="co">#&gt; 1     Yes Caucasian     333            1           0</span></span>
<span id="cb42-13"><a href="linear-models.html#cb42-13" tabindex="-1"></a><span class="co">#&gt; 2     Yes     Asian     903            0           1</span></span>
<span id="cb42-14"><a href="linear-models.html#cb42-14" tabindex="-1"></a><span class="co">#&gt; 3      No     Asian     580            1           0</span></span>
<span id="cb42-15"><a href="linear-models.html#cb42-15" tabindex="-1"></a><span class="co">#&gt; 4      No     Asian     964            0           0</span></span>
<span id="cb42-16"><a href="linear-models.html#cb42-16" tabindex="-1"></a><span class="co">#&gt; 5     Yes Caucasian     331            1           0</span></span>
<span id="cb42-17"><a href="linear-models.html#cb42-17" tabindex="-1"></a><span class="co">#&gt; 6      No Caucasian    1151            1           0</span></span>
<span id="cb42-18"><a href="linear-models.html#cb42-18" tabindex="-1"></a><span class="co">#&gt;   Married.No Ethnicity.African.American</span></span>
<span id="cb42-19"><a href="linear-models.html#cb42-19" tabindex="-1"></a><span class="co">#&gt; 1          0                          0</span></span>
<span id="cb42-20"><a href="linear-models.html#cb42-20" tabindex="-1"></a><span class="co">#&gt; 2          0                          0</span></span>
<span id="cb42-21"><a href="linear-models.html#cb42-21" tabindex="-1"></a><span class="co">#&gt; 3          1                          0</span></span>
<span id="cb42-22"><a href="linear-models.html#cb42-22" tabindex="-1"></a><span class="co">#&gt; 4          1                          0</span></span>
<span id="cb42-23"><a href="linear-models.html#cb42-23" tabindex="-1"></a><span class="co">#&gt; 5          0                          0</span></span>
<span id="cb42-24"><a href="linear-models.html#cb42-24" tabindex="-1"></a><span class="co">#&gt; 6          1                          0</span></span>
<span id="cb42-25"><a href="linear-models.html#cb42-25" tabindex="-1"></a><span class="co">#&gt;   Ethnicity.Asian</span></span>
<span id="cb42-26"><a href="linear-models.html#cb42-26" tabindex="-1"></a><span class="co">#&gt; 1               0</span></span>
<span id="cb42-27"><a href="linear-models.html#cb42-27" tabindex="-1"></a><span class="co">#&gt; 2               1</span></span>
<span id="cb42-28"><a href="linear-models.html#cb42-28" tabindex="-1"></a><span class="co">#&gt; 3               1</span></span>
<span id="cb42-29"><a href="linear-models.html#cb42-29" tabindex="-1"></a><span class="co">#&gt; 4               1</span></span>
<span id="cb42-30"><a href="linear-models.html#cb42-30" tabindex="-1"></a><span class="co">#&gt; 5               0</span></span>
<span id="cb42-31"><a href="linear-models.html#cb42-31" tabindex="-1"></a><span class="co">#&gt; 6               0</span></span>
<span id="cb42-32"><a href="linear-models.html#cb42-32" tabindex="-1"></a></span>
<span id="cb42-33"><a href="linear-models.html#cb42-33" tabindex="-1"></a>Credit.bin<span class="sc">$</span>Gender <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb42-34"><a href="linear-models.html#cb42-34" tabindex="-1"></a>Credit.bin<span class="sc">$</span>Student <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb42-35"><a href="linear-models.html#cb42-35" tabindex="-1"></a>Credit.bin<span class="sc">$</span>Married <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb42-36"><a href="linear-models.html#cb42-36" tabindex="-1"></a>Credit.bin<span class="sc">$</span>Ethnicity <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb42-37"><a href="linear-models.html#cb42-37" tabindex="-1"></a><span class="fu">head</span>(Credit.bin)</span>
<span id="cb42-38"><a href="linear-models.html#cb42-38" tabindex="-1"></a><span class="co">#&gt;   Income Rating Cards Age Education Balance</span></span>
<span id="cb42-39"><a href="linear-models.html#cb42-39" tabindex="-1"></a><span class="co">#&gt; 1  14.89    283     2  34        11     333</span></span>
<span id="cb42-40"><a href="linear-models.html#cb42-40" tabindex="-1"></a><span class="co">#&gt; 2 106.03    483     3  82        15     903</span></span>
<span id="cb42-41"><a href="linear-models.html#cb42-41" tabindex="-1"></a><span class="co">#&gt; 3 104.59    514     4  71        11     580</span></span>
<span id="cb42-42"><a href="linear-models.html#cb42-42" tabindex="-1"></a><span class="co">#&gt; 4 148.92    681     3  36        11     964</span></span>
<span id="cb42-43"><a href="linear-models.html#cb42-43" tabindex="-1"></a><span class="co">#&gt; 5  55.88    357     2  68        16     331</span></span>
<span id="cb42-44"><a href="linear-models.html#cb42-44" tabindex="-1"></a><span class="co">#&gt; 6  80.18    569     4  77        10    1151</span></span>
<span id="cb42-45"><a href="linear-models.html#cb42-45" tabindex="-1"></a><span class="co">#&gt;   Gender..Male Student.Yes Married.No</span></span>
<span id="cb42-46"><a href="linear-models.html#cb42-46" tabindex="-1"></a><span class="co">#&gt; 1            1           0          0</span></span>
<span id="cb42-47"><a href="linear-models.html#cb42-47" tabindex="-1"></a><span class="co">#&gt; 2            0           1          0</span></span>
<span id="cb42-48"><a href="linear-models.html#cb42-48" tabindex="-1"></a><span class="co">#&gt; 3            1           0          1</span></span>
<span id="cb42-49"><a href="linear-models.html#cb42-49" tabindex="-1"></a><span class="co">#&gt; 4            0           0          1</span></span>
<span id="cb42-50"><a href="linear-models.html#cb42-50" tabindex="-1"></a><span class="co">#&gt; 5            1           0          0</span></span>
<span id="cb42-51"><a href="linear-models.html#cb42-51" tabindex="-1"></a><span class="co">#&gt; 6            1           0          1</span></span>
<span id="cb42-52"><a href="linear-models.html#cb42-52" tabindex="-1"></a><span class="co">#&gt;   Ethnicity.African.American Ethnicity.Asian</span></span>
<span id="cb42-53"><a href="linear-models.html#cb42-53" tabindex="-1"></a><span class="co">#&gt; 1                          0               0</span></span>
<span id="cb42-54"><a href="linear-models.html#cb42-54" tabindex="-1"></a><span class="co">#&gt; 2                          0               1</span></span>
<span id="cb42-55"><a href="linear-models.html#cb42-55" tabindex="-1"></a><span class="co">#&gt; 3                          0               1</span></span>
<span id="cb42-56"><a href="linear-models.html#cb42-56" tabindex="-1"></a><span class="co">#&gt; 4                          0               1</span></span>
<span id="cb42-57"><a href="linear-models.html#cb42-57" tabindex="-1"></a><span class="co">#&gt; 5                          0               0</span></span>
<span id="cb42-58"><a href="linear-models.html#cb42-58" tabindex="-1"></a><span class="co">#&gt; 6                          0               0</span></span>
<span id="cb42-59"><a href="linear-models.html#cb42-59" tabindex="-1"></a></span>
<span id="cb42-60"><a href="linear-models.html#cb42-60" tabindex="-1"></a>data.train.bin <span class="ot">&lt;-</span> Credit.bin[partition, ]</span>
<span id="cb42-61"><a href="linear-models.html#cb42-61" tabindex="-1"></a>data.test.bin <span class="ot">&lt;-</span> Credit.bin[<span class="sc">-</span>partition, ]</span></code></pre></div>
<p>We then fit a model on the binzared dataset and print a model summary:</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="linear-models.html#cb43-1" tabindex="-1"></a><span class="co"># CHUNK 15</span></span>
<span id="cb43-2"><a href="linear-models.html#cb43-2" tabindex="-1"></a><span class="co"># The interaction term is now Income:Student.Yes, not Income:Student</span></span>
<span id="cb43-3"><a href="linear-models.html#cb43-3" tabindex="-1"></a>model.full.bin <span class="ot">&lt;-</span> <span class="fu">lm</span>(Balance <span class="sc">~</span> . <span class="sc">+</span> Income<span class="sc">:</span>Student.Yes, <span class="at">data =</span> data.train.bin)</span>
<span id="cb43-4"><a href="linear-models.html#cb43-4" tabindex="-1"></a><span class="fu">summary</span>(model.full.bin)</span>
<span id="cb43-5"><a href="linear-models.html#cb43-5" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb43-6"><a href="linear-models.html#cb43-6" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb43-7"><a href="linear-models.html#cb43-7" tabindex="-1"></a><span class="co">#&gt; lm(formula = Balance ~ . + Income:Student.Yes, data = data.train.bin)</span></span>
<span id="cb43-8"><a href="linear-models.html#cb43-8" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb43-9"><a href="linear-models.html#cb43-9" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb43-10"><a href="linear-models.html#cb43-10" tabindex="-1"></a><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></span>
<span id="cb43-11"><a href="linear-models.html#cb43-11" tabindex="-1"></a><span class="co">#&gt; -189.2  -76.5  -15.6   66.7  296.2 </span></span>
<span id="cb43-12"><a href="linear-models.html#cb43-12" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb43-13"><a href="linear-models.html#cb43-13" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb43-14"><a href="linear-models.html#cb43-14" tabindex="-1"></a><span class="co">#&gt;                             Estimate Std. Error</span></span>
<span id="cb43-15"><a href="linear-models.html#cb43-15" tabindex="-1"></a><span class="co">#&gt; (Intercept)                -579.2247    40.0860</span></span>
<span id="cb43-16"><a href="linear-models.html#cb43-16" tabindex="-1"></a><span class="co">#&gt; Income                       -7.9386     0.2946</span></span>
<span id="cb43-17"><a href="linear-models.html#cb43-17" tabindex="-1"></a><span class="co">#&gt; Rating                        4.0125     0.0642</span></span>
<span id="cb43-18"><a href="linear-models.html#cb43-18" tabindex="-1"></a><span class="co">#&gt; Cards                         2.8977     4.6917</span></span>
<span id="cb43-19"><a href="linear-models.html#cb43-19" tabindex="-1"></a><span class="co">#&gt; Age                          -0.7878     0.3599</span></span>
<span id="cb43-20"><a href="linear-models.html#cb43-20" tabindex="-1"></a><span class="co">#&gt; Education                     0.8892     1.9204</span></span>
<span id="cb43-21"><a href="linear-models.html#cb43-21" tabindex="-1"></a><span class="co">#&gt; Gender..Male                 18.3703    12.0087</span></span>
<span id="cb43-22"><a href="linear-models.html#cb43-22" tabindex="-1"></a><span class="co">#&gt; Student.Yes                 395.6774    30.7230</span></span>
<span id="cb43-23"><a href="linear-models.html#cb43-23" tabindex="-1"></a><span class="co">#&gt; Married.No                   20.4647    12.3974</span></span>
<span id="cb43-24"><a href="linear-models.html#cb43-24" tabindex="-1"></a><span class="co">#&gt; Ethnicity.African.American  -11.9539    14.8244</span></span>
<span id="cb43-25"><a href="linear-models.html#cb43-25" tabindex="-1"></a><span class="co">#&gt; Ethnicity.Asian              -5.4212    14.6852</span></span>
<span id="cb43-26"><a href="linear-models.html#cb43-26" tabindex="-1"></a><span class="co">#&gt; Income:Student.Yes            0.5010     0.5003</span></span>
<span id="cb43-27"><a href="linear-models.html#cb43-27" tabindex="-1"></a><span class="co">#&gt;                            t value Pr(&gt;|t|)    </span></span>
<span id="cb43-28"><a href="linear-models.html#cb43-28" tabindex="-1"></a><span class="co">#&gt; (Intercept)                 -14.45   &lt;2e-16 ***</span></span>
<span id="cb43-29"><a href="linear-models.html#cb43-29" tabindex="-1"></a><span class="co">#&gt; Income                      -26.94   &lt;2e-16 ***</span></span>
<span id="cb43-30"><a href="linear-models.html#cb43-30" tabindex="-1"></a><span class="co">#&gt; Rating                       62.54   &lt;2e-16 ***</span></span>
<span id="cb43-31"><a href="linear-models.html#cb43-31" tabindex="-1"></a><span class="co">#&gt; Cards                         0.62    0.537    </span></span>
<span id="cb43-32"><a href="linear-models.html#cb43-32" tabindex="-1"></a><span class="co">#&gt; Age                          -2.19    0.029 *  </span></span>
<span id="cb43-33"><a href="linear-models.html#cb43-33" tabindex="-1"></a><span class="co">#&gt; Education                     0.46    0.644    </span></span>
<span id="cb43-34"><a href="linear-models.html#cb43-34" tabindex="-1"></a><span class="co">#&gt; Gender..Male                  1.53    0.127    </span></span>
<span id="cb43-35"><a href="linear-models.html#cb43-35" tabindex="-1"></a><span class="co">#&gt; Student.Yes                  12.88   &lt;2e-16 ***</span></span>
<span id="cb43-36"><a href="linear-models.html#cb43-36" tabindex="-1"></a><span class="co">#&gt; Married.No                    1.65    0.100 .  </span></span>
<span id="cb43-37"><a href="linear-models.html#cb43-37" tabindex="-1"></a><span class="co">#&gt; Ethnicity.African.American   -0.81    0.421    </span></span>
<span id="cb43-38"><a href="linear-models.html#cb43-38" tabindex="-1"></a><span class="co">#&gt; Ethnicity.Asian              -0.37    0.712    </span></span>
<span id="cb43-39"><a href="linear-models.html#cb43-39" tabindex="-1"></a><span class="co">#&gt; Income:Student.Yes            1.00    0.317    </span></span>
<span id="cb43-40"><a href="linear-models.html#cb43-40" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb43-41"><a href="linear-models.html#cb43-41" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  </span></span>
<span id="cb43-42"><a href="linear-models.html#cb43-42" tabindex="-1"></a><span class="co">#&gt; 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb43-43"><a href="linear-models.html#cb43-43" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb43-44"><a href="linear-models.html#cb43-44" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 103 on 289 degrees of freedom</span></span>
<span id="cb43-45"><a href="linear-models.html#cb43-45" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.952,  Adjusted R-squared:  0.95 </span></span>
<span id="cb43-46"><a href="linear-models.html#cb43-46" tabindex="-1"></a><span class="co">#&gt; F-statistic:  521 on 11 and 289 DF,  p-value: &lt;2e-16</span></span></code></pre></div>
<p>We see a similar summary output for the model as we did before.</p>
<hr />
</div>
</div>
<div id="model-construction-and-feature-selection" class="section level3 hasAnchor" number="3.4.2">
<h3><span class="header-section-number">3.4.2</span> Model Construction and Feature Selection<a href="linear-models.html#model-construction-and-feature-selection" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="task-7-select-features-using-stepwise-selection" class="section level3 unnumbered hasAnchor">
<h3>TASK 7: Select Features using Stepwise Selection<a href="linear-models.html#task-7-select-features-using-stepwise-selection" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="task-statement-8" class="section level4 unnumbered hasAnchor">
<h4>Task Statement<a href="linear-models.html#task-statement-8" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>Motivation</strong>: Some features in the full model may lack predictive power and result in overfitting.</p>
<ul>
<li><p>Perform <strong>stepwise selection</strong> using the <code>stepAIC()</code> function to determine which features should be retained.</p>
<ul>
<li>Two decisions to make:
<ol style="list-style-type: decimal">
<li><strong>Forward</strong> (<code>direction = "forward"</code>) vs. <strong>backward</strong> (<code>direction = "backward"</code>) (default)</li>
<li><strong>AIC</strong> (<code>k = 2</code>) (default) vs. <strong>BIC</strong> (<code>k = log(nrow(data.train.bin))</code>)</li>
</ol></li>
</ul></li>
<li><p>Employ <strong>forward selection</strong> using <strong>BIC</strong>.</p></li>
<li><p>Run the <code>summary</code> function on the linear model selected by this process. Provide the summary output and <strong>list the variables selected</strong>.</p></li>
</ul>
<p>We load the <code>MASS</code> package to perform stepwise AIC. The default for stepAIC() is to use “backward” selection and “AIC” as the criteria (e.g., <span class="math inline">\(k=2\)</span>).</p>
<p>Alternatively, we can specify <code>direction="forward"</code> and <code>k=log(nrow(data.train.bin))</code> for BIC.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="linear-models.html#cb44-1" tabindex="-1"></a><span class="co"># CHUNK 16</span></span>
<span id="cb44-2"><a href="linear-models.html#cb44-2" tabindex="-1"></a><span class="co"># Uncomment this line the first time you use MASS</span></span>
<span id="cb44-3"><a href="linear-models.html#cb44-3" tabindex="-1"></a><span class="co">#install.packages(&quot;MASS&quot;)</span></span>
<span id="cb44-4"><a href="linear-models.html#cb44-4" tabindex="-1"></a></span>
<span id="cb44-5"><a href="linear-models.html#cb44-5" tabindex="-1"></a><span class="co"># Load packages</span></span>
<span id="cb44-6"><a href="linear-models.html#cb44-6" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb44-7"><a href="linear-models.html#cb44-7" tabindex="-1"></a></span>
<span id="cb44-8"><a href="linear-models.html#cb44-8" tabindex="-1"></a><span class="co"># Perform backward stepwise selection using the stepAIC() function</span></span>
<span id="cb44-9"><a href="linear-models.html#cb44-9" tabindex="-1"></a>model.backward.AIC <span class="ot">&lt;-</span> <span class="fu">stepAIC</span>(model.full.bin)</span>
<span id="cb44-10"><a href="linear-models.html#cb44-10" tabindex="-1"></a><span class="co">#&gt; Start:  AIC=2802</span></span>
<span id="cb44-11"><a href="linear-models.html#cb44-11" tabindex="-1"></a><span class="co">#&gt; Balance ~ Income + Rating + Cards + Age + Education + Gender..Male + </span></span>
<span id="cb44-12"><a href="linear-models.html#cb44-12" tabindex="-1"></a><span class="co">#&gt;     Student.Yes + Married.No + Ethnicity.African.American + Ethnicity.Asian + </span></span>
<span id="cb44-13"><a href="linear-models.html#cb44-13" tabindex="-1"></a><span class="co">#&gt;     Income:Student.Yes</span></span>
<span id="cb44-14"><a href="linear-models.html#cb44-14" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb44-15"><a href="linear-models.html#cb44-15" tabindex="-1"></a><span class="co">#&gt;                              Df Sum of Sq      RSS</span></span>
<span id="cb44-16"><a href="linear-models.html#cb44-16" tabindex="-1"></a><span class="co">#&gt; - Ethnicity.Asian             1      1448  3071419</span></span>
<span id="cb44-17"><a href="linear-models.html#cb44-17" tabindex="-1"></a><span class="co">#&gt; - Education                   1      2278  3072249</span></span>
<span id="cb44-18"><a href="linear-models.html#cb44-18" tabindex="-1"></a><span class="co">#&gt; - Cards                       1      4052  3074024</span></span>
<span id="cb44-19"><a href="linear-models.html#cb44-19" tabindex="-1"></a><span class="co">#&gt; - Ethnicity.African.American  1      6907  3076879</span></span>
<span id="cb44-20"><a href="linear-models.html#cb44-20" tabindex="-1"></a><span class="co">#&gt; - Income:Student.Yes          1     10654  3080626</span></span>
<span id="cb44-21"><a href="linear-models.html#cb44-21" tabindex="-1"></a><span class="co">#&gt; &lt;none&gt;                                     3069972</span></span>
<span id="cb44-22"><a href="linear-models.html#cb44-22" tabindex="-1"></a><span class="co">#&gt; - Gender..Male                1     24859  3094830</span></span>
<span id="cb44-23"><a href="linear-models.html#cb44-23" tabindex="-1"></a><span class="co">#&gt; - Married.No                  1     28946  3098918</span></span>
<span id="cb44-24"><a href="linear-models.html#cb44-24" tabindex="-1"></a><span class="co">#&gt; - Age                         1     50885  3120857</span></span>
<span id="cb44-25"><a href="linear-models.html#cb44-25" tabindex="-1"></a><span class="co">#&gt; - Rating                      1  41548705 44618677</span></span>
<span id="cb44-26"><a href="linear-models.html#cb44-26" tabindex="-1"></a><span class="co">#&gt;                               AIC</span></span>
<span id="cb44-27"><a href="linear-models.html#cb44-27" tabindex="-1"></a><span class="co">#&gt; - Ethnicity.Asian            2800</span></span>
<span id="cb44-28"><a href="linear-models.html#cb44-28" tabindex="-1"></a><span class="co">#&gt; - Education                  2800</span></span>
<span id="cb44-29"><a href="linear-models.html#cb44-29" tabindex="-1"></a><span class="co">#&gt; - Cards                      2801</span></span>
<span id="cb44-30"><a href="linear-models.html#cb44-30" tabindex="-1"></a><span class="co">#&gt; - Ethnicity.African.American 2801</span></span>
<span id="cb44-31"><a href="linear-models.html#cb44-31" tabindex="-1"></a><span class="co">#&gt; - Income:Student.Yes         2801</span></span>
<span id="cb44-32"><a href="linear-models.html#cb44-32" tabindex="-1"></a><span class="co">#&gt; &lt;none&gt;                       2802</span></span>
<span id="cb44-33"><a href="linear-models.html#cb44-33" tabindex="-1"></a><span class="co">#&gt; - Gender..Male               2803</span></span>
<span id="cb44-34"><a href="linear-models.html#cb44-34" tabindex="-1"></a><span class="co">#&gt; - Married.No                 2803</span></span>
<span id="cb44-35"><a href="linear-models.html#cb44-35" tabindex="-1"></a><span class="co">#&gt; - Age                        2805</span></span>
<span id="cb44-36"><a href="linear-models.html#cb44-36" tabindex="-1"></a><span class="co">#&gt; - Rating                     3606</span></span>
<span id="cb44-37"><a href="linear-models.html#cb44-37" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb44-38"><a href="linear-models.html#cb44-38" tabindex="-1"></a><span class="co">#&gt; Step:  AIC=2800</span></span>
<span id="cb44-39"><a href="linear-models.html#cb44-39" tabindex="-1"></a><span class="co">#&gt; Balance ~ Income + Rating + Cards + Age + Education + Gender..Male + </span></span>
<span id="cb44-40"><a href="linear-models.html#cb44-40" tabindex="-1"></a><span class="co">#&gt;     Student.Yes + Married.No + Ethnicity.African.American + Income:Student.Yes</span></span>
<span id="cb44-41"><a href="linear-models.html#cb44-41" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb44-42"><a href="linear-models.html#cb44-42" tabindex="-1"></a><span class="co">#&gt;                              Df Sum of Sq      RSS</span></span>
<span id="cb44-43"><a href="linear-models.html#cb44-43" tabindex="-1"></a><span class="co">#&gt; - Education                   1      2255  3073675</span></span>
<span id="cb44-44"><a href="linear-models.html#cb44-44" tabindex="-1"></a><span class="co">#&gt; - Cards                       1      3911  3075331</span></span>
<span id="cb44-45"><a href="linear-models.html#cb44-45" tabindex="-1"></a><span class="co">#&gt; - Ethnicity.African.American  1      5595  3077014</span></span>
<span id="cb44-46"><a href="linear-models.html#cb44-46" tabindex="-1"></a><span class="co">#&gt; - Income:Student.Yes          1     10176  3081595</span></span>
<span id="cb44-47"><a href="linear-models.html#cb44-47" tabindex="-1"></a><span class="co">#&gt; &lt;none&gt;                                     3071419</span></span>
<span id="cb44-48"><a href="linear-models.html#cb44-48" tabindex="-1"></a><span class="co">#&gt; - Gender..Male                1     25165  3096584</span></span>
<span id="cb44-49"><a href="linear-models.html#cb44-49" tabindex="-1"></a><span class="co">#&gt; - Married.No                  1     29351  3100771</span></span>
<span id="cb44-50"><a href="linear-models.html#cb44-50" tabindex="-1"></a><span class="co">#&gt; - Age                         1     51462  3122881</span></span>
<span id="cb44-51"><a href="linear-models.html#cb44-51" tabindex="-1"></a><span class="co">#&gt; - Rating                      1  41550276 44621695</span></span>
<span id="cb44-52"><a href="linear-models.html#cb44-52" tabindex="-1"></a><span class="co">#&gt;                               AIC</span></span>
<span id="cb44-53"><a href="linear-models.html#cb44-53" tabindex="-1"></a><span class="co">#&gt; - Education                  2799</span></span>
<span id="cb44-54"><a href="linear-models.html#cb44-54" tabindex="-1"></a><span class="co">#&gt; - Cards                      2799</span></span>
<span id="cb44-55"><a href="linear-models.html#cb44-55" tabindex="-1"></a><span class="co">#&gt; - Ethnicity.African.American 2799</span></span>
<span id="cb44-56"><a href="linear-models.html#cb44-56" tabindex="-1"></a><span class="co">#&gt; - Income:Student.Yes         2799</span></span>
<span id="cb44-57"><a href="linear-models.html#cb44-57" tabindex="-1"></a><span class="co">#&gt; &lt;none&gt;                       2800</span></span>
<span id="cb44-58"><a href="linear-models.html#cb44-58" tabindex="-1"></a><span class="co">#&gt; - Gender..Male               2801</span></span>
<span id="cb44-59"><a href="linear-models.html#cb44-59" tabindex="-1"></a><span class="co">#&gt; - Married.No                 2801</span></span>
<span id="cb44-60"><a href="linear-models.html#cb44-60" tabindex="-1"></a><span class="co">#&gt; - Age                        2803</span></span>
<span id="cb44-61"><a href="linear-models.html#cb44-61" tabindex="-1"></a><span class="co">#&gt; - Rating                     3604</span></span>
<span id="cb44-62"><a href="linear-models.html#cb44-62" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb44-63"><a href="linear-models.html#cb44-63" tabindex="-1"></a><span class="co">#&gt; Step:  AIC=2799</span></span>
<span id="cb44-64"><a href="linear-models.html#cb44-64" tabindex="-1"></a><span class="co">#&gt; Balance ~ Income + Rating + Cards + Age + Gender..Male + Student.Yes + </span></span>
<span id="cb44-65"><a href="linear-models.html#cb44-65" tabindex="-1"></a><span class="co">#&gt;     Married.No + Ethnicity.African.American + Income:Student.Yes</span></span>
<span id="cb44-66"><a href="linear-models.html#cb44-66" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb44-67"><a href="linear-models.html#cb44-67" tabindex="-1"></a><span class="co">#&gt;                              Df Sum of Sq      RSS</span></span>
<span id="cb44-68"><a href="linear-models.html#cb44-68" tabindex="-1"></a><span class="co">#&gt; - Cards                       1      3865  3077540</span></span>
<span id="cb44-69"><a href="linear-models.html#cb44-69" tabindex="-1"></a><span class="co">#&gt; - Ethnicity.African.American  1      5586  3079261</span></span>
<span id="cb44-70"><a href="linear-models.html#cb44-70" tabindex="-1"></a><span class="co">#&gt; - Income:Student.Yes          1     10214  3083888</span></span>
<span id="cb44-71"><a href="linear-models.html#cb44-71" tabindex="-1"></a><span class="co">#&gt; &lt;none&gt;                                     3073675</span></span>
<span id="cb44-72"><a href="linear-models.html#cb44-72" tabindex="-1"></a><span class="co">#&gt; - Gender..Male                1     25155  3098830</span></span>
<span id="cb44-73"><a href="linear-models.html#cb44-73" tabindex="-1"></a><span class="co">#&gt; - Married.No                  1     28499  3102174</span></span>
<span id="cb44-74"><a href="linear-models.html#cb44-74" tabindex="-1"></a><span class="co">#&gt; - Age                         1     51652  3125327</span></span>
<span id="cb44-75"><a href="linear-models.html#cb44-75" tabindex="-1"></a><span class="co">#&gt; - Rating                      1  41550265 44623939</span></span>
<span id="cb44-76"><a href="linear-models.html#cb44-76" tabindex="-1"></a><span class="co">#&gt;                               AIC</span></span>
<span id="cb44-77"><a href="linear-models.html#cb44-77" tabindex="-1"></a><span class="co">#&gt; - Cards                      2797</span></span>
<span id="cb44-78"><a href="linear-models.html#cb44-78" tabindex="-1"></a><span class="co">#&gt; - Ethnicity.African.American 2797</span></span>
<span id="cb44-79"><a href="linear-models.html#cb44-79" tabindex="-1"></a><span class="co">#&gt; - Income:Student.Yes         2798</span></span>
<span id="cb44-80"><a href="linear-models.html#cb44-80" tabindex="-1"></a><span class="co">#&gt; &lt;none&gt;                       2799</span></span>
<span id="cb44-81"><a href="linear-models.html#cb44-81" tabindex="-1"></a><span class="co">#&gt; - Gender..Male               2799</span></span>
<span id="cb44-82"><a href="linear-models.html#cb44-82" tabindex="-1"></a><span class="co">#&gt; - Married.No                 2799</span></span>
<span id="cb44-83"><a href="linear-models.html#cb44-83" tabindex="-1"></a><span class="co">#&gt; - Age                        2802</span></span>
<span id="cb44-84"><a href="linear-models.html#cb44-84" tabindex="-1"></a><span class="co">#&gt; - Rating                     3602</span></span>
<span id="cb44-85"><a href="linear-models.html#cb44-85" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb44-86"><a href="linear-models.html#cb44-86" tabindex="-1"></a><span class="co">#&gt; Step:  AIC=2797</span></span>
<span id="cb44-87"><a href="linear-models.html#cb44-87" tabindex="-1"></a><span class="co">#&gt; Balance ~ Income + Rating + Age + Gender..Male + Student.Yes + </span></span>
<span id="cb44-88"><a href="linear-models.html#cb44-88" tabindex="-1"></a><span class="co">#&gt;     Married.No + Ethnicity.African.American + Income:Student.Yes</span></span>
<span id="cb44-89"><a href="linear-models.html#cb44-89" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb44-90"><a href="linear-models.html#cb44-90" tabindex="-1"></a><span class="co">#&gt;                              Df Sum of Sq      RSS</span></span>
<span id="cb44-91"><a href="linear-models.html#cb44-91" tabindex="-1"></a><span class="co">#&gt; - Ethnicity.African.American  1      5579  3083119</span></span>
<span id="cb44-92"><a href="linear-models.html#cb44-92" tabindex="-1"></a><span class="co">#&gt; - Income:Student.Yes          1     10767  3088307</span></span>
<span id="cb44-93"><a href="linear-models.html#cb44-93" tabindex="-1"></a><span class="co">#&gt; &lt;none&gt;                                     3077540</span></span>
<span id="cb44-94"><a href="linear-models.html#cb44-94" tabindex="-1"></a><span class="co">#&gt; - Gender..Male                1     23659  3101198</span></span>
<span id="cb44-95"><a href="linear-models.html#cb44-95" tabindex="-1"></a><span class="co">#&gt; - Married.No                  1     27917  3105457</span></span>
<span id="cb44-96"><a href="linear-models.html#cb44-96" tabindex="-1"></a><span class="co">#&gt; - Age                         1     49660  3127200</span></span>
<span id="cb44-97"><a href="linear-models.html#cb44-97" tabindex="-1"></a><span class="co">#&gt; - Rating                      1  42161655 45239195</span></span>
<span id="cb44-98"><a href="linear-models.html#cb44-98" tabindex="-1"></a><span class="co">#&gt;                               AIC</span></span>
<span id="cb44-99"><a href="linear-models.html#cb44-99" tabindex="-1"></a><span class="co">#&gt; - Ethnicity.African.American 2796</span></span>
<span id="cb44-100"><a href="linear-models.html#cb44-100" tabindex="-1"></a><span class="co">#&gt; - Income:Student.Yes         2796</span></span>
<span id="cb44-101"><a href="linear-models.html#cb44-101" tabindex="-1"></a><span class="co">#&gt; &lt;none&gt;                       2797</span></span>
<span id="cb44-102"><a href="linear-models.html#cb44-102" tabindex="-1"></a><span class="co">#&gt; - Gender..Male               2797</span></span>
<span id="cb44-103"><a href="linear-models.html#cb44-103" tabindex="-1"></a><span class="co">#&gt; - Married.No                 2798</span></span>
<span id="cb44-104"><a href="linear-models.html#cb44-104" tabindex="-1"></a><span class="co">#&gt; - Age                        2800</span></span>
<span id="cb44-105"><a href="linear-models.html#cb44-105" tabindex="-1"></a><span class="co">#&gt; - Rating                     3604</span></span>
<span id="cb44-106"><a href="linear-models.html#cb44-106" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb44-107"><a href="linear-models.html#cb44-107" tabindex="-1"></a><span class="co">#&gt; Step:  AIC=2796</span></span>
<span id="cb44-108"><a href="linear-models.html#cb44-108" tabindex="-1"></a><span class="co">#&gt; Balance ~ Income + Rating + Age + Gender..Male + Student.Yes + </span></span>
<span id="cb44-109"><a href="linear-models.html#cb44-109" tabindex="-1"></a><span class="co">#&gt;     Married.No + Income:Student.Yes</span></span>
<span id="cb44-110"><a href="linear-models.html#cb44-110" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb44-111"><a href="linear-models.html#cb44-111" tabindex="-1"></a><span class="co">#&gt;                      Df Sum of Sq      RSS  AIC</span></span>
<span id="cb44-112"><a href="linear-models.html#cb44-112" tabindex="-1"></a><span class="co">#&gt; - Income:Student.Yes  1      9873  3092992 2794</span></span>
<span id="cb44-113"><a href="linear-models.html#cb44-113" tabindex="-1"></a><span class="co">#&gt; &lt;none&gt;                             3083119 2796</span></span>
<span id="cb44-114"><a href="linear-models.html#cb44-114" tabindex="-1"></a><span class="co">#&gt; - Gender..Male        1     23435  3106554 2796</span></span>
<span id="cb44-115"><a href="linear-models.html#cb44-115" tabindex="-1"></a><span class="co">#&gt; - Married.No          1     24716  3107835 2796</span></span>
<span id="cb44-116"><a href="linear-models.html#cb44-116" tabindex="-1"></a><span class="co">#&gt; - Age                 1     50672  3133791 2798</span></span>
<span id="cb44-117"><a href="linear-models.html#cb44-117" tabindex="-1"></a><span class="co">#&gt; - Rating              1  42165674 45248793 3602</span></span>
<span id="cb44-118"><a href="linear-models.html#cb44-118" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb44-119"><a href="linear-models.html#cb44-119" tabindex="-1"></a><span class="co">#&gt; Step:  AIC=2794</span></span>
<span id="cb44-120"><a href="linear-models.html#cb44-120" tabindex="-1"></a><span class="co">#&gt; Balance ~ Income + Rating + Age + Gender..Male + Student.Yes + </span></span>
<span id="cb44-121"><a href="linear-models.html#cb44-121" tabindex="-1"></a><span class="co">#&gt;     Married.No</span></span>
<span id="cb44-122"><a href="linear-models.html#cb44-122" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb44-123"><a href="linear-models.html#cb44-123" tabindex="-1"></a><span class="co">#&gt;                Df Sum of Sq      RSS  AIC</span></span>
<span id="cb44-124"><a href="linear-models.html#cb44-124" tabindex="-1"></a><span class="co">#&gt; &lt;none&gt;                       3092992 2794</span></span>
<span id="cb44-125"><a href="linear-models.html#cb44-125" tabindex="-1"></a><span class="co">#&gt; - Gender..Male  1     22314  3115306 2795</span></span>
<span id="cb44-126"><a href="linear-models.html#cb44-126" tabindex="-1"></a><span class="co">#&gt; - Married.No    1     25027  3118019 2795</span></span>
<span id="cb44-127"><a href="linear-models.html#cb44-127" tabindex="-1"></a><span class="co">#&gt; - Age           1     49133  3142125 2797</span></span>
<span id="cb44-128"><a href="linear-models.html#cb44-128" tabindex="-1"></a><span class="co">#&gt; - Student.Yes   1   4931600  8024592 3079</span></span>
<span id="cb44-129"><a href="linear-models.html#cb44-129" tabindex="-1"></a><span class="co">#&gt; - Income        1   8357794 11450786 3186</span></span>
<span id="cb44-130"><a href="linear-models.html#cb44-130" tabindex="-1"></a><span class="co">#&gt; - Rating        1  42247226 45340218 3601</span></span>
<span id="cb44-131"><a href="linear-models.html#cb44-131" tabindex="-1"></a></span>
<span id="cb44-132"><a href="linear-models.html#cb44-132" tabindex="-1"></a><span class="co"># Print a summary of the stepwise selection</span></span>
<span id="cb44-133"><a href="linear-models.html#cb44-133" tabindex="-1"></a><span class="fu">summary</span>(model.backward.AIC)</span>
<span id="cb44-134"><a href="linear-models.html#cb44-134" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb44-135"><a href="linear-models.html#cb44-135" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb44-136"><a href="linear-models.html#cb44-136" tabindex="-1"></a><span class="co">#&gt; lm(formula = Balance ~ Income + Rating + Age + Gender..Male + </span></span>
<span id="cb44-137"><a href="linear-models.html#cb44-137" tabindex="-1"></a><span class="co">#&gt;     Student.Yes + Married.No, data = data.train.bin)</span></span>
<span id="cb44-138"><a href="linear-models.html#cb44-138" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb44-139"><a href="linear-models.html#cb44-139" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb44-140"><a href="linear-models.html#cb44-140" tabindex="-1"></a><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></span>
<span id="cb44-141"><a href="linear-models.html#cb44-141" tabindex="-1"></a><span class="co">#&gt; -195.2  -76.5  -14.0   65.3  285.3 </span></span>
<span id="cb44-142"><a href="linear-models.html#cb44-142" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb44-143"><a href="linear-models.html#cb44-143" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb44-144"><a href="linear-models.html#cb44-144" tabindex="-1"></a><span class="co">#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb44-145"><a href="linear-models.html#cb44-145" tabindex="-1"></a><span class="co">#&gt; (Intercept)  -565.2227    26.7378  -21.14   &lt;2e-16 ***</span></span>
<span id="cb44-146"><a href="linear-models.html#cb44-146" tabindex="-1"></a><span class="co">#&gt; Income         -7.8767     0.2795  -28.19   &lt;2e-16 ***</span></span>
<span id="cb44-147"><a href="linear-models.html#cb44-147" tabindex="-1"></a><span class="co">#&gt; Rating          4.0118     0.0633   63.37   &lt;2e-16 ***</span></span>
<span id="cb44-148"><a href="linear-models.html#cb44-148" tabindex="-1"></a><span class="co">#&gt; Age            -0.7702     0.3564   -2.16    0.031 *  </span></span>
<span id="cb44-149"><a href="linear-models.html#cb44-149" tabindex="-1"></a><span class="co">#&gt; Gender..Male   17.3210    11.8933    1.46    0.146    </span></span>
<span id="cb44-150"><a href="linear-models.html#cb44-150" tabindex="-1"></a><span class="co">#&gt; Student.Yes   418.8703    19.3465   21.65   &lt;2e-16 ***</span></span>
<span id="cb44-151"><a href="linear-models.html#cb44-151" tabindex="-1"></a><span class="co">#&gt; Married.No     18.7377    12.1486    1.54    0.124    </span></span>
<span id="cb44-152"><a href="linear-models.html#cb44-152" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb44-153"><a href="linear-models.html#cb44-153" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  </span></span>
<span id="cb44-154"><a href="linear-models.html#cb44-154" tabindex="-1"></a><span class="co">#&gt; 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb44-155"><a href="linear-models.html#cb44-155" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb44-156"><a href="linear-models.html#cb44-156" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 103 on 294 degrees of freedom</span></span>
<span id="cb44-157"><a href="linear-models.html#cb44-157" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.952,  Adjusted R-squared:  0.951 </span></span>
<span id="cb44-158"><a href="linear-models.html#cb44-158" tabindex="-1"></a><span class="co">#&gt; F-statistic:  965 on 6 and 294 DF,  p-value: &lt;2e-16</span></span></code></pre></div>
<p>If we look at using the <code>stepAIC()</code> function on a non-binarized dataset, at just the first iteration, we can see that the stepwise selection would drop the entire <code>Ethnicity</code> factor variable, rather than just some factor levels of it:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="linear-models.html#cb45-1" tabindex="-1"></a><span class="co"># CHUNK 17</span></span>
<span id="cb45-2"><a href="linear-models.html#cb45-2" tabindex="-1"></a>model.no.binarize <span class="ot">&lt;-</span> <span class="fu">stepAIC</span>(model.full, <span class="at">steps =</span> <span class="dv">1</span>)</span>
<span id="cb45-3"><a href="linear-models.html#cb45-3" tabindex="-1"></a><span class="co">#&gt; Start:  AIC=2802</span></span>
<span id="cb45-4"><a href="linear-models.html#cb45-4" tabindex="-1"></a><span class="co">#&gt; Balance ~ Income + Rating + Cards + Age + Education + Gender + </span></span>
<span id="cb45-5"><a href="linear-models.html#cb45-5" tabindex="-1"></a><span class="co">#&gt;     Student + Married + Ethnicity + Income:Student</span></span>
<span id="cb45-6"><a href="linear-models.html#cb45-6" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb45-7"><a href="linear-models.html#cb45-7" tabindex="-1"></a><span class="co">#&gt;                  Df Sum of Sq      RSS  AIC</span></span>
<span id="cb45-8"><a href="linear-models.html#cb45-8" tabindex="-1"></a><span class="co">#&gt; - Ethnicity       2      7042  3077014 2799</span></span>
<span id="cb45-9"><a href="linear-models.html#cb45-9" tabindex="-1"></a><span class="co">#&gt; - Education       1      2278  3072249 2800</span></span>
<span id="cb45-10"><a href="linear-models.html#cb45-10" tabindex="-1"></a><span class="co">#&gt; - Cards           1      4052  3074024 2801</span></span>
<span id="cb45-11"><a href="linear-models.html#cb45-11" tabindex="-1"></a><span class="co">#&gt; - Income:Student  1     10654  3080626 2801</span></span>
<span id="cb45-12"><a href="linear-models.html#cb45-12" tabindex="-1"></a><span class="co">#&gt; &lt;none&gt;                         3069972 2802</span></span>
<span id="cb45-13"><a href="linear-models.html#cb45-13" tabindex="-1"></a><span class="co">#&gt; - Gender          1     24859  3094830 2803</span></span>
<span id="cb45-14"><a href="linear-models.html#cb45-14" tabindex="-1"></a><span class="co">#&gt; - Married         1     28946  3098918 2803</span></span>
<span id="cb45-15"><a href="linear-models.html#cb45-15" tabindex="-1"></a><span class="co">#&gt; - Age             1     50885  3120857 2805</span></span>
<span id="cb45-16"><a href="linear-models.html#cb45-16" tabindex="-1"></a><span class="co">#&gt; - Rating          1  41548705 44618677 3606</span></span>
<span id="cb45-17"><a href="linear-models.html#cb45-17" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb45-18"><a href="linear-models.html#cb45-18" tabindex="-1"></a><span class="co">#&gt; Step:  AIC=2799</span></span>
<span id="cb45-19"><a href="linear-models.html#cb45-19" tabindex="-1"></a><span class="co">#&gt; Balance ~ Income + Rating + Cards + Age + Education + Gender + </span></span>
<span id="cb45-20"><a href="linear-models.html#cb45-20" tabindex="-1"></a><span class="co">#&gt;     Student + Married + Income:Student</span></span></code></pre></div>
<p>In the next code chunk, we will perform “forward” stepwise selection on the BIC. In this approach, we need to specify the <code>direction</code> parameter as “foward”, and define the penalty argument <code>k</code> as the log(size of training dataset), and the <code>scope</code> argument with the most complex and least complex forms of the model:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="linear-models.html#cb46-1" tabindex="-1"></a><span class="co"># CHUNK 18</span></span>
<span id="cb46-2"><a href="linear-models.html#cb46-2" tabindex="-1"></a><span class="co"># first fit the null model (i.e., model with no predictors)</span></span>
<span id="cb46-3"><a href="linear-models.html#cb46-3" tabindex="-1"></a>model.null <span class="ot">&lt;-</span> <span class="fu">lm</span>(Balance <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> data.train.bin)</span>
<span id="cb46-4"><a href="linear-models.html#cb46-4" tabindex="-1"></a></span>
<span id="cb46-5"><a href="linear-models.html#cb46-5" tabindex="-1"></a>model.forward.BIC <span class="ot">&lt;-</span> <span class="fu">stepAIC</span>(model.null,</span>
<span id="cb46-6"><a href="linear-models.html#cb46-6" tabindex="-1"></a>                             <span class="at">direction =</span> <span class="st">&quot;forward&quot;</span>,</span>
<span id="cb46-7"><a href="linear-models.html#cb46-7" tabindex="-1"></a>                             <span class="at">scope =</span> <span class="fu">list</span>(<span class="at">upper =</span> model.full.bin,</span>
<span id="cb46-8"><a href="linear-models.html#cb46-8" tabindex="-1"></a>                                          <span class="at">lower =</span> model.null),</span>
<span id="cb46-9"><a href="linear-models.html#cb46-9" tabindex="-1"></a>                             <span class="at">k =</span> <span class="fu">log</span>(<span class="fu">nrow</span>(data.train.bin)))</span>
<span id="cb46-10"><a href="linear-models.html#cb46-10" tabindex="-1"></a><span class="co">#&gt; Start:  AIC=3698</span></span>
<span id="cb46-11"><a href="linear-models.html#cb46-11" tabindex="-1"></a><span class="co">#&gt; Balance ~ 1</span></span>
<span id="cb46-12"><a href="linear-models.html#cb46-12" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb46-13"><a href="linear-models.html#cb46-13" tabindex="-1"></a><span class="co">#&gt;                              Df Sum of Sq      RSS</span></span>
<span id="cb46-14"><a href="linear-models.html#cb46-14" tabindex="-1"></a><span class="co">#&gt; + Rating                      1  47082983 16908423</span></span>
<span id="cb46-15"><a href="linear-models.html#cb46-15" tabindex="-1"></a><span class="co">#&gt; + Income                      1  12910007 51081399</span></span>
<span id="cb46-16"><a href="linear-models.html#cb46-16" tabindex="-1"></a><span class="co">#&gt; + Student.Yes                 1   5425335 58566071</span></span>
<span id="cb46-17"><a href="linear-models.html#cb46-17" tabindex="-1"></a><span class="co">#&gt; &lt;none&gt;                                    63991406</span></span>
<span id="cb46-18"><a href="linear-models.html#cb46-18" tabindex="-1"></a><span class="co">#&gt; + Cards                       1    163291 63828115</span></span>
<span id="cb46-19"><a href="linear-models.html#cb46-19" tabindex="-1"></a><span class="co">#&gt; + Gender..Male                1    127201 63864205</span></span>
<span id="cb46-20"><a href="linear-models.html#cb46-20" tabindex="-1"></a><span class="co">#&gt; + Age                         1     79880 63911526</span></span>
<span id="cb46-21"><a href="linear-models.html#cb46-21" tabindex="-1"></a><span class="co">#&gt; + Education                   1     13121 63978284</span></span>
<span id="cb46-22"><a href="linear-models.html#cb46-22" tabindex="-1"></a><span class="co">#&gt; + Married.No                  1     10920 63980486</span></span>
<span id="cb46-23"><a href="linear-models.html#cb46-23" tabindex="-1"></a><span class="co">#&gt; + Ethnicity.Asian             1      3049 63988357</span></span>
<span id="cb46-24"><a href="linear-models.html#cb46-24" tabindex="-1"></a><span class="co">#&gt; + Ethnicity.African.American  1         0 63991406</span></span>
<span id="cb46-25"><a href="linear-models.html#cb46-25" tabindex="-1"></a><span class="co">#&gt;                               AIC</span></span>
<span id="cb46-26"><a href="linear-models.html#cb46-26" tabindex="-1"></a><span class="co">#&gt; + Rating                     3303</span></span>
<span id="cb46-27"><a href="linear-models.html#cb46-27" tabindex="-1"></a><span class="co">#&gt; + Income                     3636</span></span>
<span id="cb46-28"><a href="linear-models.html#cb46-28" tabindex="-1"></a><span class="co">#&gt; + Student.Yes                3677</span></span>
<span id="cb46-29"><a href="linear-models.html#cb46-29" tabindex="-1"></a><span class="co">#&gt; &lt;none&gt;                       3698</span></span>
<span id="cb46-30"><a href="linear-models.html#cb46-30" tabindex="-1"></a><span class="co">#&gt; + Cards                      3703</span></span>
<span id="cb46-31"><a href="linear-models.html#cb46-31" tabindex="-1"></a><span class="co">#&gt; + Gender..Male               3703</span></span>
<span id="cb46-32"><a href="linear-models.html#cb46-32" tabindex="-1"></a><span class="co">#&gt; + Age                        3703</span></span>
<span id="cb46-33"><a href="linear-models.html#cb46-33" tabindex="-1"></a><span class="co">#&gt; + Education                  3704</span></span>
<span id="cb46-34"><a href="linear-models.html#cb46-34" tabindex="-1"></a><span class="co">#&gt; + Married.No                 3704</span></span>
<span id="cb46-35"><a href="linear-models.html#cb46-35" tabindex="-1"></a><span class="co">#&gt; + Ethnicity.Asian            3704</span></span>
<span id="cb46-36"><a href="linear-models.html#cb46-36" tabindex="-1"></a><span class="co">#&gt; + Ethnicity.African.American 3704</span></span>
<span id="cb46-37"><a href="linear-models.html#cb46-37" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb46-38"><a href="linear-models.html#cb46-38" tabindex="-1"></a><span class="co">#&gt; Step:  AIC=3303</span></span>
<span id="cb46-39"><a href="linear-models.html#cb46-39" tabindex="-1"></a><span class="co">#&gt; Balance ~ Rating</span></span>
<span id="cb46-40"><a href="linear-models.html#cb46-40" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb46-41"><a href="linear-models.html#cb46-41" tabindex="-1"></a><span class="co">#&gt;                              Df Sum of Sq      RSS</span></span>
<span id="cb46-42"><a href="linear-models.html#cb46-42" tabindex="-1"></a><span class="co">#&gt; + Income                      1   8650956  8257467</span></span>
<span id="cb46-43"><a href="linear-models.html#cb46-43" tabindex="-1"></a><span class="co">#&gt; + Student.Yes                 1   4817765 12090659</span></span>
<span id="cb46-44"><a href="linear-models.html#cb46-44" tabindex="-1"></a><span class="co">#&gt; + Age                         1    707560 16200863</span></span>
<span id="cb46-45"><a href="linear-models.html#cb46-45" tabindex="-1"></a><span class="co">#&gt; &lt;none&gt;                                    16908423</span></span>
<span id="cb46-46"><a href="linear-models.html#cb46-46" tabindex="-1"></a><span class="co">#&gt; + Married.No                  1    174547 16733876</span></span>
<span id="cb46-47"><a href="linear-models.html#cb46-47" tabindex="-1"></a><span class="co">#&gt; + Education                   1     71402 16837022</span></span>
<span id="cb46-48"><a href="linear-models.html#cb46-48" tabindex="-1"></a><span class="co">#&gt; + Ethnicity.Asian             1     49620 16858804</span></span>
<span id="cb46-49"><a href="linear-models.html#cb46-49" tabindex="-1"></a><span class="co">#&gt; + Gender..Male                1     31887 16876536</span></span>
<span id="cb46-50"><a href="linear-models.html#cb46-50" tabindex="-1"></a><span class="co">#&gt; + Cards                       1     30049 16878374</span></span>
<span id="cb46-51"><a href="linear-models.html#cb46-51" tabindex="-1"></a><span class="co">#&gt; + Ethnicity.African.American  1      4304 16904120</span></span>
<span id="cb46-52"><a href="linear-models.html#cb46-52" tabindex="-1"></a><span class="co">#&gt;                               AIC</span></span>
<span id="cb46-53"><a href="linear-models.html#cb46-53" tabindex="-1"></a><span class="co">#&gt; + Income                     3093</span></span>
<span id="cb46-54"><a href="linear-models.html#cb46-54" tabindex="-1"></a><span class="co">#&gt; + Student.Yes                3208</span></span>
<span id="cb46-55"><a href="linear-models.html#cb46-55" tabindex="-1"></a><span class="co">#&gt; + Age                        3296</span></span>
<span id="cb46-56"><a href="linear-models.html#cb46-56" tabindex="-1"></a><span class="co">#&gt; &lt;none&gt;                       3303</span></span>
<span id="cb46-57"><a href="linear-models.html#cb46-57" tabindex="-1"></a><span class="co">#&gt; + Married.No                 3306</span></span>
<span id="cb46-58"><a href="linear-models.html#cb46-58" tabindex="-1"></a><span class="co">#&gt; + Education                  3308</span></span>
<span id="cb46-59"><a href="linear-models.html#cb46-59" tabindex="-1"></a><span class="co">#&gt; + Ethnicity.Asian            3308</span></span>
<span id="cb46-60"><a href="linear-models.html#cb46-60" tabindex="-1"></a><span class="co">#&gt; + Gender..Male               3308</span></span>
<span id="cb46-61"><a href="linear-models.html#cb46-61" tabindex="-1"></a><span class="co">#&gt; + Cards                      3308</span></span>
<span id="cb46-62"><a href="linear-models.html#cb46-62" tabindex="-1"></a><span class="co">#&gt; + Ethnicity.African.American 3309</span></span>
<span id="cb46-63"><a href="linear-models.html#cb46-63" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb46-64"><a href="linear-models.html#cb46-64" tabindex="-1"></a><span class="co">#&gt; Step:  AIC=3093</span></span>
<span id="cb46-65"><a href="linear-models.html#cb46-65" tabindex="-1"></a><span class="co">#&gt; Balance ~ Rating + Income</span></span>
<span id="cb46-66"><a href="linear-models.html#cb46-66" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb46-67"><a href="linear-models.html#cb46-67" tabindex="-1"></a><span class="co">#&gt;                              Df Sum of Sq     RSS  AIC</span></span>
<span id="cb46-68"><a href="linear-models.html#cb46-68" tabindex="-1"></a><span class="co">#&gt; + Student.Yes                 1   5069114 3188353 2812</span></span>
<span id="cb46-69"><a href="linear-models.html#cb46-69" tabindex="-1"></a><span class="co">#&gt; &lt;none&gt;                                    8257467 3093</span></span>
<span id="cb46-70"><a href="linear-models.html#cb46-70" tabindex="-1"></a><span class="co">#&gt; + Married.No                  1    127904 8129563 3094</span></span>
<span id="cb46-71"><a href="linear-models.html#cb46-71" tabindex="-1"></a><span class="co">#&gt; + Age                         1     95208 8162259 3095</span></span>
<span id="cb46-72"><a href="linear-models.html#cb46-72" tabindex="-1"></a><span class="co">#&gt; + Education                   1     44496 8212971 3097</span></span>
<span id="cb46-73"><a href="linear-models.html#cb46-73" tabindex="-1"></a><span class="co">#&gt; + Ethnicity.Asian             1     40115 8217352 3097</span></span>
<span id="cb46-74"><a href="linear-models.html#cb46-74" tabindex="-1"></a><span class="co">#&gt; + Cards                       1     22019 8235448 3098</span></span>
<span id="cb46-75"><a href="linear-models.html#cb46-75" tabindex="-1"></a><span class="co">#&gt; + Ethnicity.African.American  1      9464 8248003 3099</span></span>
<span id="cb46-76"><a href="linear-models.html#cb46-76" tabindex="-1"></a><span class="co">#&gt; + Gender..Male                1       244 8257223 3099</span></span>
<span id="cb46-77"><a href="linear-models.html#cb46-77" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb46-78"><a href="linear-models.html#cb46-78" tabindex="-1"></a><span class="co">#&gt; Step:  AIC=2812</span></span>
<span id="cb46-79"><a href="linear-models.html#cb46-79" tabindex="-1"></a><span class="co">#&gt; Balance ~ Rating + Income + Student.Yes</span></span>
<span id="cb46-80"><a href="linear-models.html#cb46-80" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb46-81"><a href="linear-models.html#cb46-81" tabindex="-1"></a><span class="co">#&gt;                              Df Sum of Sq     RSS  AIC</span></span>
<span id="cb46-82"><a href="linear-models.html#cb46-82" tabindex="-1"></a><span class="co">#&gt; &lt;none&gt;                                    3188353 2812</span></span>
<span id="cb46-83"><a href="linear-models.html#cb46-83" tabindex="-1"></a><span class="co">#&gt; + Age                         1     46257 3142096 2814</span></span>
<span id="cb46-84"><a href="linear-models.html#cb46-84" tabindex="-1"></a><span class="co">#&gt; + Gender..Male                1     24128 3164225 2816</span></span>
<span id="cb46-85"><a href="linear-models.html#cb46-85" tabindex="-1"></a><span class="co">#&gt; + Married.No                  1     23759 3164595 2816</span></span>
<span id="cb46-86"><a href="linear-models.html#cb46-86" tabindex="-1"></a><span class="co">#&gt; + Income:Student.Yes          1      7569 3180784 2817</span></span>
<span id="cb46-87"><a href="linear-models.html#cb46-87" tabindex="-1"></a><span class="co">#&gt; + Ethnicity.African.American  1      2346 3186007 2818</span></span>
<span id="cb46-88"><a href="linear-models.html#cb46-88" tabindex="-1"></a><span class="co">#&gt; + Education                   1      1600 3186753 2818</span></span>
<span id="cb46-89"><a href="linear-models.html#cb46-89" tabindex="-1"></a><span class="co">#&gt; + Cards                       1       865 3187488 2818</span></span>
<span id="cb46-90"><a href="linear-models.html#cb46-90" tabindex="-1"></a><span class="co">#&gt; + Ethnicity.Asian             1       747 3187606 2818</span></span>
<span id="cb46-91"><a href="linear-models.html#cb46-91" tabindex="-1"></a></span>
<span id="cb46-92"><a href="linear-models.html#cb46-92" tabindex="-1"></a><span class="fu">summary</span>(model.forward.BIC)</span>
<span id="cb46-93"><a href="linear-models.html#cb46-93" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb46-94"><a href="linear-models.html#cb46-94" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb46-95"><a href="linear-models.html#cb46-95" tabindex="-1"></a><span class="co">#&gt; lm(formula = Balance ~ Rating + Income + Student.Yes, data = data.train.bin)</span></span>
<span id="cb46-96"><a href="linear-models.html#cb46-96" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb46-97"><a href="linear-models.html#cb46-97" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb46-98"><a href="linear-models.html#cb46-98" tabindex="-1"></a><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span id="cb46-99"><a href="linear-models.html#cb46-99" tabindex="-1"></a><span class="co">#&gt; -220.29  -78.12   -7.47   63.27  299.90 </span></span>
<span id="cb46-100"><a href="linear-models.html#cb46-100" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb46-101"><a href="linear-models.html#cb46-101" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb46-102"><a href="linear-models.html#cb46-102" tabindex="-1"></a><span class="co">#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb46-103"><a href="linear-models.html#cb46-103" tabindex="-1"></a><span class="co">#&gt; (Intercept) -589.1664    16.1101   -36.6   &lt;2e-16 ***</span></span>
<span id="cb46-104"><a href="linear-models.html#cb46-104" tabindex="-1"></a><span class="co">#&gt; Rating         4.0163     0.0635    63.2   &lt;2e-16 ***</span></span>
<span id="cb46-105"><a href="linear-models.html#cb46-105" tabindex="-1"></a><span class="co">#&gt; Income        -7.9741     0.2769   -28.8   &lt;2e-16 ***</span></span>
<span id="cb46-106"><a href="linear-models.html#cb46-106" tabindex="-1"></a><span class="co">#&gt; Student.Yes  421.1734    19.3821    21.7   &lt;2e-16 ***</span></span>
<span id="cb46-107"><a href="linear-models.html#cb46-107" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb46-108"><a href="linear-models.html#cb46-108" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  </span></span>
<span id="cb46-109"><a href="linear-models.html#cb46-109" tabindex="-1"></a><span class="co">#&gt; 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb46-110"><a href="linear-models.html#cb46-110" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb46-111"><a href="linear-models.html#cb46-111" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 104 on 297 degrees of freedom</span></span>
<span id="cb46-112"><a href="linear-models.html#cb46-112" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.95,   Adjusted R-squared:  0.95 </span></span>
<span id="cb46-113"><a href="linear-models.html#cb46-113" tabindex="-1"></a><span class="co">#&gt; F-statistic: 1.89e+03 on 3 and 297 DF,  p-value: &lt;2e-16</span></span></code></pre></div>
<p>Based on forward selection and BIC, the final model will only have three predictor terms, <code>Rating</code>, <code>Income</code> and <code>Student.Yes</code>.</p>
<p>If you do stepwise selection with BIC, your final model will tend to be simpler.</p>
<hr />
</div>
</div>
<div id="model-validation" class="section level3 hasAnchor" number="3.4.3">
<h3><span class="header-section-number">3.4.3</span> Model Validation<a href="linear-models.html#model-validation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="task-8-select-and-validate-the-recommended-model" class="section level3 unnumbered hasAnchor">
<h3>TASK 8: Select and Validate the Recommended Model<a href="linear-models.html#task-8-select-and-validate-the-recommended-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="task-statement-9" class="section level4 unnumbered hasAnchor">
<h4>Task Statement<a href="linear-models.html#task-statement-9" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Evaluate the <strong>RMSE</strong> of the models in the preceding subsection against the <strong>test set</strong>.</li>
<li>Make a <strong>recommendation</strong> as to which model should be used.</li>
<li>Generate and interpret <strong>diagnostic plots</strong> for the recommended model to check the model assumptions.</li>
</ul>
<p>Here we will evaluate the RMSE of the models in the preceding subsection against the test set using the <code>RMSE()</code> function in the <code>caret</code> package. The <code>RMSE()</code> function takes a vector of target values for the first parameter, and a vector of predicted fitted-values as the second parameter. We specify the <code>newdata=data.test.bin</code> to calculate the prediction performance on the test data.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="linear-models.html#cb47-1" tabindex="-1"></a><span class="co"># CHUNK 19</span></span>
<span id="cb47-2"><a href="linear-models.html#cb47-2" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb47-3"><a href="linear-models.html#cb47-3" tabindex="-1"></a></span>
<span id="cb47-4"><a href="linear-models.html#cb47-4" tabindex="-1"></a><span class="fu">RMSE</span>(data.test<span class="sc">$</span>Balance, <span class="fu">predict</span>(model.null, <span class="at">newdata =</span> data.test.bin))</span>
<span id="cb47-5"><a href="linear-models.html#cb47-5" tabindex="-1"></a><span class="co">#&gt; [1] 453.4</span></span>
<span id="cb47-6"><a href="linear-models.html#cb47-6" tabindex="-1"></a><span class="fu">RMSE</span>(data.test<span class="sc">$</span>Balance, <span class="fu">predict</span>(model.full.bin, <span class="at">newdata =</span> data.test.bin))</span>
<span id="cb47-7"><a href="linear-models.html#cb47-7" tabindex="-1"></a><span class="co">#&gt; [1] 105.1</span></span>
<span id="cb47-8"><a href="linear-models.html#cb47-8" tabindex="-1"></a><span class="fu">RMSE</span>(data.test<span class="sc">$</span>Balance, <span class="fu">predict</span>(model.backward.AIC, <span class="at">newdata =</span> data.test.bin))</span>
<span id="cb47-9"><a href="linear-models.html#cb47-9" tabindex="-1"></a><span class="co">#&gt; [1] 104.2</span></span>
<span id="cb47-10"><a href="linear-models.html#cb47-10" tabindex="-1"></a><span class="fu">RMSE</span>(data.test<span class="sc">$</span>Balance, <span class="fu">predict</span>(model.forward.BIC, <span class="at">newdata =</span> data.test.bin))</span>
<span id="cb47-11"><a href="linear-models.html#cb47-11" tabindex="-1"></a><span class="co">#&gt; [1] 102.7</span></span></code></pre></div>
<p>Based on the output, the fourth model <code>model.forward.BIC</code> achieves the lowest RMSE and therefore has the greatest prediction performance on the test data.</p>
<p>We plot the model below:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="linear-models.html#cb48-1" tabindex="-1"></a><span class="co"># CHUNK 20</span></span>
<span id="cb48-2"><a href="linear-models.html#cb48-2" tabindex="-1"></a><span class="fu">plot</span>(model.forward.BIC)</span></code></pre></div>
<p><img src="figures/unnamed-chunk-52-1.png" width="100%" style="display: block; margin: auto;" /><img src="figures/unnamed-chunk-52-2.png" width="100%" style="display: block; margin: auto;" /><img src="figures/unnamed-chunk-52-3.png" width="100%" style="display: block; margin: auto;" /><img src="figures/unnamed-chunk-52-4.png" width="100%" style="display: block; margin: auto;" /></p>
<p>The first plot is the <strong>Residuals vs. Fitted Values</strong> on the training set. If the model has captured the signal effectively, then the residuals should behave randomly and there should be no systematic patterns in the plot. But that is not the case here, you can see a clear U-shape in the plot. That means there may be non-linear relationships not captured by the linear model. To remedy the problem, we may try to add non-linear terms (polynomial terms) or interaction terms to the model equation.</p>
<p>The <strong>Q-Q Plot</strong> plots the standardized empirical residuals against the theoretical quantiles. This plot is intended to check the normality of the standard errors. If the points lie on the 45-degree line, the normality assumption should be fine. In this plot, the points lie quite closely in the middle part, but not in the two extreme tails. The points above the 45-degree line in the right tail suggest a heavy tail or right-skew.</p>
<p>Overall, the predictive performance of the model is good, however the diagnostic plots suggest some room for improvement.</p>
</div>
</div>
<div id="regularization-2" class="section level3 hasAnchor" number="3.4.4">
<h3><span class="header-section-number">3.4.4</span> Regularization<a href="linear-models.html#regularization-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="task-9-effect-of-regularization" class="section level3 unnumbered hasAnchor">
<h3>TASK 9: Effect of Regularization<a href="linear-models.html#task-9-effect-of-regularization" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="task-statement-10" class="section level4 unnumbered hasAnchor">
<h4>Task Statement<a href="linear-models.html#task-statement-10" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Explain whether using <code>alpha = 0</code> is appropriate for this case study.</li>
<li>Regardless of your conclusion, use elastic net with <code>alpha = 0.5</code> to fit a regularized regression model with the following values of <code>lambda</code>: 0, 10, 100, 500, 1000.</li>
<li>State your <strong>observations</strong>.</li>
</ul>
</div>
<div id="notes" class="section level4 unnumbered hasAnchor">
<h4>Notes<a href="linear-models.html#notes" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Remember <code>alpha = 0</code> corresponds to <strong>ridge regression</strong> (no features dropped).</li>
<li><strong>Goal</strong>: To identify key factors affecting <strong>Balance</strong>.</li>
</ul>
<p>To perform regularization, we will use the <code>glmnet</code> package. The <code>glmnet</code> function takes a model matrix (design matrix) as the <code>x</code> parameter and a vector of target variable values as the <code>y</code> parameter. In addition, you must specify the <code>family</code> distribution of the target variable, and provide candidates for the <code>lambda</code> and <code>alpha</code> hyperparameters.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="linear-models.html#cb49-1" tabindex="-1"></a><span class="co"># CHUNK 21</span></span>
<span id="cb49-2"><a href="linear-models.html#cb49-2" tabindex="-1"></a>X.train <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(Balance <span class="sc">~</span> . <span class="sc">+</span> Income<span class="sc">:</span>Student, <span class="at">data =</span> data.train)</span>
<span id="cb49-3"><a href="linear-models.html#cb49-3" tabindex="-1"></a><span class="fu">head</span>(X.train)  <span class="co"># print out a few rows of the design matrix</span></span>
<span id="cb49-4"><a href="linear-models.html#cb49-4" tabindex="-1"></a><span class="co">#&gt;   (Intercept) Income Rating Cards Age Education</span></span>
<span id="cb49-5"><a href="linear-models.html#cb49-5" tabindex="-1"></a><span class="co">#&gt; 1           1  14.89    283     2  34        11</span></span>
<span id="cb49-6"><a href="linear-models.html#cb49-6" tabindex="-1"></a><span class="co">#&gt; 2           1 106.03    483     3  82        15</span></span>
<span id="cb49-7"><a href="linear-models.html#cb49-7" tabindex="-1"></a><span class="co">#&gt; 3           1 104.59    514     4  71        11</span></span>
<span id="cb49-8"><a href="linear-models.html#cb49-8" tabindex="-1"></a><span class="co">#&gt; 6           1  80.18    569     4  77        10</span></span>
<span id="cb49-9"><a href="linear-models.html#cb49-9" tabindex="-1"></a><span class="co">#&gt; 8           1  71.41    512     2  87         9</span></span>
<span id="cb49-10"><a href="linear-models.html#cb49-10" tabindex="-1"></a><span class="co">#&gt; 9           1  15.12    266     5  66        13</span></span>
<span id="cb49-11"><a href="linear-models.html#cb49-11" tabindex="-1"></a><span class="co">#&gt;   Gender Male StudentYes MarriedNo</span></span>
<span id="cb49-12"><a href="linear-models.html#cb49-12" tabindex="-1"></a><span class="co">#&gt; 1           1          0         0</span></span>
<span id="cb49-13"><a href="linear-models.html#cb49-13" tabindex="-1"></a><span class="co">#&gt; 2           0          1         0</span></span>
<span id="cb49-14"><a href="linear-models.html#cb49-14" tabindex="-1"></a><span class="co">#&gt; 3           1          0         1</span></span>
<span id="cb49-15"><a href="linear-models.html#cb49-15" tabindex="-1"></a><span class="co">#&gt; 6           1          0         1</span></span>
<span id="cb49-16"><a href="linear-models.html#cb49-16" tabindex="-1"></a><span class="co">#&gt; 8           1          0         1</span></span>
<span id="cb49-17"><a href="linear-models.html#cb49-17" tabindex="-1"></a><span class="co">#&gt; 9           0          0         1</span></span>
<span id="cb49-18"><a href="linear-models.html#cb49-18" tabindex="-1"></a><span class="co">#&gt;   EthnicityAfrican American EthnicityAsian</span></span>
<span id="cb49-19"><a href="linear-models.html#cb49-19" tabindex="-1"></a><span class="co">#&gt; 1                         0              0</span></span>
<span id="cb49-20"><a href="linear-models.html#cb49-20" tabindex="-1"></a><span class="co">#&gt; 2                         0              1</span></span>
<span id="cb49-21"><a href="linear-models.html#cb49-21" tabindex="-1"></a><span class="co">#&gt; 3                         0              1</span></span>
<span id="cb49-22"><a href="linear-models.html#cb49-22" tabindex="-1"></a><span class="co">#&gt; 6                         0              0</span></span>
<span id="cb49-23"><a href="linear-models.html#cb49-23" tabindex="-1"></a><span class="co">#&gt; 8                         0              1</span></span>
<span id="cb49-24"><a href="linear-models.html#cb49-24" tabindex="-1"></a><span class="co">#&gt; 9                         0              0</span></span>
<span id="cb49-25"><a href="linear-models.html#cb49-25" tabindex="-1"></a><span class="co">#&gt;   Income:StudentYes</span></span>
<span id="cb49-26"><a href="linear-models.html#cb49-26" tabindex="-1"></a><span class="co">#&gt; 1                 0</span></span>
<span id="cb49-27"><a href="linear-models.html#cb49-27" tabindex="-1"></a><span class="co">#&gt; 2               106</span></span>
<span id="cb49-28"><a href="linear-models.html#cb49-28" tabindex="-1"></a><span class="co">#&gt; 3                 0</span></span>
<span id="cb49-29"><a href="linear-models.html#cb49-29" tabindex="-1"></a><span class="co">#&gt; 6                 0</span></span>
<span id="cb49-30"><a href="linear-models.html#cb49-30" tabindex="-1"></a><span class="co">#&gt; 8                 0</span></span>
<span id="cb49-31"><a href="linear-models.html#cb49-31" tabindex="-1"></a><span class="co">#&gt; 9                 0</span></span></code></pre></div>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="linear-models.html#cb50-1" tabindex="-1"></a><span class="co"># CHUNK 22</span></span>
<span id="cb50-2"><a href="linear-models.html#cb50-2" tabindex="-1"></a><span class="co">#install.packages(&quot;glmnet&quot;)  # uncomment this line the first time you use glmnet</span></span>
<span id="cb50-3"><a href="linear-models.html#cb50-3" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb50-4"><a href="linear-models.html#cb50-4" tabindex="-1"></a></span>
<span id="cb50-5"><a href="linear-models.html#cb50-5" tabindex="-1"></a>m.lambda <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(<span class="at">x =</span> X.train,</span>
<span id="cb50-6"><a href="linear-models.html#cb50-6" tabindex="-1"></a>                   <span class="at">y =</span> data.train<span class="sc">$</span>Balance,</span>
<span id="cb50-7"><a href="linear-models.html#cb50-7" tabindex="-1"></a>                   <span class="at">family =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb50-8"><a href="linear-models.html#cb50-8" tabindex="-1"></a>                   <span class="at">lambda =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">500</span>, <span class="dv">1000</span>),</span>
<span id="cb50-9"><a href="linear-models.html#cb50-9" tabindex="-1"></a>                   <span class="at">alpha =</span> <span class="fl">0.5</span>)</span>
<span id="cb50-10"><a href="linear-models.html#cb50-10" tabindex="-1"></a></span>
<span id="cb50-11"><a href="linear-models.html#cb50-11" tabindex="-1"></a><span class="co"># first way to extract coefficient estimates</span></span>
<span id="cb50-12"><a href="linear-models.html#cb50-12" tabindex="-1"></a>m.lambda<span class="sc">$</span>a0</span>
<span id="cb50-13"><a href="linear-models.html#cb50-13" tabindex="-1"></a><span class="co">#&gt;     s0     s1     s2     s3     s4 </span></span>
<span id="cb50-14"><a href="linear-models.html#cb50-14" tabindex="-1"></a><span class="co">#&gt;  520.4  301.3 -225.0 -506.0 -579.2</span></span>
<span id="cb50-15"><a href="linear-models.html#cb50-15" tabindex="-1"></a>m.lambda<span class="sc">$</span>beta</span>
<span id="cb50-16"><a href="linear-models.html#cb50-16" tabindex="-1"></a><span class="co">#&gt; 12 x 5 sparse Matrix of class &quot;dgCMatrix&quot;</span></span>
<span id="cb50-17"><a href="linear-models.html#cb50-17" tabindex="-1"></a><span class="co">#&gt;                           s0     s1      s2        s3</span></span>
<span id="cb50-18"><a href="linear-models.html#cb50-18" tabindex="-1"></a><span class="co">#&gt; (Intercept)                . .        .       .      </span></span>
<span id="cb50-19"><a href="linear-models.html#cb50-19" tabindex="-1"></a><span class="co">#&gt; Income                     . .        .      -6.63361</span></span>
<span id="cb50-20"><a href="linear-models.html#cb50-20" tabindex="-1"></a><span class="co">#&gt; Rating                     . 0.6183   2.034   3.71043</span></span>
<span id="cb50-21"><a href="linear-models.html#cb50-21" tabindex="-1"></a><span class="co">#&gt; Cards                      . .        .       0.51434</span></span>
<span id="cb50-22"><a href="linear-models.html#cb50-22" tabindex="-1"></a><span class="co">#&gt; Age                        . .        .      -0.70551</span></span>
<span id="cb50-23"><a href="linear-models.html#cb50-23" tabindex="-1"></a><span class="co">#&gt; Education                  . .        .       .      </span></span>
<span id="cb50-24"><a href="linear-models.html#cb50-24" tabindex="-1"></a><span class="co">#&gt; Gender Male                . .        .       3.08510</span></span>
<span id="cb50-25"><a href="linear-models.html#cb50-25" tabindex="-1"></a><span class="co">#&gt; StudentYes                 . .      228.763 396.62015</span></span>
<span id="cb50-26"><a href="linear-models.html#cb50-26" tabindex="-1"></a><span class="co">#&gt; MarriedNo                  . .        .       9.36968</span></span>
<span id="cb50-27"><a href="linear-models.html#cb50-27" tabindex="-1"></a><span class="co">#&gt; EthnicityAfrican American  . .        .       .      </span></span>
<span id="cb50-28"><a href="linear-models.html#cb50-28" tabindex="-1"></a><span class="co">#&gt; EthnicityAsian             . .        .       .      </span></span>
<span id="cb50-29"><a href="linear-models.html#cb50-29" tabindex="-1"></a><span class="co">#&gt; Income:StudentYes          . .        .       0.01473</span></span>
<span id="cb50-30"><a href="linear-models.html#cb50-30" tabindex="-1"></a><span class="co">#&gt;                                 s4</span></span>
<span id="cb50-31"><a href="linear-models.html#cb50-31" tabindex="-1"></a><span class="co">#&gt; (Intercept)                 .     </span></span>
<span id="cb50-32"><a href="linear-models.html#cb50-32" tabindex="-1"></a><span class="co">#&gt; Income                     -7.9321</span></span>
<span id="cb50-33"><a href="linear-models.html#cb50-33" tabindex="-1"></a><span class="co">#&gt; Rating                      4.0115</span></span>
<span id="cb50-34"><a href="linear-models.html#cb50-34" tabindex="-1"></a><span class="co">#&gt; Cards                       2.9162</span></span>
<span id="cb50-35"><a href="linear-models.html#cb50-35" tabindex="-1"></a><span class="co">#&gt; Age                        -0.7885</span></span>
<span id="cb50-36"><a href="linear-models.html#cb50-36" tabindex="-1"></a><span class="co">#&gt; Education                   0.8875</span></span>
<span id="cb50-37"><a href="linear-models.html#cb50-37" tabindex="-1"></a><span class="co">#&gt; Gender Male                18.3671</span></span>
<span id="cb50-38"><a href="linear-models.html#cb50-38" tabindex="-1"></a><span class="co">#&gt; StudentYes                396.2181</span></span>
<span id="cb50-39"><a href="linear-models.html#cb50-39" tabindex="-1"></a><span class="co">#&gt; MarriedNo                  20.4647</span></span>
<span id="cb50-40"><a href="linear-models.html#cb50-40" tabindex="-1"></a><span class="co">#&gt; EthnicityAfrican American -11.9281</span></span>
<span id="cb50-41"><a href="linear-models.html#cb50-41" tabindex="-1"></a><span class="co">#&gt; EthnicityAsian             -5.3983</span></span>
<span id="cb50-42"><a href="linear-models.html#cb50-42" tabindex="-1"></a><span class="co">#&gt; Income:StudentYes           0.4929</span></span>
<span id="cb50-43"><a href="linear-models.html#cb50-43" tabindex="-1"></a></span>
<span id="cb50-44"><a href="linear-models.html#cb50-44" tabindex="-1"></a><span class="co"># second way</span></span>
<span id="cb50-45"><a href="linear-models.html#cb50-45" tabindex="-1"></a><span class="fu">coef</span>(m.lambda)</span>
<span id="cb50-46"><a href="linear-models.html#cb50-46" tabindex="-1"></a><span class="co">#&gt; 13 x 5 sparse Matrix of class &quot;dgCMatrix&quot;</span></span>
<span id="cb50-47"><a href="linear-models.html#cb50-47" tabindex="-1"></a><span class="co">#&gt;                              s0       s1       s2</span></span>
<span id="cb50-48"><a href="linear-models.html#cb50-48" tabindex="-1"></a><span class="co">#&gt; (Intercept)               520.4 301.2973 -224.967</span></span>
<span id="cb50-49"><a href="linear-models.html#cb50-49" tabindex="-1"></a><span class="co">#&gt; (Intercept)                 .     .         .    </span></span>
<span id="cb50-50"><a href="linear-models.html#cb50-50" tabindex="-1"></a><span class="co">#&gt; Income                      .     .         .    </span></span>
<span id="cb50-51"><a href="linear-models.html#cb50-51" tabindex="-1"></a><span class="co">#&gt; Rating                      .     0.6183    2.034</span></span>
<span id="cb50-52"><a href="linear-models.html#cb50-52" tabindex="-1"></a><span class="co">#&gt; Cards                       .     .         .    </span></span>
<span id="cb50-53"><a href="linear-models.html#cb50-53" tabindex="-1"></a><span class="co">#&gt; Age                         .     .         .    </span></span>
<span id="cb50-54"><a href="linear-models.html#cb50-54" tabindex="-1"></a><span class="co">#&gt; Education                   .     .         .    </span></span>
<span id="cb50-55"><a href="linear-models.html#cb50-55" tabindex="-1"></a><span class="co">#&gt; Gender Male                 .     .         .    </span></span>
<span id="cb50-56"><a href="linear-models.html#cb50-56" tabindex="-1"></a><span class="co">#&gt; StudentYes                  .     .       228.763</span></span>
<span id="cb50-57"><a href="linear-models.html#cb50-57" tabindex="-1"></a><span class="co">#&gt; MarriedNo                   .     .         .    </span></span>
<span id="cb50-58"><a href="linear-models.html#cb50-58" tabindex="-1"></a><span class="co">#&gt; EthnicityAfrican American   .     .         .    </span></span>
<span id="cb50-59"><a href="linear-models.html#cb50-59" tabindex="-1"></a><span class="co">#&gt; EthnicityAsian              .     .         .    </span></span>
<span id="cb50-60"><a href="linear-models.html#cb50-60" tabindex="-1"></a><span class="co">#&gt; Income:StudentYes           .     .         .    </span></span>
<span id="cb50-61"><a href="linear-models.html#cb50-61" tabindex="-1"></a><span class="co">#&gt;                                   s3        s4</span></span>
<span id="cb50-62"><a href="linear-models.html#cb50-62" tabindex="-1"></a><span class="co">#&gt; (Intercept)               -506.01795 -579.1925</span></span>
<span id="cb50-63"><a href="linear-models.html#cb50-63" tabindex="-1"></a><span class="co">#&gt; (Intercept)                  .          .     </span></span>
<span id="cb50-64"><a href="linear-models.html#cb50-64" tabindex="-1"></a><span class="co">#&gt; Income                      -6.63361   -7.9321</span></span>
<span id="cb50-65"><a href="linear-models.html#cb50-65" tabindex="-1"></a><span class="co">#&gt; Rating                       3.71043    4.0115</span></span>
<span id="cb50-66"><a href="linear-models.html#cb50-66" tabindex="-1"></a><span class="co">#&gt; Cards                        0.51434    2.9162</span></span>
<span id="cb50-67"><a href="linear-models.html#cb50-67" tabindex="-1"></a><span class="co">#&gt; Age                         -0.70551   -0.7885</span></span>
<span id="cb50-68"><a href="linear-models.html#cb50-68" tabindex="-1"></a><span class="co">#&gt; Education                    .          0.8875</span></span>
<span id="cb50-69"><a href="linear-models.html#cb50-69" tabindex="-1"></a><span class="co">#&gt; Gender Male                  3.08510   18.3671</span></span>
<span id="cb50-70"><a href="linear-models.html#cb50-70" tabindex="-1"></a><span class="co">#&gt; StudentYes                 396.62015  396.2181</span></span>
<span id="cb50-71"><a href="linear-models.html#cb50-71" tabindex="-1"></a><span class="co">#&gt; MarriedNo                    9.36968   20.4647</span></span>
<span id="cb50-72"><a href="linear-models.html#cb50-72" tabindex="-1"></a><span class="co">#&gt; EthnicityAfrican American    .        -11.9281</span></span>
<span id="cb50-73"><a href="linear-models.html#cb50-73" tabindex="-1"></a><span class="co">#&gt; EthnicityAsian               .         -5.3983</span></span>
<span id="cb50-74"><a href="linear-models.html#cb50-74" tabindex="-1"></a><span class="co">#&gt; Income:StudentYes            0.01473    0.4929</span></span>
<span id="cb50-75"><a href="linear-models.html#cb50-75" tabindex="-1"></a></span>
<span id="cb50-76"><a href="linear-models.html#cb50-76" tabindex="-1"></a><span class="fu">mean</span>(data.train<span class="sc">$</span>Balance)</span>
<span id="cb50-77"><a href="linear-models.html#cb50-77" tabindex="-1"></a><span class="co">#&gt; [1] 520.4</span></span></code></pre></div>
<p>Next we’ll construct a ridge model, an elastic net model, and a lasso model:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="linear-models.html#cb51-1" tabindex="-1"></a><span class="co"># CHUNK 23</span></span>
<span id="cb51-2"><a href="linear-models.html#cb51-2" tabindex="-1"></a>m.ridge <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(<span class="at">x =</span> X.train,</span>
<span id="cb51-3"><a href="linear-models.html#cb51-3" tabindex="-1"></a>                  <span class="at">y =</span> data.train<span class="sc">$</span>Balance,</span>
<span id="cb51-4"><a href="linear-models.html#cb51-4" tabindex="-1"></a>                  <span class="at">family =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb51-5"><a href="linear-models.html#cb51-5" tabindex="-1"></a>                  <span class="at">lambda =</span> <span class="dv">10</span>,</span>
<span id="cb51-6"><a href="linear-models.html#cb51-6" tabindex="-1"></a>                  <span class="at">alpha =</span> <span class="dv">0</span>)</span>
<span id="cb51-7"><a href="linear-models.html#cb51-7" tabindex="-1"></a><span class="fu">coef</span>(m.ridge)</span>
<span id="cb51-8"><a href="linear-models.html#cb51-8" tabindex="-1"></a><span class="co">#&gt; 13 x 1 sparse Matrix of class &quot;dgCMatrix&quot;</span></span>
<span id="cb51-9"><a href="linear-models.html#cb51-9" tabindex="-1"></a><span class="co">#&gt;                                  s0</span></span>
<span id="cb51-10"><a href="linear-models.html#cb51-10" tabindex="-1"></a><span class="co">#&gt; (Intercept)               -523.1426</span></span>
<span id="cb51-11"><a href="linear-models.html#cb51-11" tabindex="-1"></a><span class="co">#&gt; (Intercept)                  .     </span></span>
<span id="cb51-12"><a href="linear-models.html#cb51-12" tabindex="-1"></a><span class="co">#&gt; Income                      -6.7528</span></span>
<span id="cb51-13"><a href="linear-models.html#cb51-13" tabindex="-1"></a><span class="co">#&gt; Rating                       3.7207</span></span>
<span id="cb51-14"><a href="linear-models.html#cb51-14" tabindex="-1"></a><span class="co">#&gt; Cards                        5.1458</span></span>
<span id="cb51-15"><a href="linear-models.html#cb51-15" tabindex="-1"></a><span class="co">#&gt; Age                         -0.9952</span></span>
<span id="cb51-16"><a href="linear-models.html#cb51-16" tabindex="-1"></a><span class="co">#&gt; Education                    0.9866</span></span>
<span id="cb51-17"><a href="linear-models.html#cb51-17" tabindex="-1"></a><span class="co">#&gt; Gender Male                 14.7247</span></span>
<span id="cb51-18"><a href="linear-models.html#cb51-18" tabindex="-1"></a><span class="co">#&gt; StudentYes                 390.5753</span></span>
<span id="cb51-19"><a href="linear-models.html#cb51-19" tabindex="-1"></a><span class="co">#&gt; MarriedNo                   20.1062</span></span>
<span id="cb51-20"><a href="linear-models.html#cb51-20" tabindex="-1"></a><span class="co">#&gt; EthnicityAfrican American  -10.0939</span></span>
<span id="cb51-21"><a href="linear-models.html#cb51-21" tabindex="-1"></a><span class="co">#&gt; EthnicityAsian              -4.4601</span></span>
<span id="cb51-22"><a href="linear-models.html#cb51-22" tabindex="-1"></a><span class="co">#&gt; Income:StudentYes            0.4123</span></span>
<span id="cb51-23"><a href="linear-models.html#cb51-23" tabindex="-1"></a></span>
<span id="cb51-24"><a href="linear-models.html#cb51-24" tabindex="-1"></a>m.elastic.net <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(<span class="at">x =</span> X.train,</span>
<span id="cb51-25"><a href="linear-models.html#cb51-25" tabindex="-1"></a>                        <span class="at">y =</span> data.train<span class="sc">$</span>Balance,</span>
<span id="cb51-26"><a href="linear-models.html#cb51-26" tabindex="-1"></a>                        <span class="at">family =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb51-27"><a href="linear-models.html#cb51-27" tabindex="-1"></a>                        <span class="at">lambda =</span> <span class="dv">10</span>,</span>
<span id="cb51-28"><a href="linear-models.html#cb51-28" tabindex="-1"></a>                        <span class="at">alpha =</span> <span class="fl">0.5</span>)</span>
<span id="cb51-29"><a href="linear-models.html#cb51-29" tabindex="-1"></a><span class="fu">coef</span>(m.elastic.net)</span>
<span id="cb51-30"><a href="linear-models.html#cb51-30" tabindex="-1"></a><span class="co">#&gt; 13 x 1 sparse Matrix of class &quot;dgCMatrix&quot;</span></span>
<span id="cb51-31"><a href="linear-models.html#cb51-31" tabindex="-1"></a><span class="co">#&gt;                                   s0</span></span>
<span id="cb51-32"><a href="linear-models.html#cb51-32" tabindex="-1"></a><span class="co">#&gt; (Intercept)               -506.12459</span></span>
<span id="cb51-33"><a href="linear-models.html#cb51-33" tabindex="-1"></a><span class="co">#&gt; (Intercept)                  .      </span></span>
<span id="cb51-34"><a href="linear-models.html#cb51-34" tabindex="-1"></a><span class="co">#&gt; Income                      -6.63607</span></span>
<span id="cb51-35"><a href="linear-models.html#cb51-35" tabindex="-1"></a><span class="co">#&gt; Rating                       3.71092</span></span>
<span id="cb51-36"><a href="linear-models.html#cb51-36" tabindex="-1"></a><span class="co">#&gt; Cards                        0.51137</span></span>
<span id="cb51-37"><a href="linear-models.html#cb51-37" tabindex="-1"></a><span class="co">#&gt; Age                         -0.70476</span></span>
<span id="cb51-38"><a href="linear-models.html#cb51-38" tabindex="-1"></a><span class="co">#&gt; Education                    .      </span></span>
<span id="cb51-39"><a href="linear-models.html#cb51-39" tabindex="-1"></a><span class="co">#&gt; Gender Male                  3.09012</span></span>
<span id="cb51-40"><a href="linear-models.html#cb51-40" tabindex="-1"></a><span class="co">#&gt; StudentYes                 396.73966</span></span>
<span id="cb51-41"><a href="linear-models.html#cb51-41" tabindex="-1"></a><span class="co">#&gt; MarriedNo                    9.36636</span></span>
<span id="cb51-42"><a href="linear-models.html#cb51-42" tabindex="-1"></a><span class="co">#&gt; EthnicityAfrican American    .      </span></span>
<span id="cb51-43"><a href="linear-models.html#cb51-43" tabindex="-1"></a><span class="co">#&gt; EthnicityAsian               .      </span></span>
<span id="cb51-44"><a href="linear-models.html#cb51-44" tabindex="-1"></a><span class="co">#&gt; Income:StudentYes            0.01376</span></span>
<span id="cb51-45"><a href="linear-models.html#cb51-45" tabindex="-1"></a></span>
<span id="cb51-46"><a href="linear-models.html#cb51-46" tabindex="-1"></a>m.lasso <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(<span class="at">x =</span> X.train,</span>
<span id="cb51-47"><a href="linear-models.html#cb51-47" tabindex="-1"></a>                  <span class="at">y =</span> data.train<span class="sc">$</span>Balance,</span>
<span id="cb51-48"><a href="linear-models.html#cb51-48" tabindex="-1"></a>                  <span class="at">family =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb51-49"><a href="linear-models.html#cb51-49" tabindex="-1"></a>                  <span class="at">lambda =</span> <span class="dv">10</span>,</span>
<span id="cb51-50"><a href="linear-models.html#cb51-50" tabindex="-1"></a>                  <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb51-51"><a href="linear-models.html#cb51-51" tabindex="-1"></a><span class="fu">coef</span>(m.lasso)</span>
<span id="cb51-52"><a href="linear-models.html#cb51-52" tabindex="-1"></a><span class="co">#&gt; 13 x 1 sparse Matrix of class &quot;dgCMatrix&quot;</span></span>
<span id="cb51-53"><a href="linear-models.html#cb51-53" tabindex="-1"></a><span class="co">#&gt;                                  s0</span></span>
<span id="cb51-54"><a href="linear-models.html#cb51-54" tabindex="-1"></a><span class="co">#&gt; (Intercept)               -512.8489</span></span>
<span id="cb51-55"><a href="linear-models.html#cb51-55" tabindex="-1"></a><span class="co">#&gt; (Intercept)                  .     </span></span>
<span id="cb51-56"><a href="linear-models.html#cb51-56" tabindex="-1"></a><span class="co">#&gt; Income                      -6.5545</span></span>
<span id="cb51-57"><a href="linear-models.html#cb51-57" tabindex="-1"></a><span class="co">#&gt; Rating                       3.6995</span></span>
<span id="cb51-58"><a href="linear-models.html#cb51-58" tabindex="-1"></a><span class="co">#&gt; Cards                        .     </span></span>
<span id="cb51-59"><a href="linear-models.html#cb51-59" tabindex="-1"></a><span class="co">#&gt; Age                         -0.4336</span></span>
<span id="cb51-60"><a href="linear-models.html#cb51-60" tabindex="-1"></a><span class="co">#&gt; Education                    .     </span></span>
<span id="cb51-61"><a href="linear-models.html#cb51-61" tabindex="-1"></a><span class="co">#&gt; Gender Male                  .     </span></span>
<span id="cb51-62"><a href="linear-models.html#cb51-62" tabindex="-1"></a><span class="co">#&gt; StudentYes                 386.5700</span></span>
<span id="cb51-63"><a href="linear-models.html#cb51-63" tabindex="-1"></a><span class="co">#&gt; MarriedNo                    .     </span></span>
<span id="cb51-64"><a href="linear-models.html#cb51-64" tabindex="-1"></a><span class="co">#&gt; EthnicityAfrican American    .     </span></span>
<span id="cb51-65"><a href="linear-models.html#cb51-65" tabindex="-1"></a><span class="co">#&gt; EthnicityAsian               .     </span></span>
<span id="cb51-66"><a href="linear-models.html#cb51-66" tabindex="-1"></a><span class="co">#&gt; Income:StudentYes            .</span></span></code></pre></div>
<hr />
</div>
</div>
<div id="task-10-perform-feature-selection-with-regularization" class="section level3 unnumbered hasAnchor">
<h3>TASK 10: Perform Feature Selection with Regularization<a href="linear-models.html#task-10-perform-feature-selection-with-regularization" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="task-statement-11" class="section level4 unnumbered hasAnchor">
<h4>Task Statement<a href="linear-models.html#task-statement-11" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Use <strong>cross-validation</strong> to set the value of <code>lambda</code> for fitting the regularized model (<code>alpha = 0.5</code>) in Task 9.
<ul>
<li><strong>List</strong> the features used in the resulting model.</li>
<li><strong>Calculate</strong> the RMSE on the test set.</li>
<li><strong>Recommend</strong> which model should be used and <strong>justify</strong> your choice.</li>
</ul></li>
<li>Suggest <strong>another method</strong> to set the value of <code>lambda</code>.</li>
</ul>
<p>We use cross-validation using the <code>cv.glmnet()</code> function to systematically determine the appropriate or optimal value of the <code>lambda</code> hyperparameter:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="linear-models.html#cb52-1" tabindex="-1"></a><span class="co"># CHUNK 24</span></span>
<span id="cb52-2"><a href="linear-models.html#cb52-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1111</span>)</span>
<span id="cb52-3"><a href="linear-models.html#cb52-3" tabindex="-1"></a></span>
<span id="cb52-4"><a href="linear-models.html#cb52-4" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(<span class="at">x =</span> X.train,</span>
<span id="cb52-5"><a href="linear-models.html#cb52-5" tabindex="-1"></a>               <span class="at">y =</span> data.train<span class="sc">$</span>Balance,</span>
<span id="cb52-6"><a href="linear-models.html#cb52-6" tabindex="-1"></a>               <span class="at">family =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb52-7"><a href="linear-models.html#cb52-7" tabindex="-1"></a>               <span class="at">alpha =</span> <span class="fl">0.5</span>)</span>
<span id="cb52-8"><a href="linear-models.html#cb52-8" tabindex="-1"></a><span class="fu">plot</span>(m)</span>
<span id="cb52-9"><a href="linear-models.html#cb52-9" tabindex="-1"></a></span>
<span id="cb52-10"><a href="linear-models.html#cb52-10" tabindex="-1"></a>m<span class="sc">$</span>lambda.min</span>
<span id="cb52-11"><a href="linear-models.html#cb52-11" tabindex="-1"></a><span class="co">#&gt; [1] 0.8886</span></span>
<span id="cb52-12"><a href="linear-models.html#cb52-12" tabindex="-1"></a>m<span class="sc">$</span>lambda<span class="fl">.1</span>se</span>
<span id="cb52-13"><a href="linear-models.html#cb52-13" tabindex="-1"></a><span class="co">#&gt; [1] 7.551</span></span></code></pre></div>
<p><img src="figures/unnamed-chunk-56-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>We refit the regularized elastic-net (<code>alpha=0.5</code>) model using the optimal value of the <code>lambda</code> parameter that resulted in the lowest mean squared error (MSE). Using this model, we set up the design matrix for the test data, and make predictions on the test data. We then calculate the test RMSE to determine the prediction performance:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="linear-models.html#cb53-1" tabindex="-1"></a><span class="co"># CHUNK 25</span></span>
<span id="cb53-2"><a href="linear-models.html#cb53-2" tabindex="-1"></a><span class="co"># Fit the regularized model using lambda.min</span></span>
<span id="cb53-3"><a href="linear-models.html#cb53-3" tabindex="-1"></a>m.min <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(<span class="at">x =</span> X.train,</span>
<span id="cb53-4"><a href="linear-models.html#cb53-4" tabindex="-1"></a>                <span class="at">y =</span> data.train<span class="sc">$</span>Balance,</span>
<span id="cb53-5"><a href="linear-models.html#cb53-5" tabindex="-1"></a>                <span class="at">family =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb53-6"><a href="linear-models.html#cb53-6" tabindex="-1"></a>                <span class="at">lambda =</span> m<span class="sc">$</span>lambda.min,</span>
<span id="cb53-7"><a href="linear-models.html#cb53-7" tabindex="-1"></a>                <span class="at">alpha =</span> <span class="fl">0.5</span>)</span>
<span id="cb53-8"><a href="linear-models.html#cb53-8" tabindex="-1"></a></span>
<span id="cb53-9"><a href="linear-models.html#cb53-9" tabindex="-1"></a><span class="co"># List the coefficient estimates</span></span>
<span id="cb53-10"><a href="linear-models.html#cb53-10" tabindex="-1"></a>m.min<span class="sc">$</span>beta</span>
<span id="cb53-11"><a href="linear-models.html#cb53-11" tabindex="-1"></a><span class="co">#&gt; 12 x 1 sparse Matrix of class &quot;dgCMatrix&quot;</span></span>
<span id="cb53-12"><a href="linear-models.html#cb53-12" tabindex="-1"></a><span class="co">#&gt;                                 s0</span></span>
<span id="cb53-13"><a href="linear-models.html#cb53-13" tabindex="-1"></a><span class="co">#&gt; (Intercept)                 .     </span></span>
<span id="cb53-14"><a href="linear-models.html#cb53-14" tabindex="-1"></a><span class="co">#&gt; Income                     -7.8132</span></span>
<span id="cb53-15"><a href="linear-models.html#cb53-15" tabindex="-1"></a><span class="co">#&gt; Rating                      3.9840</span></span>
<span id="cb53-16"><a href="linear-models.html#cb53-16" tabindex="-1"></a><span class="co">#&gt; Cards                       2.6915</span></span>
<span id="cb53-17"><a href="linear-models.html#cb53-17" tabindex="-1"></a><span class="co">#&gt; Age                        -0.7829</span></span>
<span id="cb53-18"><a href="linear-models.html#cb53-18" tabindex="-1"></a><span class="co">#&gt; Education                   0.7558</span></span>
<span id="cb53-19"><a href="linear-models.html#cb53-19" tabindex="-1"></a><span class="co">#&gt; Gender Male                17.0049</span></span>
<span id="cb53-20"><a href="linear-models.html#cb53-20" tabindex="-1"></a><span class="co">#&gt; StudentYes                396.3329</span></span>
<span id="cb53-21"><a href="linear-models.html#cb53-21" tabindex="-1"></a><span class="co">#&gt; MarriedNo                  19.4182</span></span>
<span id="cb53-22"><a href="linear-models.html#cb53-22" tabindex="-1"></a><span class="co">#&gt; EthnicityAfrican American  -9.9708</span></span>
<span id="cb53-23"><a href="linear-models.html#cb53-23" tabindex="-1"></a><span class="co">#&gt; EthnicityAsian             -3.6479</span></span>
<span id="cb53-24"><a href="linear-models.html#cb53-24" tabindex="-1"></a><span class="co">#&gt; Income:StudentYes           0.4458</span></span>
<span id="cb53-25"><a href="linear-models.html#cb53-25" tabindex="-1"></a></span>
<span id="cb53-26"><a href="linear-models.html#cb53-26" tabindex="-1"></a><span class="co"># Set up the design matrix for the test set</span></span>
<span id="cb53-27"><a href="linear-models.html#cb53-27" tabindex="-1"></a>X.test <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(Balance <span class="sc">~</span> . <span class="sc">+</span> Income<span class="sc">:</span>Student, <span class="at">data =</span> data.test)</span>
<span id="cb53-28"><a href="linear-models.html#cb53-28" tabindex="-1"></a></span>
<span id="cb53-29"><a href="linear-models.html#cb53-29" tabindex="-1"></a><span class="co"># Make predictions on the test set and calculate test RMSE</span></span>
<span id="cb53-30"><a href="linear-models.html#cb53-30" tabindex="-1"></a>m.min.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(m.min, <span class="at">newx =</span> X.test)</span>
<span id="cb53-31"><a href="linear-models.html#cb53-31" tabindex="-1"></a><span class="fu">RMSE</span>(data.test<span class="sc">$</span>Balance, m.min.pred)</span>
<span id="cb53-32"><a href="linear-models.html#cb53-32" tabindex="-1"></a><span class="co">#&gt; [1] 103.9</span></span></code></pre></div>
<p>We again refit the model using <code>lambda.1se</code> as the lambda hyperparameter, make predictions again, and evaluate the RMSE:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="linear-models.html#cb54-1" tabindex="-1"></a><span class="co"># CHUNK 26</span></span>
<span id="cb54-2"><a href="linear-models.html#cb54-2" tabindex="-1"></a><span class="co"># Fit the regularized model using lambda.1se</span></span>
<span id="cb54-3"><a href="linear-models.html#cb54-3" tabindex="-1"></a>m<span class="fl">.1</span>se <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(<span class="at">x =</span> X.train,</span>
<span id="cb54-4"><a href="linear-models.html#cb54-4" tabindex="-1"></a>                <span class="at">y =</span> data.train<span class="sc">$</span>Balance,</span>
<span id="cb54-5"><a href="linear-models.html#cb54-5" tabindex="-1"></a>                <span class="at">family =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb54-6"><a href="linear-models.html#cb54-6" tabindex="-1"></a>                <span class="at">lambda =</span> m<span class="sc">$</span>lambda<span class="fl">.1</span>se,</span>
<span id="cb54-7"><a href="linear-models.html#cb54-7" tabindex="-1"></a>                <span class="at">alpha =</span> <span class="fl">0.5</span>)</span>
<span id="cb54-8"><a href="linear-models.html#cb54-8" tabindex="-1"></a></span>
<span id="cb54-9"><a href="linear-models.html#cb54-9" tabindex="-1"></a><span class="co"># List the coefficient estimates</span></span>
<span id="cb54-10"><a href="linear-models.html#cb54-10" tabindex="-1"></a>m<span class="fl">.1</span>se<span class="sc">$</span>beta</span>
<span id="cb54-11"><a href="linear-models.html#cb54-11" tabindex="-1"></a><span class="co">#&gt; 12 x 1 sparse Matrix of class &quot;dgCMatrix&quot;</span></span>
<span id="cb54-12"><a href="linear-models.html#cb54-12" tabindex="-1"></a><span class="co">#&gt;                                 s0</span></span>
<span id="cb54-13"><a href="linear-models.html#cb54-13" tabindex="-1"></a><span class="co">#&gt; (Intercept)                 .     </span></span>
<span id="cb54-14"><a href="linear-models.html#cb54-14" tabindex="-1"></a><span class="co">#&gt; Income                     -6.9378</span></span>
<span id="cb54-15"><a href="linear-models.html#cb54-15" tabindex="-1"></a><span class="co">#&gt; Rating                      3.7814</span></span>
<span id="cb54-16"><a href="linear-models.html#cb54-16" tabindex="-1"></a><span class="co">#&gt; Cards                       1.1075</span></span>
<span id="cb54-17"><a href="linear-models.html#cb54-17" tabindex="-1"></a><span class="co">#&gt; Age                        -0.7306</span></span>
<span id="cb54-18"><a href="linear-models.html#cb54-18" tabindex="-1"></a><span class="co">#&gt; Education                   .     </span></span>
<span id="cb54-19"><a href="linear-models.html#cb54-19" tabindex="-1"></a><span class="co">#&gt; Gender Male                 6.7717</span></span>
<span id="cb54-20"><a href="linear-models.html#cb54-20" tabindex="-1"></a><span class="co">#&gt; StudentYes                397.5199</span></span>
<span id="cb54-21"><a href="linear-models.html#cb54-21" tabindex="-1"></a><span class="co">#&gt; MarriedNo                  11.6768</span></span>
<span id="cb54-22"><a href="linear-models.html#cb54-22" tabindex="-1"></a><span class="co">#&gt; EthnicityAfrican American   .     </span></span>
<span id="cb54-23"><a href="linear-models.html#cb54-23" tabindex="-1"></a><span class="co">#&gt; EthnicityAsian              .     </span></span>
<span id="cb54-24"><a href="linear-models.html#cb54-24" tabindex="-1"></a><span class="co">#&gt; Income:StudentYes           0.1148</span></span>
<span id="cb54-25"><a href="linear-models.html#cb54-25" tabindex="-1"></a></span>
<span id="cb54-26"><a href="linear-models.html#cb54-26" tabindex="-1"></a><span class="co"># Make predictions on the test set and calculate test RMSE</span></span>
<span id="cb54-27"><a href="linear-models.html#cb54-27" tabindex="-1"></a>m<span class="fl">.1</span>se.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(m<span class="fl">.1</span>se, <span class="at">newx =</span> X.test)</span>
<span id="cb54-28"><a href="linear-models.html#cb54-28" tabindex="-1"></a><span class="fu">RMSE</span>(data.test<span class="sc">$</span>Balance, m<span class="fl">.1</span>se.pred)</span>
<span id="cb54-29"><a href="linear-models.html#cb54-29" tabindex="-1"></a><span class="co">#&gt; [1] 102.8</span></span></code></pre></div>
</div>
</div>
</div>
<div id="conceptual-review-questions-for-chapter-3" class="section level2 unnumbered hasAnchor">
<h2>Conceptual Review: Questions for Chapter 3<a href="linear-models.html#conceptual-review-questions-for-chapter-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data-exploration-and-visualization.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": {}
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["soa-exam-pa.pdf", "soa-exam-pa.epub"],
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"theme": "journal",
"toolbar": {
"position": "fixed"
},
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
